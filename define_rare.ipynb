{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ADRprofilePrediction import Pairs2Mat, evaluation\n",
    "from Models import loadHyperpar\n",
    "import seaborn as sns \n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import matplotlib.patheffects as path_effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drug_target_mat = Pairs2Mat(path=\"data/drug_target.tsv\",colname1=\"0\",colname2=\"1\")\n",
    "# drug_enzyme_mat = Pairs2Mat(path=\"data/drug_enzyme.tsv\",colname1=\"0\",colname2=\"1\")\n",
    "# drug_Chem_mat = pd.read_csv(\"data/drug_chemsfp.tsv\",sep = \"\\t\",header=0,index_col=0)\n",
    "# DGI_mat = Pairs2Mat(path=\"data/interactions.tsv\",colname1=\"drug_claim_name\",colname2=\"gene_name\")\n",
    "# # DGI_mat2 = pd.read_csv(\"data/intersection_DGIdb_mat.tsv\",sep = \"\\t\",header=0,index_col=0)\n",
    "# drug_transporter_mat = Pairs2Mat(path=\"data/drug_transporter.tsv\",colname1=\"0\",colname2=\"1\")\n",
    "# drug_pathway_mat = Pairs2Mat(path=\"data/drug_pathway.tsv\",colname1=\"0\",colname2=\"1\")\n",
    "# drug_indication_mat = Pairs2Mat(path=\"data/drug_indication.tsv\",colname1=\"1_x\",colname2=\"6\")\n",
    "\n",
    "# SIDER = Pairs2Mat(path=\"data/drug_se.tsv\",colname1=\"1_x\",colname2=\"5\")\n",
    "# # drug_sideeffect_mat = Pairs2Mat(path=\"data/side-effect-and-drug_name_upper.tsv\",colname1=\"drugbank_name\",colname2=\"side_effect_name\")\n",
    "# OFFSIDES = Pairs2Mat(path=\"data/OFFSIDES.csv\",colname1=\"drug_concept_name\",colname2=\"condition_concept_name\",sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dict = {\n",
    "    \"target\":Pairs2Mat(path=\"data/drug_target.tsv\",colname1=\"0\",colname2=\"1\"),\n",
    "    \"enzyme\":Pairs2Mat(path=\"data/drug_enzyme.tsv\",colname1=\"0\",colname2=\"1\"),\n",
    "    \"Chem\":pd.read_csv(\"data/drug_chemsfp.tsv\",sep = \"\\t\",header=0,index_col=0),\n",
    "    \"DGI\":Pairs2Mat(path=\"data/interactions.tsv\",colname1=\"drug_claim_name\",colname2=\"gene_name\"),\n",
    "    \"transporter\":Pairs2Mat(path=\"data/drug_transporter.tsv\",colname1=\"0\",colname2=\"1\"),\n",
    "    \"pathway\":Pairs2Mat(path=\"data/drug_pathway.tsv\",colname1=\"0\",colname2=\"1\"),\n",
    "    \"indication\":Pairs2Mat(path=\"data/drug_indication.tsv\",colname1=\"1_x\",colname2=\"6\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_names = [\"target\", \"enzyme\", \"Chem\", \"DGI\", \"transporter\", \"pathway\", \"indication\"]\n",
    "SE_names = [\"SIDER\", \"OFFSIDES\"]\n",
    "methods = [\"SKR\", \"KR\", \"KRR\", \"Naive\", \"LNSM_RLN\", \"LNSM_jaccard\", \"VKR\"]\n",
    "# methods = [\"SKR\", \"KR\", \"KRR\", \"Naive\", \"LNSM_RLN\", \"LNSM_jaccard\", \"VKR\", \"SVM\", \"OCCA\", \"SCCA\", \"RF\", \"BRF\"]\n",
    "tuning_metrices=[\"AUROC\", \"AUPR\", \"AUROCperdrug\", \"AUPRperdrug\"]\n",
    "# metrice_names = [\"AUROC\", \"AUPR\", \"F1\", \"AUROCperdrug\", \"AUPRperdrug\", \"F1perdrug\", \"adjF1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEs = {}\n",
    "# SIDER = Pairs2Mat(path=\"data/drug_se.tsv\",colname1=\"1_x\",colname2=\"5\")\n",
    "# column_sums = np.sum(SIDER, axis=0)\n",
    "# SEs[\"SIDER\"] = SIDER.loc[:, column_sums >= 5]\n",
    "SEs = {}\n",
    "SIDER = Pairs2Mat(path=\"data/drug_se.tsv\",colname1=\"1_x\",colname2=\"5\")\n",
    "column_sums = np.sum(SIDER, axis=0)\n",
    "SEs[\"SIDER\"] = SIDER.loc[:, (column_sums >= 50)]\n",
    "\n",
    "# OFFSIDERS = Pairs2Mat(path=\"data/OFFSIDES.csv\",colname1=\"drug_concept_name\",colname2=\"condition_concept_name\",sep = \",\")\n",
    "# column_sums = np.sum(OFFSIDERS, axis=0)\n",
    "# SEs[\"OFFSIDES\"] = OFFSIDERS.loc[:, column_sums >= 5]\n",
    "\n",
    "# SEs = {}\n",
    "# SEs[\"SIDER\"] = Pairs2Mat(path=\"data/drug_se.tsv\",colname1=\"1_x\",colname2=\"5\")\n",
    "# SEs[\"OFFSIDES\"] = Pairs2Mat(path=\"data/OFFSIDES.csv\",colname1=\"drug_concept_name\",colname2=\"condition_concept_name\",sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEs = {}\n",
    "SIDER = Pairs2Mat(path=\"data/drug_se.tsv\",colname1=\"1_x\",colname2=\"5\")\n",
    "column_sums = np.sum(SIDER, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x1400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "column_sums\n",
    "plt.figure(dpi=350)\n",
    "plt.hist(column_sums, bins=50, alpha=0.7, edgecolor='black')\n",
    "plt.axvline(x=50, color='red', linestyle='--', linewidth=2)\n",
    "plt.title('ADR counts of SIDER')\n",
    "plt.xlabel('counts')\n",
    "plt.ylabel('number of ADRs')\n",
    "prop = ((column_sums < 50).sum()/len(column_sums)).round(5)*100\n",
    "plt.text(600, 1250, f'Proportion of low-frequent ADRs: {prop}%', color='black', fontsize=12, ha='center')\n",
    "plt.text(600, 1750, \"counts < 50\", color='black', fontsize=12, ha='center')\n",
    "plt.savefig(fname=f\"figs/SIDER_rare.jpg\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "OFFSIDERS = Pairs2Mat(path=\"data/OFFSIDES.csv\",colname1=\"drug_concept_name\",colname2=\"condition_concept_name\",sep = \",\")\n",
    "column_sums = np.sum(OFFSIDERS, axis=0)\n",
    "SEs[\"OFFSIDES\"] = OFFSIDERS.loc[:, column_sums >= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x1400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "column_sums\n",
    "plt.figure(dpi=350)\n",
    "plt.hist(column_sums, bins=50, alpha=0.7, edgecolor='black')\n",
    "plt.axvline(x=50, color='red', linestyle='--', linewidth=2)\n",
    "plt.title('ADR counts of OFFSIDES')\n",
    "plt.xlabel('counts')\n",
    "plt.ylabel('number of ADRs')\n",
    "prop = ((column_sums < 50).sum()/len(column_sums)).round(5)*100\n",
    "plt.text(1200, 1250, f'Proportion of low-frequent ADRs: {prop}%', color='black', fontsize=12, ha='center')\n",
    "plt.text(1200, 1750, \"counts < 50\", color='black', fontsize=12, ha='center')\n",
    "\n",
    "plt.savefig(fname=f\"figs/OFFSIDES_rare.jpg\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 10**np.arange(-2, 3, 1, dtype=float)\n",
    "B = np.arange(0, 1, 0.1, dtype=float)\n",
    "C = np.arange(5, 20, 5, dtype=int)\n",
    "D = np.arange(1, 2, 1, dtype=float)\n",
    "all_hyperparlist = {\n",
    "    \"SKR\":[A,B,A,A], \n",
    "    \"KR\":[A,A], \n",
    "    \"KRR\":[A,A],\n",
    "    \"Naive\":[], \n",
    "    \"LNSM_RLN\":[B], \n",
    "    \"LNSM_jaccard\":[B], \n",
    "    \"VKR\":[A,A,C], \n",
    "    \"SVM\":[A,A,A], \n",
    "    \"OCCA\":[], \n",
    "    \"SCCA\":[A], \n",
    "    \"RF\":[C], \n",
    "    \"BRF\":[C]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrice = \"AUPR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperpars = {}\n",
    "hyperpars[\"nested_cv\"] = {}\n",
    "hyperpars[\"cv\"] = {}\n",
    "hyperparsOut = {}\n",
    "hyperparsOut[\"nested_cv\"] = {}\n",
    "hyperparsOut[\"cv\"] = {}\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperpars[\"nested_cv\"][\"KRR\"] = {}\n",
    "hyperpars[\"nested_cv\"][\"KRR\"][\"target\"] = [\n",
    "    (0.1, 10),\n",
    "    (0.1, 10),\n",
    "    (0.1, 10),\n",
    "    (0.1, 10),\n",
    "    (0.1, 10),\n",
    "    ]\n",
    "hyperpars[\"nested_cv\"][\"KRR\"][\"enzyme\"] = [\n",
    "    (1, 10),\n",
    "    (10, 10),\n",
    "    (1, 10),\n",
    "    (1, 10),\n",
    "    (1, 10),\n",
    "    ]\n",
    "hyperpars[\"nested_cv\"][\"KRR\"][\"Chem\"] = [\n",
    "    (1, 10),\n",
    "    (1, 10),\n",
    "    (1, 10),\n",
    "    (1, 10),\n",
    "    (1, 10),\n",
    "    ]\n",
    "hyperpars[\"nested_cv\"][\"KRR\"][\"DGI\"] = [\n",
    "    (0.1, 10),\n",
    "    (0.1, 10),\n",
    "    (0.1, 10),\n",
    "    (0.1, 10),\n",
    "    (0.1, 10),\n",
    "    ]\n",
    "hyperpars[\"nested_cv\"][\"KRR\"][\"transporter\"] = [\n",
    "    (1, 10),\n",
    "    (1, 10),\n",
    "    (1, 10),\n",
    "    (1, 10),\n",
    "    (1, 10),\n",
    "    ]\n",
    "hyperpars[\"nested_cv\"][\"KRR\"][\"pathway\"] = [\n",
    "    (0.01, 10),\n",
    "    (0.01, 10),\n",
    "    (0.01, 10),\n",
    "    (0.01, 10),\n",
    "    (0.01, 10),\n",
    "    ]\n",
    "hyperpars[\"nested_cv\"][\"KRR\"][\"indication\"] = [\n",
    "    (0.1, 10),\n",
    "    (0.1, 10),\n",
    "    (0.1, 10),\n",
    "    (0.1, 10),\n",
    "    (0.1, 10),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4403870302633993\n",
      "AUROCperdrug: 0.9100148691206565\n",
      "AUPR+AUROCperdrug: 1.3504018993840559\n",
      "AUPR: 0.400166789881065\n",
      "AUROC: 0.895499274556988\n",
      "AUPR+AUROC: 1.2956660644380529\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.44501046206194855\n",
      "AUROCperdrug: 0.9150826598561888\n",
      "AUPR+AUROCperdrug: 1.3600931219181374\n",
      "AUPR: 0.3885331118808608\n",
      "AUROC: 0.887145375391362\n",
      "AUPR+AUROC: 1.2756784872722227\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4453262150327367\n",
      "AUROCperdrug: 0.916151988299712\n",
      "AUPR+AUROCperdrug: 1.3614782033324486\n",
      "AUPR: 0.42072835435916534\n",
      "AUROC: 0.9004670521190702\n",
      "AUPR+AUROC: 1.3211954064782354\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.43748270560748154\n",
      "AUROCperdrug: 0.9072625899642408\n",
      "AUPR+AUROCperdrug: 1.3447452955717223\n",
      "AUPR: 0.39689529557413006\n",
      "AUROC: 0.8753591717603485\n",
      "AUPR+AUROC: 1.2722544673344784\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.44440878730408123\n",
      "AUROCperdrug: 0.9076968883399532\n",
      "AUPR+AUROCperdrug: 1.3521056756440344\n",
      "AUPR: 0.4117742424431416\n",
      "AUROC: 0.8785113253312009\n",
      "AUPR+AUROC: 1.2902855677743426\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.4425230400539294, std: 0.003084432202416969\n",
      "Mean AUROCperdrug: 0.9112417991161503, std: 0.0037085852866670303\n",
      "Mean AUPR+AUROCperdrug: 1.3537648391700796, std: 0.00624431747389469\n",
      "Mean AUPR: 0.40361955882767253, std: 0.011348550220952373\n",
      "Mean AUROC: 0.887396439831794, std: 0.00959584234774462\n",
      "Mean AUPR+AUROC: 1.2910159986594665, std: 0.017436671761130538\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.35255363793139893\n",
      "AUPR for each fold: [0.36622061 0.36033108 0.33822951 0.34543334]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4062646668767695\n",
      "AUROCperdrug: 0.925884365062312\n",
      "AUPR+AUROCperdrug: 1.3321490319390814\n",
      "AUPR: 0.3596671848389722\n",
      "AUROC: 0.9182381033291207\n",
      "AUPR+AUROC: 1.277905288168093\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.3548603790472511\n",
      "AUPR for each fold: [0.37690319 0.36294346 0.33357576 0.3460191 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.40931494521365475\n",
      "AUROCperdrug: 0.9297585289144547\n",
      "AUPR+AUROCperdrug: 1.3390734741281094\n",
      "AUPR: 0.3472417091031613\n",
      "AUROC: 0.9133474789122837\n",
      "AUPR+AUROC: 1.260589188015445\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.3524477636792591\n",
      "AUPR for each fold: [0.36406061 0.36486669 0.33024898 0.35061478]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4081142839680789\n",
      "AUROCperdrug: 0.9293907485843156\n",
      "AUPR+AUROCperdrug: 1.3375050325523945\n",
      "AUPR: 0.35834908273006794\n",
      "AUROC: 0.9196049282972562\n",
      "AUPR+AUROC: 1.2779540110273242\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.3552429327093303\n",
      "AUPR for each fold: [0.3643001  0.35794126 0.34797647 0.3507539 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.40518116511994956\n",
      "AUROCperdrug: 0.9269027269160796\n",
      "AUPR+AUROCperdrug: 1.3320838920360292\n",
      "AUPR: 0.34667439642613096\n",
      "AUROC: 0.9147479527946396\n",
      "AUPR+AUROC: 1.2614223492207706\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.35306583707429806\n",
      "AUPR for each fold: [0.35326866 0.37049267 0.34453863 0.34396339]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4138017230897416\n",
      "AUROCperdrug: 0.9231930457375283\n",
      "AUPR+AUROCperdrug: 1.3369947688272699\n",
      "AUPR: 0.3567143478843263\n",
      "AUROC: 0.9068493435590159\n",
      "AUPR+AUROC: 1.2635636914433421\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.40853535685363884, std: 0.002997542622755973\n",
      "Mean AUROCperdrug: 0.9270258830429379, std: 0.0024111746112352814\n",
      "Mean AUPR+AUROCperdrug: 1.335561239896577, std: 0.0028949692803048625\n",
      "Mean AUPR: 0.3537293441965318, std: 0.005610202844411572\n",
      "Mean AUROC: 0.9145575613784633, std: 0.004470782309212302\n",
      "Mean AUPR+AUROC: 1.2682869055749948, std: 0.007932867739147519\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4552369445850115\n",
      "AUROCperdrug: 0.8873232414423817\n",
      "AUPR+AUROCperdrug: 1.3425601860273932\n",
      "AUPR: 0.41904037587097426\n",
      "AUROC: 0.867533492767044\n",
      "AUPR+AUROC: 1.2865738686380181\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4598772557221016\n",
      "AUROCperdrug: 0.8915827867323713\n",
      "AUPR+AUROCperdrug: 1.351460042454473\n",
      "AUPR: 0.4065923158226469\n",
      "AUROC: 0.8561589106897773\n",
      "AUPR+AUROC: 1.262751226512424\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.45911870511724734\n",
      "AUROCperdrug: 0.8906060086649078\n",
      "AUPR+AUROCperdrug: 1.349724713782155\n",
      "AUPR: 0.43810289691258764\n",
      "AUROC: 0.8731489319243033\n",
      "AUPR+AUROC: 1.311251828836891\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.452712089059717\n",
      "AUROCperdrug: 0.881507243437244\n",
      "AUPR+AUROCperdrug: 1.334219332496961\n",
      "AUPR: 0.4151421485364135\n",
      "AUROC: 0.8467004899060564\n",
      "AUPR+AUROC: 1.26184263844247\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4620790026817741\n",
      "AUROCperdrug: 0.8856917613483897\n",
      "AUPR+AUROCperdrug: 1.3477707640301637\n",
      "AUPR: 0.4342057998128973\n",
      "AUROC: 0.8545852092490716\n",
      "AUPR+AUROC: 1.2887910090619688\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.4578047994331703, std: 0.0033710477331431407\n",
      "Mean AUROCperdrug: 0.8873422083250588, std: 0.003616795490332033\n",
      "Mean AUPR+AUROCperdrug: 1.3451470077582293, std: 0.006225747019833694\n",
      "Mean AUPR: 0.4226167073911039, std: 0.011828520037684528\n",
      "Mean AUROC: 0.8596254069072504, std: 0.009485749509656504\n",
      "Mean AUPR+AUROC: 1.2822421142983544, std: 0.018435015474742716\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.36645797037967837\n",
      "AUPR for each fold: [0.37937706 0.37544324 0.35132204 0.35968954]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.41829029318354316\n",
      "AUROCperdrug: 0.8834735124657277\n",
      "AUPR+AUROCperdrug: 1.3017638056492709\n",
      "AUPR: 0.37297545124937115\n",
      "AUROC: 0.8675334590160192\n",
      "AUPR+AUROC: 1.2405089102653903\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.3686192495712154\n",
      "AUPR for each fold: [0.38857382 0.37770523 0.3471558  0.36104215]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4212204778185457\n",
      "AUROCperdrug: 0.8875413037400774\n",
      "AUPR+AUROCperdrug: 1.3087617815586232\n",
      "AUPR: 0.3608500775214872\n",
      "AUROC: 0.8595206943909952\n",
      "AUPR+AUROC: 1.2203707719124823\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.36647137800805535\n",
      "AUPR for each fold: [0.37572937 0.37940635 0.344615   0.3661348 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.41899158489047095\n",
      "AUROCperdrug: 0.8847237144147739\n",
      "AUPR+AUROCperdrug: 1.303715299305245\n",
      "AUPR: 0.3706590352886549\n",
      "AUROC: 0.867386532159015\n",
      "AUPR+AUROC: 1.2380455674476698\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.36935968698667143\n",
      "AUPR for each fold: [0.37582786 0.37207604 0.36325973 0.36627512]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4165893254752751\n",
      "AUROCperdrug: 0.8830846936972876\n",
      "AUPR+AUROCperdrug: 1.2996740191725626\n",
      "AUPR: 0.35886525385016665\n",
      "AUROC: 0.8577837946164228\n",
      "AUPR+AUROC: 1.2166490484665895\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.36583495524966725\n",
      "AUPR for each fold: [0.36399087 0.38210276 0.35980463 0.35744156]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4280565462442539\n",
      "AUROCperdrug: 0.8794066460524298\n",
      "AUPR+AUROCperdrug: 1.3074631922966837\n",
      "AUPR: 0.37359526519999386\n",
      "AUROC: 0.8580611243532998\n",
      "AUPR+AUROC: 1.2316563895532937\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.42062964552241777, std: 0.0039996983690481595\n",
      "Mean AUROCperdrug: 0.8836459740740592, std: 0.0026325576229832147\n",
      "Mean AUPR+AUROCperdrug: 1.304275619596477, std: 0.00340834750180275\n",
      "Mean AUPR: 0.3673890166219348, std: 0.006258291327330828\n",
      "Mean AUROC: 0.8620571209071504, std: 0.004450969981732367\n",
      "Mean AUPR+AUROC: 1.229446137529085, std: 0.009458838185514823\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4670110551434802\n",
      "AUROCperdrug: 0.8717992836444296\n",
      "AUPR+AUROCperdrug: 1.3388103387879098\n",
      "AUPR: 0.43358566028119455\n",
      "AUROC: 0.8502892513347443\n",
      "AUPR+AUROC: 1.283874911615939\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.47247007411975533\n",
      "AUROCperdrug: 0.8779458708975011\n",
      "AUPR+AUROCperdrug: 1.3504159450172564\n",
      "AUPR: 0.42121633708659845\n",
      "AUROC: 0.8389598699111718\n",
      "AUPR+AUROC: 1.2601762069977702\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.47047347962959596\n",
      "AUROCperdrug: 0.874304762618861\n",
      "AUPR+AUROCperdrug: 1.344778242248457\n",
      "AUPR: 0.45167850312197766\n",
      "AUROC: 0.8559646539095189\n",
      "AUPR+AUROC: 1.3076431570314966\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4651996555259286\n",
      "AUROCperdrug: 0.8669054060518184\n",
      "AUPR+AUROCperdrug: 1.332105061577747\n",
      "AUPR: 0.43029674500450993\n",
      "AUROC: 0.8304495559187222\n",
      "AUPR+AUROC: 1.260746300923232\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4755994836261731\n",
      "AUROCperdrug: 0.8704481430019625\n",
      "AUPR+AUROCperdrug: 1.3460476266281356\n",
      "AUPR: 0.4499176450364082\n",
      "AUROC: 0.838950973455626\n",
      "AUPR+AUROC: 1.2888686184920342\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.4701507496089866, std: 0.0037294272267608024\n",
      "Mean AUROCperdrug: 0.8722806932429146, std: 0.00370607076755315\n",
      "Mean AUPR+AUROCperdrug: 1.342431442851901, std: 0.006357406266728518\n",
      "Mean AUPR: 0.4373389781061377, std: 0.011725739504357137\n",
      "Mean AUROC: 0.8429228609059567, std: 0.00907101535159664\n",
      "Mean AUPR+AUROC: 1.2802618390120943, std: 0.01800642309538063\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.3783917222895438\n",
      "AUPR for each fold: [0.39165188 0.38745258 0.36367624 0.37078619]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.428461262554432\n",
      "AUROCperdrug: 0.8586917696530092\n",
      "AUPR+AUROCperdrug: 1.2871530322074412\n",
      "AUPR: 0.38405647593900694\n",
      "AUROC: 0.8398907945697073\n",
      "AUPR+AUROC: 1.2239472705087142\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.3803095809909527\n",
      "AUPR for each fold: [0.40028516 0.38895234 0.35957333 0.37242751]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4321242583194682\n",
      "AUROCperdrug: 0.8664504748613494\n",
      "AUPR+AUROCperdrug: 1.2985747331808177\n",
      "AUPR: 0.37300831104519744\n",
      "AUROC: 0.8324147422305376\n",
      "AUPR+AUROC: 1.205423053275735\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.37845402137856077\n",
      "AUPR for each fold: [0.38730692 0.39047955 0.3575599  0.37846971]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4291132204706882\n",
      "AUROCperdrug: 0.8599940288038724\n",
      "AUPR+AUROCperdrug: 1.2891072492745606\n",
      "AUPR: 0.3815322639312627\n",
      "AUROC: 0.8392036147336422\n",
      "AUPR+AUROC: 1.220735878664905\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.3811125734785853\n",
      "AUPR for each fold: [0.38683466 0.3818588  0.377091   0.37866584]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4271428079812286\n",
      "AUROCperdrug: 0.8598459584778696\n",
      "AUPR+AUROCperdrug: 1.2869887664590982\n",
      "AUPR: 0.3705509150946876\n",
      "AUROC: 0.8291107850795355\n",
      "AUPR+AUROC: 1.1996617001742231\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.37729558833851257\n",
      "AUPR for each fold: [0.37454537 0.39169753 0.3734707  0.36946875]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.43983621326135497\n",
      "AUROCperdrug: 0.8547209031082719\n",
      "AUPR+AUROCperdrug: 1.2945571163696268\n",
      "AUPR: 0.3863152229721026\n",
      "AUROC: 0.8307800575064999\n",
      "AUPR+AUROC: 1.2170952804786024\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.4313355525174344, std: 0.0045532998844505955\n",
      "Mean AUROCperdrug: 0.8599406269808745, std: 0.0037734624746687227\n",
      "Mean AUPR+AUROCperdrug: 1.291276179498309, std: 0.004563330912316339\n",
      "Mean AUPR: 0.3790926377964515, std: 0.006208659438760205\n",
      "Mean AUROC: 0.8342799988239845, std: 0.004431084847914547\n",
      "Mean AUPR+AUROC: 1.213372636620436, std: 0.009285299630682212\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4770934625933624\n",
      "AUROCperdrug: 0.8612320905543847\n",
      "AUPR+AUROCperdrug: 1.338325553147747\n",
      "AUPR: 0.4458938276233605\n",
      "AUROC: 0.8381481027771087\n",
      "AUPR+AUROC: 1.2840419304004693\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.482167376450324\n",
      "AUROCperdrug: 0.8674512204990509\n",
      "AUPR+AUROCperdrug: 1.3496185969493748\n",
      "AUPR: 0.4329448002931618\n",
      "AUROC: 0.8267771940335018\n",
      "AUPR+AUROC: 1.2597219943266635\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.48023292972917164\n",
      "AUROCperdrug: 0.8626050885951753\n",
      "AUPR+AUROCperdrug: 1.342838018324347\n",
      "AUPR: 0.4633649333679867\n",
      "AUROC: 0.8442694926655483\n",
      "AUPR+AUROC: 1.3076344260335349\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4752678614020223\n",
      "AUROCperdrug: 0.8569938259752186\n",
      "AUPR+AUROCperdrug: 1.3322616873772408\n",
      "AUPR: 0.4432050222554154\n",
      "AUROC: 0.8202310445322911\n",
      "AUPR+AUROC: 1.2634360667877065\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4861553977323217\n",
      "AUROCperdrug: 0.8592107581222839\n",
      "AUPR+AUROCperdrug: 1.3453661558546055\n",
      "AUPR: 0.4624717892658471\n",
      "AUROC: 0.8282296650702028\n",
      "AUPR+AUROC: 1.29070145433605\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.4801834055814404, std: 0.0038291932714178438\n",
      "Mean AUROCperdrug: 0.8614985967492226, std: 0.003528632725952087\n",
      "Mean AUPR+AUROCperdrug: 1.341682002330663, std: 0.005965014320964596\n",
      "Mean AUPR: 0.4495760745611543, std: 0.011723315390367445\n",
      "Mean AUROC: 0.8315310998157306, std: 0.008570200949350586\n",
      "Mean AUPR+AUROC: 1.281107174376885, std: 0.01774233384037593\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.38853068700116133\n",
      "AUPR for each fold: [0.40258845 0.39861531 0.37274307 0.38017592]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4375172487836131\n",
      "AUROCperdrug: 0.842126859560506\n",
      "AUPR+AUROCperdrug: 1.2796441083441192\n",
      "AUPR: 0.3938465307471998\n",
      "AUROC: 0.8214672573295875\n",
      "AUPR+AUROC: 1.2153137880767872\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.39037109556595884\n",
      "AUPR for each fold: [0.41056603 0.39996089 0.36865971 0.38229776]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4408795197167272\n",
      "AUROCperdrug: 0.8508139222722348\n",
      "AUPR+AUROCperdrug: 1.291693441988962\n",
      "AUPR: 0.3831797969953601\n",
      "AUROC: 0.8137982962457614\n",
      "AUPR+AUROC: 1.1969780932411216\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.38860034920104425\n",
      "AUPR for each fold: [0.39726003 0.40147418 0.36716659 0.3885006 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4382277382287586\n",
      "AUROCperdrug: 0.8430392147748037\n",
      "AUPR+AUROCperdrug: 1.2812669530035623\n",
      "AUPR: 0.3913610579980735\n",
      "AUROC: 0.8207367875895883\n",
      "AUPR+AUROC: 1.2120978455876619\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.39122381783452576\n",
      "AUPR for each fold: [0.3965331  0.39164046 0.38782353 0.38889817]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.43598022881284304\n",
      "AUROCperdrug: 0.8427962489317775\n",
      "AUPR+AUROCperdrug: 1.2787764777446204\n",
      "AUPR: 0.3805317592492877\n",
      "AUROC: 0.809472351303544\n",
      "AUPR+AUROC: 1.1900041105528318\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.38724269892595675\n",
      "AUPR for each fold: [0.38375247 0.40087785 0.3847084  0.37963208]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4491005955464055\n",
      "AUROCperdrug: 0.8353848328377843\n",
      "AUPR+AUROCperdrug: 1.2844854283841898\n",
      "AUPR: 0.39687752084834926\n",
      "AUROC: 0.8119332344516726\n",
      "AUPR+AUROC: 1.2088107553000218\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.4403410662176695, std: 0.004657816853259963\n",
      "Mean AUROCperdrug: 0.8428322156754213, std: 0.00489311395351853\n",
      "Mean AUPR+AUROCperdrug: 1.2831732818930908, std: 0.004684781723137125\n",
      "Mean AUPR: 0.38915933316765405, std: 0.0062702108258920145\n",
      "Mean AUROC: 0.8154815853840308, std: 0.004795426357632612\n",
      "Mean AUPR+AUROC: 1.204640918551685, std: 0.00959018752020024\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4848062057309433\n",
      "AUROCperdrug: 0.8530549448612096\n",
      "AUPR+AUROCperdrug: 1.337861150592153\n",
      "AUPR: 0.45484281670959004\n",
      "AUROC: 0.8292943300701514\n",
      "AUPR+AUROC: 1.2841371467797416\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4897516438276574\n",
      "AUROCperdrug: 0.8594259911935821\n",
      "AUPR+AUROCperdrug: 1.3491776350212394\n",
      "AUPR: 0.4414302819534712\n",
      "AUROC: 0.817360675127772\n",
      "AUPR+AUROC: 1.2587909570812432\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4879416596823158\n",
      "AUROCperdrug: 0.8557730068423751\n",
      "AUPR+AUROCperdrug: 1.3437146665246908\n",
      "AUPR: 0.4719592544191368\n",
      "AUROC: 0.8360354901835496\n",
      "AUPR+AUROC: 1.3079947446026865\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.48322461342273776\n",
      "AUROCperdrug: 0.8492886899627274\n",
      "AUPR+AUROCperdrug: 1.3325133033854653\n",
      "AUPR: 0.45202841886056244\n",
      "AUROC: 0.8112934693450169\n",
      "AUPR+AUROC: 1.2633218882055792\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.494333337394404\n",
      "AUROCperdrug: 0.8513486001748924\n",
      "AUPR+AUROCperdrug: 1.3456819375692963\n",
      "AUPR: 0.4717012017549058\n",
      "AUROC: 0.8201819744253791\n",
      "AUPR+AUROC: 1.291883176180285\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.48801149201161165, std: 0.0039035061344052007\n",
      "Mean AUROCperdrug: 0.8537782466069574, std: 0.003534361423922276\n",
      "Mean AUPR+AUROCperdrug: 1.3417897386185689, std: 0.0059147549042655794\n",
      "Mean AUPR: 0.45839239473953325, std: 0.011849025184244893\n",
      "Mean AUROC: 0.8228331878303738, std: 0.00878851041971914\n",
      "Mean AUPR+AUROC: 1.281225582569907, std: 0.018234605761337567\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.3961758681329208\n",
      "AUPR for each fold: [0.41090691 0.4066464  0.37957741 0.38757275]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.44486001361533256\n",
      "AUROCperdrug: 0.8316461843673527\n",
      "AUPR+AUROCperdrug: 1.2765061979826853\n",
      "AUPR: 0.4016492322128673\n",
      "AUROC: 0.810274943170185\n",
      "AUPR+AUROC: 1.2119241753830523\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.39809863834320597\n",
      "AUPR for each fold: [0.41865131 0.40792861 0.3756233  0.39019133]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4477416858289927\n",
      "AUROCperdrug: 0.8402553567839038\n",
      "AUPR+AUROCperdrug: 1.2879970426128966\n",
      "AUPR: 0.3906875311616557\n",
      "AUROC: 0.8009337247674038\n",
      "AUPR+AUROC: 1.1916212559290595\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.396349524564874\n",
      "AUPR for each fold: [0.40513995 0.40913067 0.3745446  0.39658288]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4455591470743275\n",
      "AUROCperdrug: 0.8336144165191948\n",
      "AUPR+AUROCperdrug: 1.2791735635935222\n",
      "AUPR: 0.39880468352719844\n",
      "AUROC: 0.8083629580790934\n",
      "AUPR+AUROC: 1.2071676416062918\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.3990179529162151\n",
      "AUPR for each fold: [0.40433025 0.39909476 0.39578524 0.39686157]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4430532509450082\n",
      "AUROCperdrug: 0.8316097671876638\n",
      "AUPR+AUROCperdrug: 1.274663018132672\n",
      "AUPR: 0.38783555708743844\n",
      "AUROC: 0.795647938442081\n",
      "AUPR+AUROC: 1.1834834955295195\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.39476638750249005\n",
      "AUPR for each fold: [0.39103442 0.40808626 0.39262715 0.38731773]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4568411351430837\n",
      "AUROCperdrug: 0.8237236591608367\n",
      "AUPR+AUROCperdrug: 1.2805647943039205\n",
      "AUPR: 0.4051452689082696\n",
      "AUROC: 0.8002456505300578\n",
      "AUPR+AUROC: 1.2053909194383274\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.4476110465213489, std: 0.004853113979707518\n",
      "Mean AUROCperdrug: 0.8321698768037903, std: 0.005279928986651205\n",
      "Mean AUPR+AUROCperdrug: 1.2797809233251392, std: 0.004591399249318626\n",
      "Mean AUPR: 0.39682445457948584, std: 0.006555880477096533\n",
      "Mean AUROC: 0.8030930429977643, std: 0.0054323397533882455\n",
      "Mean AUPR+AUROC: 1.1999174975772502, std: 0.010635669194117469\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.49112041551636065\n",
      "AUROCperdrug: 0.8465824740467514\n",
      "AUPR+AUROCperdrug: 1.337702889563112\n",
      "AUPR: 0.46292738786994647\n",
      "AUROC: 0.821849723586198\n",
      "AUPR+AUROC: 1.2847771114561444\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4964806010224501\n",
      "AUROCperdrug: 0.8525124613286952\n",
      "AUPR+AUROCperdrug: 1.3489930623511452\n",
      "AUPR: 0.4497020255715243\n",
      "AUROC: 0.8104831382053528\n",
      "AUPR+AUROC: 1.260185163776877\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4954815339073597\n",
      "AUROCperdrug: 0.8498694769062184\n",
      "AUPR+AUROCperdrug: 1.345351010813578\n",
      "AUPR: 0.48051610269811085\n",
      "AUROC: 0.8296999531222603\n",
      "AUPR+AUROC: 1.310216055820371\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.49108240833787725\n",
      "AUROCperdrug: 0.8446675783615444\n",
      "AUPR+AUROCperdrug: 1.3357499866994216\n",
      "AUPR: 0.46073480191796456\n",
      "AUROC: 0.8052268565416845\n",
      "AUPR+AUROC: 1.265961658459649\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5022684959395776\n",
      "AUROCperdrug: 0.8467152916261854\n",
      "AUPR+AUROCperdrug: 1.3489837875657629\n",
      "AUPR: 0.48082686604638236\n",
      "AUROC: 0.8147180582708157\n",
      "AUPR+AUROC: 1.295544924317198\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.495286690944725, std: 0.004128990899073649\n",
      "Mean AUROCperdrug: 0.8480694564538789, std: 0.0027784175194256245\n",
      "Mean AUPR+AUROCperdrug: 1.343356147398604, std: 0.005607809355068048\n",
      "Mean AUPR: 0.4669414368207857, std: 0.012074012626114666\n",
      "Mean AUROC: 0.8163955459452623, std: 0.008593782138787242\n",
      "Mean AUPR+AUROC: 1.283336982766048, std: 0.018501356669605857\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.40356857380230526\n",
      "AUPR for each fold: [0.41875764 0.41454521 0.38657748 0.39439397]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.45090714129993537\n",
      "AUROCperdrug: 0.8215769370619441\n",
      "AUPR+AUROCperdrug: 1.2724840783618796\n",
      "AUPR: 0.4082734290764462\n",
      "AUROC: 0.7990070869729817\n",
      "AUPR+AUROC: 1.207280516049428\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4053714604555143\n",
      "AUPR for each fold: [0.42570937 0.41592348 0.38296082 0.39689218]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.453942491568654\n",
      "AUROCperdrug: 0.8303316022157732\n",
      "AUPR+AUROCperdrug: 1.2842740937844273\n",
      "AUPR: 0.3978795577876552\n",
      "AUROC: 0.7904412706807735\n",
      "AUPR+AUROC: 1.1883208284684288\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.40359266892354295\n",
      "AUPR for each fold: [0.41209768 0.41677918 0.38233113 0.40316269]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4525067055626856\n",
      "AUROCperdrug: 0.8252484693489486\n",
      "AUPR+AUROCperdrug: 1.277755174911634\n",
      "AUPR: 0.4060120845156506\n",
      "AUROC: 0.7985476119718163\n",
      "AUPR+AUROC: 1.204559696487467\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4062925104216424\n",
      "AUPR for each fold: [0.41128039 0.40625689 0.40375255 0.40388021]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4503253335328499\n",
      "AUROCperdrug: 0.8240274391544755\n",
      "AUPR+AUROCperdrug: 1.2743527726873254\n",
      "AUPR: 0.39494464795631423\n",
      "AUROC: 0.7845894217230271\n",
      "AUPR+AUROC: 1.1795340696793413\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.40181172238334195\n",
      "AUPR for each fold: [0.39769613 0.41475608 0.40041838 0.39437631]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4643665252429664\n",
      "AUROCperdrug: 0.8164278545383026\n",
      "AUPR+AUROCperdrug: 1.2807943797812689\n",
      "AUPR: 0.41317935381480786\n",
      "AUROC: 0.7913822128627308\n",
      "AUPR+AUROC: 1.2045615666775387\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.4544096394414182, std: 0.005136691684981396\n",
      "Mean AUROCperdrug: 0.8235224604638887, std: 0.004554492641192531\n",
      "Mean AUPR+AUROCperdrug: 1.277932099905307, std: 0.004264677173610079\n",
      "Mean AUPR: 0.40405781463017476, std: 0.006723298557693076\n",
      "Mean AUROC: 0.7927935208422658, std: 0.005413872591437378\n",
      "Mean AUPR+AUROC: 1.1968513354724408, std: 0.010957112270811139\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4977741554669054\n",
      "AUROCperdrug: 0.8398981316848687\n",
      "AUPR+AUROCperdrug: 1.337672287151774\n",
      "AUPR: 0.47083649236925307\n",
      "AUROC: 0.8144860108780719\n",
      "AUPR+AUROC: 1.285322503247325\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5025492778908278\n",
      "AUROCperdrug: 0.8466971569982239\n",
      "AUPR+AUROCperdrug: 1.3492464348890518\n",
      "AUPR: 0.4578594986022675\n",
      "AUROC: 0.8044025828729462\n",
      "AUPR+AUROC: 1.2622620814752137\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5017096404299065\n",
      "AUROCperdrug: 0.8428250746230919\n",
      "AUPR+AUROCperdrug: 1.3445347150529985\n",
      "AUPR: 0.48819976826200806\n",
      "AUROC: 0.8230127036697059\n",
      "AUPR+AUROC: 1.311212471931714\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.49730910732809436\n",
      "AUROCperdrug: 0.837768016314866\n",
      "AUPR+AUROCperdrug: 1.3350771236429604\n",
      "AUPR: 0.46888203636490483\n",
      "AUROC: 0.7989064816983774\n",
      "AUPR+AUROC: 1.2677885180632822\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5089138939175102\n",
      "AUROCperdrug: 0.8411980871311266\n",
      "AUPR+AUROCperdrug: 1.3501119810486368\n",
      "AUPR: 0.4884768396192777\n",
      "AUROC: 0.8076585516795605\n",
      "AUPR+AUROC: 1.2961353912988383\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5016512150066488, std: 0.004181911649070799\n",
      "Mean AUROCperdrug: 0.8416772933504355, std: 0.0030064575388961037\n",
      "Mean AUPR+AUROCperdrug: 1.3433285083570843, std: 0.006042689447786488\n",
      "Mean AUPR: 0.47485092704354226, std: 0.011868521707104196\n",
      "Mean AUROC: 0.8096932661597324, std: 0.008353010585290678\n",
      "Mean AUPR+AUROC: 1.2845441932032746, std: 0.01801890053589147\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.410608952570016\n",
      "AUPR for each fold: [0.42619979 0.42241566 0.39277846 0.4010419 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4571134569299102\n",
      "AUROCperdrug: 0.813276860663004\n",
      "AUPR+AUROCperdrug: 1.270390317592914\n",
      "AUPR: 0.4146546726024642\n",
      "AUROC: 0.7882378792279807\n",
      "AUPR+AUROC: 1.202892551830445\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.412218083798245\n",
      "AUPR for each fold: [0.43260039 0.42362753 0.3891157  0.40352871]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4600047023147825\n",
      "AUROCperdrug: 0.8219885721757986\n",
      "AUPR+AUROCperdrug: 1.281993274490581\n",
      "AUPR: 0.40511257572936354\n",
      "AUROC: 0.7813106141584657\n",
      "AUPR+AUROC: 1.1864231898878292\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4105967727674392\n",
      "AUPR for each fold: [0.41915466 0.42430615 0.38895189 0.40997439]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.45858123771565235\n",
      "AUROCperdrug: 0.8162091210750865\n",
      "AUPR+AUROCperdrug: 1.2747903587907388\n",
      "AUPR: 0.4126043998920427\n",
      "AUROC: 0.7882600640532831\n",
      "AUPR+AUROC: 1.2008644639453259\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4130945754654106\n",
      "AUPR for each fold: [0.41805986 0.41272903 0.41109512 0.4104943 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4567962183082443\n",
      "AUROCperdrug: 0.8159327801474108\n",
      "AUPR+AUROCperdrug: 1.2727289984556551\n",
      "AUPR: 0.4022173370670017\n",
      "AUROC: 0.7753505384710717\n",
      "AUPR+AUROC: 1.1775678755380734\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4087100662757162\n",
      "AUPR for each fold: [0.40446252 0.42114299 0.40817916 0.4010556 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.47104490491323875\n",
      "AUROCperdrug: 0.8106658497673969\n",
      "AUPR+AUROCperdrug: 1.2817107546806357\n",
      "AUPR: 0.42023092849082433\n",
      "AUROC: 0.7814565200149769\n",
      "AUPR+AUROC: 1.2016874485058011\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.46070810403636564, std: 0.0052932433245801835\n",
      "Mean AUROCperdrug: 0.8156146367657394, std: 0.003769280283514409\n",
      "Mean AUPR+AUROCperdrug: 1.276322740802105, std: 0.004725303581395678\n",
      "Mean AUPR: 0.4109639827563393, std: 0.006525813637784002\n",
      "Mean AUROC: 0.7829231231851556, std: 0.004874930134813154\n",
      "Mean AUPR+AUROC: 1.193887105941495, std: 0.010125751807239632\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5026955269733275\n",
      "AUROCperdrug: 0.8340590017093509\n",
      "AUPR+AUROCperdrug: 1.3367545286826785\n",
      "AUPR: 0.47720720363283164\n",
      "AUROC: 0.8088097936680888\n",
      "AUPR+AUROC: 1.2860169973009206\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5079939012488338\n",
      "AUROCperdrug: 0.841895951655802\n",
      "AUPR+AUROCperdrug: 1.349889852904636\n",
      "AUPR: 0.464152179913663\n",
      "AUROC: 0.7988356121964107\n",
      "AUPR+AUROC: 1.2629877921100738\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5068117472081686\n",
      "AUROCperdrug: 0.8364045417874963\n",
      "AUPR+AUROCperdrug: 1.343216288995665\n",
      "AUPR: 0.4938049231289728\n",
      "AUROC: 0.8167543380947497\n",
      "AUPR+AUROC: 1.3105592612237225\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5028420183778057\n",
      "AUROCperdrug: 0.8331471260604404\n",
      "AUPR+AUROCperdrug: 1.3359891444382461\n",
      "AUPR: 0.47499782351007597\n",
      "AUROC: 0.793618296939605\n",
      "AUPR+AUROC: 1.2686161204496809\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5141211232995178\n",
      "AUROCperdrug: 0.8353492078737981\n",
      "AUPR+AUROCperdrug: 1.3494703311733158\n",
      "AUPR: 0.494445706813166\n",
      "AUROC: 0.8021894747297295\n",
      "AUPR+AUROC: 1.2966351815428956\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5068928634215307, std: 0.004183146754026828\n",
      "Mean AUROCperdrug: 0.8361711658173776, std: 0.003069505034074389\n",
      "Mean AUPR+AUROCperdrug: 1.3430640292389082, std: 0.005958515728528928\n",
      "Mean AUPR: 0.4809215673997419, std: 0.011653178092187457\n",
      "Mean AUROC: 0.8040415031257167, std: 0.008043970467274425\n",
      "Mean AUPR+AUROC: 1.2849630705254587, std: 0.01756501952021087\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4164447924173328\n",
      "AUPR for each fold: [0.43213513 0.42866984 0.39849526 0.40647894]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.46190119076506986\n",
      "AUROCperdrug: 0.8055807392459322\n",
      "AUPR+AUROCperdrug: 1.267481930011002\n",
      "AUPR: 0.4201254396363369\n",
      "AUROC: 0.7800693874145529\n",
      "AUPR+AUROC: 1.2001948270508898\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.41800969547182365\n",
      "AUPR for each fold: [0.43834903 0.42965761 0.39489889 0.40913325]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4653446655219607\n",
      "AUROCperdrug: 0.8158213455996861\n",
      "AUPR+AUROCperdrug: 1.2811660111216467\n",
      "AUPR: 0.41076857974873915\n",
      "AUROC: 0.773298549003602\n",
      "AUPR+AUROC: 1.184067128752341\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4163870490380017\n",
      "AUPR for each fold: [0.42505235 0.43041433 0.39444007 0.41564145]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.46369242891000034\n",
      "AUROCperdrug: 0.8090817558427296\n",
      "AUPR+AUROCperdrug: 1.2727741847527299\n",
      "AUPR: 0.41821254495113147\n",
      "AUROC: 0.7803748274045996\n",
      "AUPR+AUROC: 1.198587372355731\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.41875521813729\n",
      "AUPR for each fold: [0.42391642 0.4183855  0.41642639 0.41629257]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4624347242070271\n",
      "AUROCperdrug: 0.810373046393142\n",
      "AUPR+AUROCperdrug: 1.272807770600169\n",
      "AUPR: 0.40829789588289883\n",
      "AUROC: 0.7682391166474364\n",
      "AUPR+AUROC: 1.1765370125303352\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4144577008175113\n",
      "AUPR for each fold: [0.41050254 0.42656896 0.41389079 0.40686851]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4762271688180734\n",
      "AUROCperdrug: 0.8033501010441805\n",
      "AUPR+AUROCperdrug: 1.2795772698622538\n",
      "AUPR: 0.42615377732057325\n",
      "AUROC: 0.7736664572884049\n",
      "AUPR+AUROC: 1.1998202346089781\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.4659200356444263, std: 0.0052882660065541\n",
      "Mean AUROCperdrug: 0.8088413976251341, std: 0.00428741472112533\n",
      "Mean AUPR+AUROCperdrug: 1.2747614332695603, std: 0.004999360393805193\n",
      "Mean AUPR: 0.4167116475079359, std: 0.006467947990326399\n",
      "Mean AUROC: 0.7751296675517192, std: 0.004580091819646905\n",
      "Mean AUPR+AUROC: 1.191841315059655, std: 0.009732556267024486\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5075670303842815\n",
      "AUROCperdrug: 0.8309149104773084\n",
      "AUPR+AUROCperdrug: 1.3384819408615898\n",
      "AUPR: 0.48291663472612845\n",
      "AUROC: 0.804835024077732\n",
      "AUPR+AUROC: 1.2877516588038604\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5127521031469403\n",
      "AUROCperdrug: 0.8389820097464156\n",
      "AUPR+AUROCperdrug: 1.351734112893356\n",
      "AUPR: 0.4697412304159925\n",
      "AUROC: 0.7951963948398324\n",
      "AUPR+AUROC: 1.2649376252558249\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.511918296965952\n",
      "AUROCperdrug: 0.8335278227128705\n",
      "AUPR+AUROCperdrug: 1.3454461196788225\n",
      "AUPR: 0.49926931493274057\n",
      "AUROC: 0.8130041443857965\n",
      "AUPR+AUROC: 1.312273459318537\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5066960829965064\n",
      "AUROCperdrug: 0.8301682598657406\n",
      "AUPR+AUROCperdrug: 1.3368643428622469\n",
      "AUPR: 0.47992494429669497\n",
      "AUROC: 0.7888669839961225\n",
      "AUPR+AUROC: 1.2687919282928175\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5191853782590227\n",
      "AUROCperdrug: 0.831888296918541\n",
      "AUPR+AUROCperdrug: 1.3510736751775636\n",
      "AUPR: 0.5001579139515238\n",
      "AUROC: 0.798771457769341\n",
      "AUPR+AUROC: 1.2989293717208648\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5116237783505405, std: 0.00445594068185087\n",
      "Mean AUROCperdrug: 0.8330962599441751, std: 0.0031502044944767926\n",
      "Mean AUPR+AUROCperdrug: 1.3447200382947155, std: 0.006176065877297724\n",
      "Mean AUPR: 0.48640200766461594, std: 0.011717288312806653\n",
      "Mean AUROC: 0.8001348010137649, std: 0.008257388889500401\n",
      "Mean AUPR+AUROC: 1.286536808678381, std: 0.017882014261161597\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4214862389921199\n",
      "AUPR for each fold: [0.43746877 0.43408549 0.40320948 0.41118122]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4665862143621464\n",
      "AUROCperdrug: 0.8013410729950782\n",
      "AUPR+AUROCperdrug: 1.2679272873572245\n",
      "AUPR: 0.42495190282929934\n",
      "AUROC: 0.7742474553870605\n",
      "AUPR+AUROC: 1.1991993582163598\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.42298240217927\n",
      "AUPR for each fold: [0.44311571 0.43505201 0.39975508 0.41400681]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4700496707531618\n",
      "AUROCperdrug: 0.8118350312263111\n",
      "AUPR+AUROCperdrug: 1.2818847019794728\n",
      "AUPR: 0.41596774620999233\n",
      "AUROC: 0.7681587645507167\n",
      "AUPR+AUROC: 1.184126510760709\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4213515896820861\n",
      "AUPR for each fold: [0.4295593  0.43553068 0.3995358  0.42078057]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.46888918708917837\n",
      "AUROCperdrug: 0.8056983967518515\n",
      "AUPR+AUROCperdrug: 1.2745875838410299\n",
      "AUPR: 0.4233936056016816\n",
      "AUROC: 0.7753632138155101\n",
      "AUPR+AUROC: 1.1987568194171918\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.42388777478274975\n",
      "AUPR for each fold: [0.42881102 0.42335806 0.42172798 0.42165404]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4664813677994096\n",
      "AUROCperdrug: 0.8067116560595192\n",
      "AUPR+AUROCperdrug: 1.2731930238589289\n",
      "AUPR: 0.41287566039142015\n",
      "AUROC: 0.7612515548788853\n",
      "AUPR+AUROC: 1.1741272152703055\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.419381479620071\n",
      "AUPR for each fold: [0.41506841 0.43116649 0.41931662 0.41197439]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4811426028038458\n",
      "AUROCperdrug: 0.8000139353400838\n",
      "AUPR+AUROCperdrug: 1.2811565381439296\n",
      "AUPR: 0.4314586546962005\n",
      "AUROC: 0.7684935583174884\n",
      "AUPR+AUROC: 1.199952213013689\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.4706298085615484, std: 0.00543038452734406\n",
      "Mean AUROCperdrug: 0.8051200184745687, std: 0.004202659676984453\n",
      "Mean AUPR+AUROCperdrug: 1.2757498270361172, std: 0.00521439151451466\n",
      "Mean AUPR: 0.4217295139457187, std: 0.006624165775410171\n",
      "Mean AUROC: 0.7695029093899322, std: 0.005054982707834347\n",
      "Mean AUPR+AUROC: 1.191232423335651, std: 0.010384656530632669\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5142691138243616\n",
      "AUROCperdrug: 0.8290001591236794\n",
      "AUPR+AUROCperdrug: 1.3432692729480409\n",
      "AUPR: 0.4898816147094466\n",
      "AUROC: 0.8014722315050493\n",
      "AUPR+AUROC: 1.2913538462144958\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5178770388630144\n",
      "AUROCperdrug: 0.8350916909528429\n",
      "AUPR+AUROCperdrug: 1.3529687298158573\n",
      "AUPR: 0.4760741750697848\n",
      "AUROC: 0.7914499884153969\n",
      "AUPR+AUROC: 1.2675241634851817\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5176554823402301\n",
      "AUROCperdrug: 0.830137914376536\n",
      "AUPR+AUROCperdrug: 1.347793396716766\n",
      "AUPR: 0.504962725814169\n",
      "AUROC: 0.8084129378505861\n",
      "AUPR+AUROC: 1.313375663664755\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5114497722608511\n",
      "AUROCperdrug: 0.82722489896115\n",
      "AUPR+AUROCperdrug: 1.3386746712220012\n",
      "AUPR: 0.48566305680173727\n",
      "AUROC: 0.784517056783191\n",
      "AUPR+AUROC: 1.2701801135849282\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5244154433463442\n",
      "AUROCperdrug: 0.8279610740792833\n",
      "AUPR+AUROCperdrug: 1.3523765174256275\n",
      "AUPR: 0.5061749445422888\n",
      "AUROC: 0.7945902502904088\n",
      "AUPR+AUROC: 1.3007651948326977\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5171333701269603, std: 0.004344225675429743\n",
      "Mean AUROCperdrug: 0.8298831474986983, std: 0.0027833128125732774\n",
      "Mean AUPR+AUROCperdrug: 1.3470165176256585, std: 0.005447755740323921\n",
      "Mean AUPR: 0.49255130338748526, std: 0.011538786255322784\n",
      "Mean AUROC: 0.7960884929689264, std: 0.008228428443922887\n",
      "Mean AUPR+AUROC: 1.2886397963564116, std: 0.01762319111803098\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.42696988476771763\n",
      "AUPR for each fold: [0.44343407 0.43951075 0.40837208 0.41656264]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4730802034378151\n",
      "AUROCperdrug: 0.80044502473317\n",
      "AUPR+AUROCperdrug: 1.273525228170985\n",
      "AUPR: 0.4309230836028315\n",
      "AUROC: 0.7692718454973256\n",
      "AUPR+AUROC: 1.200194929100157\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.42853377647913576\n",
      "AUPR for each fold: [0.44887632 0.44052846 0.40518232 0.41954801]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.47516508489630194\n",
      "AUROCperdrug: 0.8072972229167826\n",
      "AUPR+AUROCperdrug: 1.2824623078130846\n",
      "AUPR: 0.42173616630050476\n",
      "AUROC: 0.7623423438873915\n",
      "AUPR+AUROC: 1.1840785101878963\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.42698299497079245\n",
      "AUPR for each fold: [0.43532872 0.44132624 0.40511554 0.42616149]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4746750219844128\n",
      "AUROCperdrug: 0.8015756899725329\n",
      "AUPR+AUROCperdrug: 1.2762507119569457\n",
      "AUPR: 0.42878950673908744\n",
      "AUROC: 0.7687632400506803\n",
      "AUPR+AUROC: 1.1975527467897678\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.42959011392310764\n",
      "AUPR for each fold: [0.43460735 0.42885189 0.42765181 0.42724941]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4719006286063931\n",
      "AUROCperdrug: 0.8036449917105717\n",
      "AUPR+AUROCperdrug: 1.2755456203169648\n",
      "AUPR: 0.41807799325250095\n",
      "AUROC: 0.7535558084271061\n",
      "AUPR+AUROC: 1.171633801679607\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4249388815553653\n",
      "AUPR for each fold: [0.42040993 0.43640549 0.42570204 0.41723807]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4867140736177131\n",
      "AUROCperdrug: 0.797416253558221\n",
      "AUPR+AUROCperdrug: 1.2841303271759341\n",
      "AUPR: 0.4371345761665015\n",
      "AUROC: 0.7620890654211309\n",
      "AUPR+AUROC: 1.1992236415876323\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.47630700250852726, std: 0.0053310942318441235\n",
      "Mean AUROCperdrug: 0.8020758365782557, std: 0.0032968630832144914\n",
      "Mean AUPR+AUROCperdrug: 1.2783828390867829, std: 0.004144100497784359\n",
      "Mean AUPR: 0.4273322652122852, std: 0.006753676068046944\n",
      "Mean AUROC: 0.7632044606567269, std: 0.0057060849776058185\n",
      "Mean AUPR+AUROC: 1.190536725869012, std: 0.011108528584931426\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5188429765014767\n",
      "AUROCperdrug: 0.8255503390687676\n",
      "AUPR+AUROCperdrug: 1.3443933155702443\n",
      "AUPR: 0.4952914726206178\n",
      "AUROC: 0.7985073418096476\n",
      "AUPR+AUROC: 1.2937988144302652\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5219717510963574\n",
      "AUROCperdrug: 0.831797840240734\n",
      "AUPR+AUROCperdrug: 1.3537695913370915\n",
      "AUPR: 0.4818680288557902\n",
      "AUROC: 0.7898409781545409\n",
      "AUPR+AUROC: 1.2717090070103312\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5215241149322177\n",
      "AUROCperdrug: 0.8257935254033242\n",
      "AUPR+AUROCperdrug: 1.3473176403355418\n",
      "AUPR: 0.5096366421683849\n",
      "AUROC: 0.8045711113379134\n",
      "AUPR+AUROC: 1.3142077535062984\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5155622970984798\n",
      "AUROCperdrug: 0.8241020769835686\n",
      "AUPR+AUROCperdrug: 1.3396643740820484\n",
      "AUPR: 0.4908950241362505\n",
      "AUROC: 0.7817106289888087\n",
      "AUPR+AUROC: 1.2726056531250594\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5285467371249952\n",
      "AUROCperdrug: 0.8239627960215513\n",
      "AUPR+AUROCperdrug: 1.3525095331465464\n",
      "AUPR: 0.5113799381189947\n",
      "AUROC: 0.7915556029542262\n",
      "AUPR+AUROC: 1.302935541073221\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5212895753507054, std: 0.004288923680573694\n",
      "Mean AUROCperdrug: 0.8262413155435893, std: 0.002874749520825846\n",
      "Mean AUPR+AUROCperdrug: 1.3475308908942947, std: 0.005205385737159371\n",
      "Mean AUPR: 0.4978142211800076, std: 0.011245611693103365\n",
      "Mean AUROC: 0.7932371326490274, std: 0.007790454051090469\n",
      "Mean AUPR+AUROC: 1.2910513538290354, std: 0.016729444384910218\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.43180313561712236\n",
      "AUPR for each fold: [0.44893156 0.44463913 0.41279165 0.4208502 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.47745131228520715\n",
      "AUROCperdrug: 0.795884513937594\n",
      "AUPR+AUROCperdrug: 1.2733358262228012\n",
      "AUPR: 0.43574309038503\n",
      "AUROC: 0.7649580263749297\n",
      "AUPR+AUROC: 1.2007011167599597\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.433260115607521\n",
      "AUPR for each fold: [0.45387487 0.44527654 0.40944341 0.42444565]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.47941810455185363\n",
      "AUROCperdrug: 0.80287572956564\n",
      "AUPR+AUROCperdrug: 1.2822938341174936\n",
      "AUPR: 0.42712333090210897\n",
      "AUROC: 0.7593134076830637\n",
      "AUPR+AUROC: 1.1864367385851726\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4320067728161162\n",
      "AUPR for each fold: [0.44029793 0.44650496 0.40982987 0.43139433]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4784618588630706\n",
      "AUROCperdrug: 0.7955147084302865\n",
      "AUPR+AUROCperdrug: 1.273976567293357\n",
      "AUPR: 0.43294819044776794\n",
      "AUROC: 0.7625314971287049\n",
      "AUPR+AUROC: 1.1954796875764728\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.43441042000005614\n",
      "AUPR for each fold: [0.43935175 0.43368996 0.43242607 0.4321739 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4764302211877419\n",
      "AUROCperdrug: 0.8001399273401455\n",
      "AUPR+AUROCperdrug: 1.2765701485278873\n",
      "AUPR: 0.4230180082393776\n",
      "AUROC: 0.7489986922432547\n",
      "AUPR+AUROC: 1.1720167004826323\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4297706741501635\n",
      "AUPR for each fold: [0.42499763 0.44131277 0.4306955  0.42207681]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.49064236297584063\n",
      "AUROCperdrug: 0.7932074250036678\n",
      "AUPR+AUROCperdrug: 1.2838497879795083\n",
      "AUPR: 0.4420434756847681\n",
      "AUROC: 0.7574460226765259\n",
      "AUPR+AUROC: 1.199489498361294\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.4804807719727428, std: 0.0051777947345629525\n",
      "Mean AUROCperdrug: 0.7975244608554668, std: 0.00348832541459747\n",
      "Mean AUPR+AUROCperdrug: 1.2780052328282094, std: 0.004304506868908313\n",
      "Mean AUPR: 0.43217521913181056, std: 0.006634542385782501\n",
      "Mean AUROC: 0.7586495292212957, std: 0.0054753014193483635\n",
      "Mean AUPR+AUROC: 1.1908247483531063, std: 0.010651631792425434\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5249912784427253\n",
      "AUROCperdrug: 0.8270897727779426\n",
      "AUPR+AUROCperdrug: 1.3520810512206678\n",
      "AUPR: 0.5015211172323524\n",
      "AUROC: 0.7955828740447346\n",
      "AUPR+AUROC: 1.297103991277087\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5263685364196188\n",
      "AUROCperdrug: 0.8279765826693459\n",
      "AUPR+AUROCperdrug: 1.3543451190889648\n",
      "AUPR: 0.4876679802729162\n",
      "AUROC: 0.7863816840516348\n",
      "AUPR+AUROC: 1.274049664324551\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5267124800250998\n",
      "AUROCperdrug: 0.8229597852318623\n",
      "AUPR+AUROCperdrug: 1.3496722652569622\n",
      "AUPR: 0.5153616988678769\n",
      "AUROC: 0.8013798604102891\n",
      "AUPR+AUROC: 1.316741559278166\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5198147366569813\n",
      "AUROCperdrug: 0.8198881008195611\n",
      "AUPR+AUROCperdrug: 1.3397028374765423\n",
      "AUPR: 0.4966971635144696\n",
      "AUROC: 0.7780714210309416\n",
      "AUPR+AUROC: 1.274768584545411\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5339569430836956\n",
      "AUROCperdrug: 0.8207644566975401\n",
      "AUPR+AUROCperdrug: 1.3547213997812357\n",
      "AUPR: 0.5174258946387545\n",
      "AUROC: 0.7887340104947841\n",
      "AUPR+AUROC: 1.3061599051335386\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5263687949256242, std: 0.0045288264138227535\n",
      "Mean AUROCperdrug: 0.8237357396392504, std: 0.0032701449493922827\n",
      "Mean AUPR+AUROCperdrug: 1.3501045345648746, std: 0.005506119844220807\n",
      "Mean AUPR: 0.5037347709052739, std: 0.011271222334137463\n",
      "Mean AUROC: 0.7900299700064768, std: 0.007970585304746041\n",
      "Mean AUPR+AUROC: 1.2937647409117505, std: 0.01698389279796776\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4369227804737358\n",
      "AUPR for each fold: [0.45424792 0.44990022 0.41787423 0.42566876]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.483212337560677\n",
      "AUROCperdrug: 0.79796523090422\n",
      "AUPR+AUROCperdrug: 1.281177568464897\n",
      "AUPR: 0.44104692661556316\n",
      "AUROC: 0.7602288339183526\n",
      "AUPR+AUROC: 1.2012757605339157\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.43845343600276565\n",
      "AUPR for each fold: [0.45931721 0.45058359 0.41442883 0.42948411]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.48355569076400506\n",
      "AUROCperdrug: 0.7970459010834193\n",
      "AUPR+AUROCperdrug: 1.2806015918474243\n",
      "AUPR: 0.4321523308866379\n",
      "AUROC: 0.7535264575072695\n",
      "AUPR+AUROC: 1.1856787883939075\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.43715762955090953\n",
      "AUPR for each fold: [0.44550296 0.45197989 0.41496638 0.4361813 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4832286141834472\n",
      "AUROCperdrug: 0.7919058022986464\n",
      "AUPR+AUROCperdrug: 1.2751344164820937\n",
      "AUPR: 0.43811557720049\n",
      "AUROC: 0.7571667030493111\n",
      "AUPR+AUROC: 1.195282280249801\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4396499664652283\n",
      "AUPR for each fold: [0.44454636 0.43902092 0.43793109 0.43710149]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4807516666569671\n",
      "AUROCperdrug: 0.794097897394373\n",
      "AUPR+AUROCperdrug: 1.27484956405134\n",
      "AUPR: 0.42779756229126686\n",
      "AUROC: 0.742117292867583\n",
      "AUPR+AUROC: 1.1699148551588499\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4348131374486279\n",
      "AUPR for each fold: [0.43006734 0.4461039  0.43614044 0.42694087]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4957788745495956\n",
      "AUROCperdrug: 0.7910490628889763\n",
      "AUPR+AUROCperdrug: 1.2868279374385718\n",
      "AUPR: 0.44758369159615946\n",
      "AUROC: 0.7526765967865714\n",
      "AUPR+AUROC: 1.200260288382731\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.4853054367429384, std: 0.005332646408810399\n",
      "Mean AUROCperdrug: 0.794412778913927, std: 0.0027295389764661615\n",
      "Mean AUPR+AUROCperdrug: 1.2797182156568652, std: 0.004431098989105292\n",
      "Mean AUPR: 0.4373392177180235, std: 0.006888338952741453\n",
      "Mean AUROC: 0.7531431768258174, std: 0.006137263523401683\n",
      "Mean AUPR+AUROC: 1.190482394543841, std: 0.011672541869767902\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5296879036820221\n",
      "AUROCperdrug: 0.8249158142102165\n",
      "AUPR+AUROCperdrug: 1.3546037178922385\n",
      "AUPR: 0.5072943712914495\n",
      "AUROC: 0.793803639344175\n",
      "AUPR+AUROC: 1.3010980106356245\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5308939368771873\n",
      "AUROCperdrug: 0.825363969182162\n",
      "AUPR+AUROCperdrug: 1.3562579060593494\n",
      "AUPR: 0.49255718023860456\n",
      "AUROC: 0.782895228805802\n",
      "AUPR+AUROC: 1.2754524090444066\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.531730027866644\n",
      "AUROCperdrug: 0.8209505975170623\n",
      "AUPR+AUROCperdrug: 1.3526806253837065\n",
      "AUPR: 0.5204748773203278\n",
      "AUROC: 0.7986785160322328\n",
      "AUPR+AUROC: 1.3191533933525608\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5240888216946052\n",
      "AUROCperdrug: 0.8165257377212044\n",
      "AUPR+AUROCperdrug: 1.3406145594158096\n",
      "AUPR: 0.5015443630365273\n",
      "AUROC: 0.7747985065215093\n",
      "AUPR+AUROC: 1.2763428695580366\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.538475557910275\n",
      "AUROCperdrug: 0.8174321018762831\n",
      "AUPR+AUROCperdrug: 1.355907659786558\n",
      "AUPR: 0.5222477039355703\n",
      "AUROC: 0.7852872682190257\n",
      "AUPR+AUROC: 1.307534972154596\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5309752496061467, std: 0.004602414052399105\n",
      "Mean AUROCperdrug: 0.8210376441013857, std: 0.0036639351284089095\n",
      "Mean AUPR+AUROCperdrug: 1.3520128937075324, std: 0.005835573542518244\n",
      "Mean AUPR: 0.5088236991644959, std: 0.011277243215310822\n",
      "Mean AUROC: 0.7870926317845489, std: 0.008382044877225487\n",
      "Mean AUPR+AUROC: 1.295916330949045, std: 0.017341834894421985\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4414788930870088\n",
      "AUPR for each fold: [0.45873342 0.45447    0.42256772 0.43014443]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4878923468931479\n",
      "AUROCperdrug: 0.7949968390541817\n",
      "AUPR+AUROCperdrug: 1.2828891859473297\n",
      "AUPR: 0.4460914983458746\n",
      "AUROC: 0.7573833234360348\n",
      "AUPR+AUROC: 1.2034748217819093\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.44315547110051634\n",
      "AUPR for each fold: [0.46386537 0.45515198 0.41922619 0.43437835]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4879705804673237\n",
      "AUROCperdrug: 0.7934916739842259\n",
      "AUPR+AUROCperdrug: 1.2814622544515497\n",
      "AUPR: 0.43668446235629177\n",
      "AUROC: 0.7489413154251523\n",
      "AUPR+AUROC: 1.185625777781444\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.44185284814799347\n",
      "AUPR for each fold: [0.45009406 0.45659765 0.41956976 0.44114993]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4878088907510525\n",
      "AUROCperdrug: 0.7899254554999707\n",
      "AUPR+AUROCperdrug: 1.2777343462510231\n",
      "AUPR: 0.4426723764706124\n",
      "AUROC: 0.7527151716867554\n",
      "AUPR+AUROC: 1.1953875481573677\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4443495888175838\n",
      "AUPR for each fold: [0.44904215 0.44356013 0.4427258  0.44207028]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4849011995207213\n",
      "AUROCperdrug: 0.7896030119765168\n",
      "AUPR+AUROCperdrug: 1.2745042114972382\n",
      "AUPR: 0.4323197372216576\n",
      "AUROC: 0.7372310843687195\n",
      "AUPR+AUROC: 1.1695508215903772\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4394807085448403\n",
      "AUPR for each fold: [0.43442479 0.45065383 0.44091928 0.43192494]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.50024664514595\n",
      "AUROCperdrug: 0.7871385711429589\n",
      "AUPR+AUROCperdrug: 1.287385216288909\n",
      "AUPR: 0.45217246690354984\n",
      "AUROC: 0.7479525796245822\n",
      "AUPR+AUROC: 1.200125046528132\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.48976393255563905, std: 0.005367952475242896\n",
      "Mean AUROCperdrug: 0.7910311103315708, std: 0.00283531926397492\n",
      "Mean AUPR+AUROCperdrug: 1.2807950428872101, std: 0.004409158998451221\n",
      "Mean AUPR: 0.4419881082595973, std: 0.006966107271185762\n",
      "Mean AUROC: 0.7488446949082489, std: 0.006686851614863045\n",
      "Mean AUPR+AUROC: 1.1908328031678461, std: 0.01222250364256875\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5333090947450388\n",
      "AUROCperdrug: 0.8214815518884498\n",
      "AUPR+AUROCperdrug: 1.3547906466334887\n",
      "AUPR: 0.5121210293923751\n",
      "AUROC: 0.791016770075747\n",
      "AUPR+AUROC: 1.3031377994681221\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5349494838764347\n",
      "AUROCperdrug: 0.8227371558417832\n",
      "AUPR+AUROCperdrug: 1.357686639718218\n",
      "AUPR: 0.49740544123495445\n",
      "AUROC: 0.7804024834811802\n",
      "AUPR+AUROC: 1.2778079247161347\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5359751637499367\n",
      "AUROCperdrug: 0.818469235077288\n",
      "AUPR+AUROCperdrug: 1.3544443988272246\n",
      "AUPR: 0.5251773642562496\n",
      "AUROC: 0.7962655544456616\n",
      "AUPR+AUROC: 1.3214429187019112\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5278667248469558\n",
      "AUROCperdrug: 0.8130043416837603\n",
      "AUPR+AUROCperdrug: 1.3408710665307162\n",
      "AUPR: 0.5056943852966387\n",
      "AUROC: 0.7718139178762611\n",
      "AUPR+AUROC: 1.2775083031728998\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5423050693302494\n",
      "AUROCperdrug: 0.8137707611589682\n",
      "AUPR+AUROCperdrug: 1.3560758304892175\n",
      "AUPR: 0.5267432004567076\n",
      "AUROC: 0.7821260441061724\n",
      "AUPR+AUROC: 1.30886924456288\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.534881107309723, std: 0.004647356921282598\n",
      "Mean AUROCperdrug: 0.8178926091300498, std: 0.003938716282532425\n",
      "Mean AUPR+AUROCperdrug: 1.3527737164397728, std: 0.006059257945310757\n",
      "Mean AUPR: 0.5134282841273852, std: 0.011256833312733036\n",
      "Mean AUROC: 0.7843249539970045, std: 0.008533526187646506\n",
      "Mean AUPR+AUROC: 1.2977532381243895, std: 0.017443812564995945\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4460673799084919\n",
      "AUPR for each fold: [0.46346248 0.45908221 0.42689951 0.43482531]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4915310219598903\n",
      "AUROCperdrug: 0.7905992890997762\n",
      "AUPR+AUROCperdrug: 1.2821303110596665\n",
      "AUPR: 0.4504170743337498\n",
      "AUROC: 0.753259457255215\n",
      "AUPR+AUROC: 1.2036765315889648\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.44763451646989205\n",
      "AUPR for each fold: [0.468193   0.45973947 0.42359608 0.43900951]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4921756488549436\n",
      "AUROCperdrug: 0.790340270853045\n",
      "AUPR+AUROCperdrug: 1.2825159197079885\n",
      "AUPR: 0.44149539803837756\n",
      "AUROC: 0.7459627451856864\n",
      "AUPR+AUROC: 1.187458143224064\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4463801115003772\n",
      "AUPR for each fold: [0.454243   0.4614576  0.42407661 0.44574324]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.49189644385295006\n",
      "AUROCperdrug: 0.7860311789577344\n",
      "AUPR+AUROCperdrug: 1.2779276228106844\n",
      "AUPR: 0.4472055044234672\n",
      "AUROC: 0.7489513270916048\n",
      "AUPR+AUROC: 1.1961568315150721\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4488930427439607\n",
      "AUPR for each fold: [0.45340737 0.44819    0.4473532  0.4466216 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.48872647092614896\n",
      "AUROCperdrug: 0.7850653356083427\n",
      "AUPR+AUROCperdrug: 1.2737918065344918\n",
      "AUPR: 0.4368208625561631\n",
      "AUROC: 0.7331003008760002\n",
      "AUPR+AUROC: 1.1699211634321633\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.44404464187575465\n",
      "AUPR for each fold: [0.43882028 0.45515422 0.4460023  0.43620177]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5041630733160757\n",
      "AUROCperdrug: 0.7819905554940151\n",
      "AUPR+AUROCperdrug: 1.2861536288100908\n",
      "AUPR: 0.4565932341883159\n",
      "AUROC: 0.7434160326137178\n",
      "AUPR+AUROC: 1.2000092668020337\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.49369853178200174, std: 0.005375738290042973\n",
      "Mean AUROCperdrug: 0.7868053260025827, std: 0.0032771596344378265\n",
      "Mean AUPR+AUROCperdrug: 1.2805038577845844, std: 0.004249759398010783\n",
      "Mean AUPR: 0.4465064147080147, std: 0.006876716090059379\n",
      "Mean AUROC: 0.7449379726044448, std: 0.006765368477203108\n",
      "Mean AUPR+AUROC: 1.1914443873124596, std: 0.012036020544752536\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.535790528980605\n",
      "AUROCperdrug: 0.8181281336454307\n",
      "AUPR+AUROCperdrug: 1.3539186626260356\n",
      "AUPR: 0.5157779133022384\n",
      "AUROC: 0.7886512207141478\n",
      "AUPR+AUROC: 1.3044291340163863\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5377276415913864\n",
      "AUROCperdrug: 0.8202895617045961\n",
      "AUPR+AUROCperdrug: 1.3580172032959825\n",
      "AUPR: 0.500900504274198\n",
      "AUROC: 0.778298451270853\n",
      "AUPR+AUROC: 1.279198955545051\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5386828611731804\n",
      "AUROCperdrug: 0.8157508053529628\n",
      "AUPR+AUROCperdrug: 1.3544336665261434\n",
      "AUPR: 0.5279549276338713\n",
      "AUROC: 0.7935434745138762\n",
      "AUPR+AUROC: 1.3214984021477476\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5302606641575855\n",
      "AUROCperdrug: 0.8095578180561382\n",
      "AUPR+AUROCperdrug: 1.3398184822137238\n",
      "AUPR: 0.5086990656256011\n",
      "AUROC: 0.7693195229167133\n",
      "AUPR+AUROC: 1.2780185885423143\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.544614123615411\n",
      "AUROCperdrug: 0.810132593376237\n",
      "AUPR+AUROCperdrug: 1.3547467169916478\n",
      "AUPR: 0.5292150347187661\n",
      "AUROC: 0.7782904863421688\n",
      "AUPR+AUROC: 1.3075055210609348\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5374151639036338, std: 0.004633703159540523\n",
      "Mean AUROCperdrug: 0.814771782427073, std: 0.00427497291351948\n",
      "Mean AUPR+AUROCperdrug: 1.3521869463307068, std: 0.006349327833636354\n",
      "Mean AUPR: 0.516509489110935, std: 0.010932586866726487\n",
      "Mean AUROC: 0.7816206311515519, std: 0.008544324325031187\n",
      "Mean AUPR+AUROC: 1.2981301202624869, std: 0.016950014857589683\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.44985424542056374\n",
      "AUPR for each fold: [0.46726349 0.46370812 0.43029659 0.43814878]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4943259453378217\n",
      "AUROCperdrug: 0.78675177926929\n",
      "AUPR+AUROCperdrug: 1.2810777246071117\n",
      "AUPR: 0.454051315727631\n",
      "AUROC: 0.7505577756330273\n",
      "AUPR+AUROC: 1.2046090913606582\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4513336318823506\n",
      "AUPR for each fold: [0.47174409 0.46424667 0.42693333 0.44241044]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.49522485236955466\n",
      "AUROCperdrug: 0.7873789924645825\n",
      "AUPR+AUROCperdrug: 1.2826038448341373\n",
      "AUPR: 0.44550347516805194\n",
      "AUROC: 0.7441890518588004\n",
      "AUPR+AUROC: 1.1896925270268524\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4500951382147156\n",
      "AUPR for each fold: [0.45756927 0.46611658 0.42763241 0.44906229]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4949042548124869\n",
      "AUROCperdrug: 0.782567377953081\n",
      "AUPR+AUROCperdrug: 1.2774716327655677\n",
      "AUPR: 0.4510959646366448\n",
      "AUROC: 0.7468165397715747\n",
      "AUPR+AUROC: 1.1979125044082195\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4526074932116663\n",
      "AUPR for each fold: [0.45686558 0.45253425 0.4511323  0.44989784]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.49165977993993276\n",
      "AUROCperdrug: 0.781504540594028\n",
      "AUPR+AUROCperdrug: 1.2731643205339607\n",
      "AUPR: 0.44065021586057335\n",
      "AUROC: 0.7306508708094843\n",
      "AUPR+AUROC: 1.1713010866700577\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4479042593423726\n",
      "AUPR for each fold: [0.44240493 0.45928238 0.45019783 0.4397319 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5069493974466206\n",
      "AUROCperdrug: 0.777521272999406\n",
      "AUPR+AUROCperdrug: 1.2844706704460265\n",
      "AUPR: 0.46000497765269033\n",
      "AUROC: 0.7396007337181254\n",
      "AUPR+AUROC: 1.1996057113708156\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.49661284598128325, std: 0.005318888681047952\n",
      "Mean AUROCperdrug: 0.7831447926560775, std: 0.0036217843210633966\n",
      "Mean AUPR+AUROCperdrug: 1.2797576386373606, std: 0.004018802109337867\n",
      "Mean AUPR: 0.4502611898091183, std: 0.006708352612628868\n",
      "Mean AUROC: 0.7423629943582023, std: 0.00685750559242696\n",
      "Mean AUPR+AUROC: 1.1926241841673206, std: 0.011692862386630521\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5390751885405651\n",
      "AUROCperdrug: 0.8156582854630888\n",
      "AUPR+AUROCperdrug: 1.354733474003654\n",
      "AUPR: 0.5197467829767333\n",
      "AUROC: 0.7863101554473808\n",
      "AUPR+AUROC: 1.306056938424114\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5406847638316069\n",
      "AUROCperdrug: 0.817463737645792\n",
      "AUPR+AUROCperdrug: 1.358148501477399\n",
      "AUPR: 0.5046313689456197\n",
      "AUROC: 0.7760045691902491\n",
      "AUPR+AUROC: 1.2806359381358687\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.542336149771184\n",
      "AUROCperdrug: 0.8142171215360525\n",
      "AUPR+AUROCperdrug: 1.3565532713072366\n",
      "AUPR: 0.5318525499424531\n",
      "AUROC: 0.791817611219428\n",
      "AUPR+AUROC: 1.323670161161881\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5335753599474673\n",
      "AUROCperdrug: 0.8074171788964746\n",
      "AUPR+AUROCperdrug: 1.3409925388439419\n",
      "AUPR: 0.5123990722083049\n",
      "AUROC: 0.767309173057245\n",
      "AUPR+AUROC: 1.27970824526555\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5481504162543959\n",
      "AUROCperdrug: 0.8081865767097376\n",
      "AUPR+AUROCperdrug: 1.3563369929641333\n",
      "AUPR: 0.5330921954179226\n",
      "AUROC: 0.7763237842278812\n",
      "AUPR+AUROC: 1.3094159796458038\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5407643756690439, std: 0.004723678812141632\n",
      "Mean AUROCperdrug: 0.812588580050229, std: 0.004048788055137376\n",
      "Mean AUPR+AUROCperdrug: 1.353352955719273, std: 0.006274224945362388\n",
      "Mean AUPR: 0.5203443938982067, std: 0.01100298621152374\n",
      "Mean AUROC: 0.7795530586284368, std: 0.008590812906881672\n",
      "Mean AUPR+AUROC: 1.2998974525266438, std: 0.017159797943755894\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.45367005557376805\n",
      "AUPR for each fold: [0.47114494 0.46782435 0.4336527  0.44205823]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4974066370100733\n",
      "AUROCperdrug: 0.783285584811749\n",
      "AUPR+AUROCperdrug: 1.2806922218218224\n",
      "AUPR: 0.45749241952209896\n",
      "AUROC: 0.7471573820514397\n",
      "AUPR+AUROC: 1.2046498015735385\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.45509437985923124\n",
      "AUPR for each fold: [0.47551977 0.46834917 0.43023385 0.44627473]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4980894517782815\n",
      "AUROCperdrug: 0.7843611368923372\n",
      "AUPR+AUROCperdrug: 1.2824505886706188\n",
      "AUPR: 0.44912301686021994\n",
      "AUROC: 0.7411715030681838\n",
      "AUPR+AUROC: 1.1902945199284036\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.45379348920315166\n",
      "AUPR for each fold: [0.46105901 0.47006796 0.43113827 0.45290871]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4985808819929765\n",
      "AUROCperdrug: 0.7803923837956617\n",
      "AUPR+AUROCperdrug: 1.2789732657886381\n",
      "AUPR: 0.45498747666487965\n",
      "AUROC: 0.7445647661062659\n",
      "AUPR+AUROC: 1.1995522427711456\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.456308248271145\n",
      "AUPR for each fold: [0.46058047 0.45612953 0.45500733 0.45351566]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4952553177768412\n",
      "AUROCperdrug: 0.7794809579169513\n",
      "AUPR+AUROCperdrug: 1.2747362756937926\n",
      "AUPR: 0.444498821878175\n",
      "AUROC: 0.7280827899753806\n",
      "AUPR+AUROC: 1.1725816118535555\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4516256954739414\n",
      "AUPR for each fold: [0.44615755 0.46289547 0.45418823 0.44326153]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5102956781391064\n",
      "AUROCperdrug: 0.7752764709197962\n",
      "AUPR+AUROCperdrug: 1.2855721490589027\n",
      "AUPR: 0.46379345567363855\n",
      "AUROC: 0.7366529601620342\n",
      "AUPR+AUROC: 1.2004464158356727\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.4999255933394558, std: 0.005308011642980013\n",
      "Mean AUROCperdrug: 0.7805593068672991, std: 0.0031932916681213183\n",
      "Mean AUPR+AUROCperdrug: 1.2804849002067549, std: 0.0036088429358393484\n",
      "Mean AUPR: 0.45397903811980245, std: 0.0066804046518123515\n",
      "Mean AUROC: 0.7395258802726608, std: 0.006716193114294851\n",
      "Mean AUPR+AUROC: 1.1935049183924633, std: 0.011463458071926119\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.542379125689178\n",
      "AUROCperdrug: 0.8126636058933763\n",
      "AUPR+AUROCperdrug: 1.3550427315825542\n",
      "AUPR: 0.5240579145881882\n",
      "AUROC: 0.7837936224046632\n",
      "AUPR+AUROC: 1.3078515369928514\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5443097062166912\n",
      "AUROCperdrug: 0.8146558211564686\n",
      "AUPR+AUROCperdrug: 1.3589655273731598\n",
      "AUPR: 0.5087810570295718\n",
      "AUROC: 0.7737030049436118\n",
      "AUPR+AUROC: 1.2824840619731837\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.546117728240331\n",
      "AUROCperdrug: 0.8119075710712585\n",
      "AUPR+AUROCperdrug: 1.3580252993115896\n",
      "AUPR: 0.5356855383783812\n",
      "AUROC: 0.7892954319355099\n",
      "AUPR+AUROC: 1.324980970313891\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5378773471574182\n",
      "AUROCperdrug: 0.805636894347485\n",
      "AUPR+AUROCperdrug: 1.343514241504903\n",
      "AUPR: 0.5170181821797167\n",
      "AUROC: 0.7658823246860876\n",
      "AUPR+AUROC: 1.2829005068658044\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5521721862453425\n",
      "AUROCperdrug: 0.8059803910443012\n",
      "AUPR+AUROCperdrug: 1.3581525772896437\n",
      "AUPR: 0.5375235244616045\n",
      "AUROC: 0.7746397827800162\n",
      "AUPR+AUROC: 1.3121633072416206\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5445712187097922, std: 0.004687173480025931\n",
      "Mean AUROCperdrug: 0.8101688567025779, std: 0.0036731914883345583\n",
      "Mean AUPR+AUROCperdrug: 1.35474007541237, std: 0.005768938499910133\n",
      "Mean AUPR: 0.5246132433274925, std: 0.010935470209140163\n",
      "Mean AUROC: 0.7774628333499777, std: 0.008201260688718206\n",
      "Mean AUPR+AUROC: 1.3020760766774702, std: 0.016800546613605614\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.45803864747351974\n",
      "AUPR for each fold: [0.47563549 0.4722228  0.43801606 0.44628023]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.500682547042063\n",
      "AUROCperdrug: 0.7789442903241951\n",
      "AUPR+AUROCperdrug: 1.279626837366258\n",
      "AUPR: 0.4612963993527667\n",
      "AUROC: 0.7432960397690247\n",
      "AUPR+AUROC: 1.2045924391217913\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.45935202651850565\n",
      "AUPR for each fold: [0.47977124 0.47275537 0.43428915 0.45059235]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.501956229743718\n",
      "AUROCperdrug: 0.7813949280497693\n",
      "AUPR+AUROCperdrug: 1.2833511577934873\n",
      "AUPR: 0.45343568633879316\n",
      "AUROC: 0.7386912397324787\n",
      "AUPR+AUROC: 1.192126926071272\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4580802528592877\n",
      "AUPR for each fold: [0.46526688 0.47426302 0.43530636 0.45748476]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5026729793432313\n",
      "AUROCperdrug: 0.7779775018561033\n",
      "AUPR+AUROCperdrug: 1.2806504811993347\n",
      "AUPR: 0.4592106640645479\n",
      "AUROC: 0.7418418875705308\n",
      "AUPR+AUROC: 1.2010525516350787\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.46059035687504657\n",
      "AUPR for each fold: [0.46470846 0.46041511 0.45939633 0.45784152]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.4993122541094136\n",
      "AUROCperdrug: 0.7772045614054047\n",
      "AUPR+AUROCperdrug: 1.2765168155148183\n",
      "AUPR: 0.44875067330210694\n",
      "AUROC: 0.7253557021372081\n",
      "AUPR+AUROC: 1.174106375439315\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4557583475378314\n",
      "AUPR for each fold: [0.44994242 0.467127   0.45848543 0.44747854]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5145470703631632\n",
      "AUROCperdrug: 0.7726998672593892\n",
      "AUPR+AUROCperdrug: 1.2872469376225524\n",
      "AUPR: 0.46851533244894994\n",
      "AUROC: 0.7349294885571208\n",
      "AUPR+AUROC: 1.2034448210060709\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5038342161203179, std: 0.0054776218949191885\n",
      "Mean AUROCperdrug: 0.7776442297789723, std: 0.0028463659013195485\n",
      "Mean AUPR+AUROCperdrug: 1.2814784458992903, std: 0.003619787352209961\n",
      "Mean AUPR: 0.4582417511014329, std: 0.006767495227468791\n",
      "Mean AUROC: 0.7368228715532725, std: 0.006413487378498987\n",
      "Mean AUPR+AUROC: 1.1950646226547057, std: 0.011355531621817001\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5466518178662623\n",
      "AUROCperdrug: 0.8104136809866618\n",
      "AUPR+AUROCperdrug: 1.357065498852924\n",
      "AUPR: 0.5287478681378174\n",
      "AUROC: 0.7809765971602133\n",
      "AUPR+AUROC: 1.3097244652980307\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5485788736024539\n",
      "AUROCperdrug: 0.8125920482059006\n",
      "AUPR+AUROCperdrug: 1.3611709218083545\n",
      "AUPR: 0.5136514199852487\n",
      "AUROC: 0.7716643109650577\n",
      "AUPR+AUROC: 1.2853157309503063\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5500576823872685\n",
      "AUROCperdrug: 0.8089345431744548\n",
      "AUPR+AUROCperdrug: 1.3589922255617233\n",
      "AUPR: 0.5399557115596727\n",
      "AUROC: 0.786496226299066\n",
      "AUPR+AUROC: 1.3264519378587387\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5415843383622153\n",
      "AUROCperdrug: 0.802890873075119\n",
      "AUPR+AUROCperdrug: 1.3444752114373344\n",
      "AUPR: 0.5215122873601636\n",
      "AUROC: 0.7636527844013032\n",
      "AUPR+AUROC: 1.2851650717614669\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5566613894072678\n",
      "AUROCperdrug: 0.8033638130102994\n",
      "AUPR+AUROCperdrug: 1.3600252024175672\n",
      "AUPR: 0.5419138170224238\n",
      "AUROC: 0.772126634971906\n",
      "AUPR+AUROC: 1.3140404519943298\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5487068203250935, std: 0.004900390849213341\n",
      "Mean AUROCperdrug: 0.8076389916904871, std: 0.0038660550000209357\n",
      "Mean AUPR+AUROCperdrug: 1.3563458120155807, std: 0.006086907427123661\n",
      "Mean AUPR: 0.5291562208130653, std: 0.010755283173186398\n",
      "Mean AUROC: 0.7749833107595092, std: 0.007950143267223308\n",
      "Mean AUPR+AUROC: 1.3041395315725743, std: 0.016379430876466827\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.46279477756734805\n",
      "AUPR for each fold: [0.48029334 0.477624   0.44253389 0.45072788]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5046922421019024\n",
      "AUROCperdrug: 0.7763557618463058\n",
      "AUPR+AUROCperdrug: 1.2810480039482082\n",
      "AUPR: 0.4654630531410419\n",
      "AUROC: 0.7387750288517902\n",
      "AUPR+AUROC: 1.2042380819928322\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.46391334295620407\n",
      "AUPR for each fold: [0.48403903 0.47812503 0.4385422  0.45494711]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5064326819388163\n",
      "AUROCperdrug: 0.7791114104631353\n",
      "AUPR+AUROCperdrug: 1.2855440924019517\n",
      "AUPR: 0.4583605069315302\n",
      "AUROC: 0.7363118260690601\n",
      "AUPR+AUROC: 1.1946723330005904\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.46278859881447587\n",
      "AUPR for each fold: [0.46958902 0.47957418 0.43976284 0.46222836]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5067809270381008\n",
      "AUROCperdrug: 0.774368831280366\n",
      "AUPR+AUROCperdrug: 1.2811497583184668\n",
      "AUPR: 0.46364091160219245\n",
      "AUROC: 0.7380167895487452\n",
      "AUPR+AUROC: 1.2016577011509377\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.46517999717289105\n",
      "AUPR for each fold: [0.4690175  0.46514782 0.46406881 0.46248586]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5036533210137488\n",
      "AUROCperdrug: 0.7750045274352734\n",
      "AUPR+AUROCperdrug: 1.278657848449022\n",
      "AUPR: 0.4535920874964012\n",
      "AUROC: 0.7225835012211036\n",
      "AUPR+AUROC: 1.1761755887175047\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4603624709326024\n",
      "AUPR for each fold: [0.45424866 0.47176397 0.46323454 0.45220271]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5187513812252185\n",
      "AUROCperdrug: 0.7715524678693526\n",
      "AUPR+AUROCperdrug: 1.290303849094571\n",
      "AUPR: 0.4733285614779009\n",
      "AUROC: 0.7317802702175618\n",
      "AUPR+AUROC: 1.2051088316954628\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5080621106635574, std: 0.005465352960068233\n",
      "Mean AUROCperdrug: 0.7752785997788866, std: 0.002475381555981177\n",
      "Mean AUPR+AUROCperdrug: 1.283340710442444, std: 0.004131008658328782\n",
      "Mean AUPR: 0.46287702412981335, std: 0.00668004010384234\n",
      "Mean AUROC: 0.7334934831816521, std: 0.005970944428265329\n",
      "Mean AUPR+AUROC: 1.1963705073114654, std: 0.010741787524521387\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5506565797099349\n",
      "AUROCperdrug: 0.8066537023589307\n",
      "AUPR+AUROCperdrug: 1.3573102820688656\n",
      "AUPR: 0.5344499961975644\n",
      "AUROC: 0.7785146216157335\n",
      "AUPR+AUROC: 1.3129646178132979\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5525041129646627\n",
      "AUROCperdrug: 0.8091146276596763\n",
      "AUPR+AUROCperdrug: 1.3616187406243392\n",
      "AUPR: 0.5185921868056718\n",
      "AUROC: 0.7688707632055204\n",
      "AUPR+AUROC: 1.287462950011192\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5551540072070874\n",
      "AUROCperdrug: 0.8072378159855197\n",
      "AUPR+AUROCperdrug: 1.362391823192607\n",
      "AUPR: 0.5446046403282614\n",
      "AUROC: 0.7839052303944449\n",
      "AUPR+AUROC: 1.3285098707227063\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5461423501230348\n",
      "AUROCperdrug: 0.8008822576280996\n",
      "AUPR+AUROCperdrug: 1.3470246077511345\n",
      "AUPR: 0.5263230844129805\n",
      "AUROC: 0.760965310187776\n",
      "AUPR+AUROC: 1.2872883946007565\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5606056645277555\n",
      "AUROCperdrug: 0.799008289975775\n",
      "AUPR+AUROCperdrug: 1.3596139545035304\n",
      "AUPR: 0.5463486321603789\n",
      "AUROC: 0.7683633431951891\n",
      "AUPR+AUROC: 1.3147119753555678\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.553012542906495, std: 0.0048010410907879456\n",
      "Mean AUROCperdrug: 0.8045793387216003, std: 0.003915209428747636\n",
      "Mean AUPR+AUROCperdrug: 1.3575918816280954, std: 0.005569387517750665\n",
      "Mean AUPR: 0.5340637079809714, std: 0.010596839681049205\n",
      "Mean AUROC: 0.7721238537197328, std: 0.008110238981749444\n",
      "Mean AUPR+AUROC: 1.3061875617007042, std: 0.016276788367371415\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.46802618064327833\n",
      "AUPR for each fold: [0.485958   0.48305995 0.44753179 0.45555498]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5087175346984617\n",
      "AUROCperdrug: 0.7716453626274509\n",
      "AUPR+AUROCperdrug: 1.2803628973259125\n",
      "AUPR: 0.4703875833156914\n",
      "AUROC: 0.7353454104772127\n",
      "AUPR+AUROC: 1.2057329937929042\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4691336630899918\n",
      "AUPR for each fold: [0.48938279 0.48353292 0.44337505 0.4602439 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5106206692768569\n",
      "AUROCperdrug: 0.7750624363770601\n",
      "AUPR+AUROCperdrug: 1.2856831056539169\n",
      "AUPR: 0.463411760643873\n",
      "AUROC: 0.7331976352478354\n",
      "AUPR+AUROC: 1.1966093958917083\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4678839079950285\n",
      "AUPR for each fold: [0.4743609  0.4848225  0.44519648 0.46715576]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.512017973920432\n",
      "AUROCperdrug: 0.7720172691653449\n",
      "AUPR+AUROCperdrug: 1.2840352430857769\n",
      "AUPR: 0.46911975732476136\n",
      "AUROC: 0.7360949487471528\n",
      "AUPR+AUROC: 1.205214706071914\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4702390340685017\n",
      "AUPR for each fold: [0.47390575 0.47013248 0.4696543  0.46726361]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5087412854174348\n",
      "AUROCperdrug: 0.7739457890721707\n",
      "AUPR+AUROCperdrug: 1.2826870744896055\n",
      "AUPR: 0.45910351240108366\n",
      "AUROC: 0.7207436639686763\n",
      "AUPR+AUROC: 1.17984717636976\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.46560201473909557\n",
      "AUPR for each fold: [0.4590252  0.47689435 0.46909518 0.45739333]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5228413827541746\n",
      "AUROCperdrug: 0.7662370654331785\n",
      "AUPR+AUROCperdrug: 1.289078448187353\n",
      "AUPR: 0.4783142695983666\n",
      "AUROC: 0.7279903103968158\n",
      "AUPR+AUROC: 1.2063045799951824\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.512587769213472, std: 0.005274559550768853\n",
      "Mean AUROCperdrug: 0.771781584535041, std: 0.0030418272735906614\n",
      "Mean AUPR+AUROCperdrug: 1.284369353748513, std: 0.002928989621318828\n",
      "Mean AUPR: 0.46806737665675524, std: 0.006534757865765515\n",
      "Mean AUROC: 0.7306743937675386, std: 0.0057164894618282535\n",
      "Mean AUPR+AUROC: 1.1987417704242938, std: 0.010094799595102465\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5545695167033687\n",
      "AUROCperdrug: 0.8058091118752605\n",
      "AUPR+AUROCperdrug: 1.3603786285786292\n",
      "AUPR: 0.5385605978086956\n",
      "AUROC: 0.777371232962693\n",
      "AUPR+AUROC: 1.3159318307713885\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5563895469323749\n",
      "AUROCperdrug: 0.8078845620447377\n",
      "AUPR+AUROCperdrug: 1.3642741089771127\n",
      "AUPR: 0.5220791700867617\n",
      "AUROC: 0.7666501291676526\n",
      "AUPR+AUROC: 1.2887292992544144\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5589353718855468\n",
      "AUROCperdrug: 0.8060583585722085\n",
      "AUPR+AUROCperdrug: 1.3649937304577553\n",
      "AUPR: 0.5483128027496131\n",
      "AUROC: 0.7817499465817297\n",
      "AUPR+AUROC: 1.3300627493313428\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5496769585093824\n",
      "AUROCperdrug: 0.7988251711559002\n",
      "AUPR+AUROCperdrug: 1.3485021296652826\n",
      "AUPR: 0.5300338401884956\n",
      "AUROC: 0.7590516599318757\n",
      "AUPR+AUROC: 1.2890855001203714\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5635906576836563\n",
      "AUROCperdrug: 0.7971337665386575\n",
      "AUPR+AUROCperdrug: 1.360724424222314\n",
      "AUPR: 0.5497613386308343\n",
      "AUROC: 0.7654421177757296\n",
      "AUPR+AUROC: 1.315203456406564\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5566324103428658, std: 0.004613321166678667\n",
      "Mean AUROCperdrug: 0.803142194037353, std: 0.004309162522626196\n",
      "Mean AUPR+AUROCperdrug: 1.3597746043802186, std: 0.005929932677430148\n",
      "Mean AUPR: 0.5377495498928802, std: 0.01059826549802\n",
      "Mean AUROC: 0.7700530172839362, std: 0.008297521812117637\n",
      "Mean AUPR+AUROC: 1.3078025671768163, std: 0.016312522465694364\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4718436604876878\n",
      "AUPR for each fold: [0.49014798 0.48695932 0.45104984 0.4592175 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.51326521623442\n",
      "AUROCperdrug: 0.771975702340782\n",
      "AUPR+AUROCperdrug: 1.285240918575202\n",
      "AUPR: 0.4748504504998082\n",
      "AUROC: 0.7349184273377691\n",
      "AUPR+AUROC: 1.2097688778375773\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4730746912572945\n",
      "AUPR for each fold: [0.49340936 0.48766554 0.44704518 0.46417869]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5148829106108784\n",
      "AUROCperdrug: 0.7751482358489232\n",
      "AUPR+AUROCperdrug: 1.2900311464598015\n",
      "AUPR: 0.46743803998625527\n",
      "AUROC: 0.7315147479244093\n",
      "AUPR+AUROC: 1.1989527879106645\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4718325753156046\n",
      "AUPR for each fold: [0.47811862 0.48907223 0.4490071  0.47113236]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5157940272020756\n",
      "AUROCperdrug: 0.7711774148948936\n",
      "AUPR+AUROCperdrug: 1.2869714420969691\n",
      "AUPR: 0.47305251780447033\n",
      "AUROC: 0.7341063664824901\n",
      "AUPR+AUROC: 1.2071588842869603\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.47418808083953795\n",
      "AUPR for each fold: [0.47760464 0.47441657 0.47359436 0.47113675]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5123208255156684\n",
      "AUROCperdrug: 0.7718793822391329\n",
      "AUPR+AUROCperdrug: 1.2842002077548011\n",
      "AUPR: 0.4630029792080742\n",
      "AUROC: 0.7186417946406026\n",
      "AUPR+AUROC: 1.1816447738486768\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4696594732270334\n",
      "AUPR for each fold: [0.4627542  0.48112042 0.47341202 0.46135124]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5258580074952242\n",
      "AUROCperdrug: 0.76358216419986\n",
      "AUPR+AUROCperdrug: 1.2894401716950843\n",
      "AUPR: 0.48186500053363596\n",
      "AUROC: 0.7245883915254911\n",
      "AUPR+AUROC: 1.2064533920591272\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5164241974116534, std: 0.004870036451260676\n",
      "Mean AUROCperdrug: 0.7707525799047183, std: 0.003838824021067499\n",
      "Mean AUPR+AUROCperdrug: 1.2871767773163714, std: 0.0022768423438398414\n",
      "Mean AUPR: 0.4720417976064487, std: 0.0064544593020182265\n",
      "Mean AUROC: 0.7287539455821526, std: 0.0062270171293544235\n",
      "Mean AUPR+AUROC: 1.2007957431886012, std: 0.010229093915138744\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5595568374837949\n",
      "AUROCperdrug: 0.804464995276608\n",
      "AUPR+AUROCperdrug: 1.364021832760403\n",
      "AUPR: 0.5438198660420205\n",
      "AUROC: 0.7746647274479381\n",
      "AUPR+AUROC: 1.3184845934899587\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5610291840427147\n",
      "AUROCperdrug: 0.8058422795711983\n",
      "AUPR+AUROCperdrug: 1.366871463613913\n",
      "AUPR: 0.5266303413935844\n",
      "AUROC: 0.763448970043388\n",
      "AUPR+AUROC: 1.2900793114369724\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5634154244268479\n",
      "AUROCperdrug: 0.8041604755171422\n",
      "AUPR+AUROCperdrug: 1.36757589994399\n",
      "AUPR: 0.5527764344857409\n",
      "AUROC: 0.7791303562014587\n",
      "AUPR+AUROC: 1.3319067906871995\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5538499887657367\n",
      "AUROCperdrug: 0.7965787387640059\n",
      "AUPR+AUROCperdrug: 1.3504287275297426\n",
      "AUPR: 0.5340586867302238\n",
      "AUROC: 0.7560330602585985\n",
      "AUPR+AUROC: 1.2900917469888222\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5681114056494416\n",
      "AUROCperdrug: 0.7941302568973434\n",
      "AUPR+AUROCperdrug: 1.362241662546785\n",
      "AUPR: 0.5542543769467958\n",
      "AUROC: 0.7620937572844743\n",
      "AUPR+AUROC: 1.3163481342312702\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5611925680737072, std: 0.004678187331954287\n",
      "Mean AUROCperdrug: 0.8010353492052594, std: 0.004736605168026034\n",
      "Mean AUPR+AUROCperdrug: 1.3622279172789669, std: 0.0062064908213144265\n",
      "Mean AUPR: 0.5423079411196731, std: 0.010662363063140216\n",
      "Mean AUROC: 0.7670741742471716, std: 0.008518460869883268\n",
      "Mean AUPR+AUROC: 1.3093821153668446, std: 0.01663404987850887\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4769194663054114\n",
      "AUPR for each fold: [0.4954987  0.49217436 0.45581147 0.46419334]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5181183246392053\n",
      "AUROCperdrug: 0.7703370320404419\n",
      "AUPR+AUROCperdrug: 1.288455356679647\n",
      "AUPR: 0.4796443636816957\n",
      "AUROC: 0.7313514597702799\n",
      "AUPR+AUROC: 1.2109958234519755\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4782153453870682\n",
      "AUPR for each fold: [0.49880978 0.49275138 0.45177938 0.46952084]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5194584787296169\n",
      "AUROCperdrug: 0.7719904464676265\n",
      "AUPR+AUROCperdrug: 1.2914489251972434\n",
      "AUPR: 0.47205887606254926\n",
      "AUROC: 0.7272997568161867\n",
      "AUPR+AUROC: 1.199358632878736\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.47682064407009606\n",
      "AUPR for each fold: [0.48323253 0.49376817 0.45374495 0.47653692]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5208755293445482\n",
      "AUROCperdrug: 0.7697643677191854\n",
      "AUPR+AUROCperdrug: 1.2906398970637336\n",
      "AUPR: 0.4782492244701923\n",
      "AUROC: 0.7316260770677472\n",
      "AUPR+AUROC: 1.2098753015379395\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.47913146424402153\n",
      "AUPR for each fold: [0.48269693 0.47908485 0.4785626  0.47618148]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5173265142451856\n",
      "AUROCperdrug: 0.7703778151296486\n",
      "AUPR+AUROCperdrug: 1.2877043293748343\n",
      "AUPR: 0.4682637800000038\n",
      "AUROC: 0.7163388502519463\n",
      "AUPR+AUROC: 1.1846026302519501\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4746565311973941\n",
      "AUPR for each fold: [0.46753852 0.48607358 0.47843491 0.46657912]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5308693288115758\n",
      "AUROCperdrug: 0.7610456024602443\n",
      "AUPR+AUROCperdrug: 1.29191493127182\n",
      "AUPR: 0.486996338691493\n",
      "AUROC: 0.7214568964597794\n",
      "AUPR+AUROC: 1.2084532351512725\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5213296351540263, std: 0.0049203797772956045\n",
      "Mean AUROCperdrug: 0.7687030527634293, std: 0.003899861772126438\n",
      "Mean AUPR+AUROCperdrug: 1.2900326879174557, std: 0.0016629190215881374\n",
      "Mean AUPR: 0.4770425165811868, std: 0.006468496203109993\n",
      "Mean AUROC: 0.7256146080731879, std: 0.005919716246098323\n",
      "Mean AUPR+AUROC: 1.2026571246543747, std: 0.009920440395193396\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5643506767716057\n",
      "AUROCperdrug: 0.803021749505332\n",
      "AUPR+AUROCperdrug: 1.3673724262769378\n",
      "AUPR: 0.5495000942845845\n",
      "AUROC: 0.7729129505593904\n",
      "AUPR+AUROC: 1.3224130448439748\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5658838362693718\n",
      "AUROCperdrug: 0.8036187510767118\n",
      "AUPR+AUROCperdrug: 1.3695025873460835\n",
      "AUPR: 0.5322976119861473\n",
      "AUROC: 0.7613637342268953\n",
      "AUPR+AUROC: 1.2936613462130426\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5685658110201515\n",
      "AUROCperdrug: 0.8029691541735237\n",
      "AUPR+AUROCperdrug: 1.3715349651936752\n",
      "AUPR: 0.5583759536942945\n",
      "AUROC: 0.77710177178567\n",
      "AUPR+AUROC: 1.3354777254799646\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5591818531996182\n",
      "AUROCperdrug: 0.7962936106024802\n",
      "AUPR+AUROCperdrug: 1.3554754638020983\n",
      "AUPR: 0.5394700794439244\n",
      "AUROC: 0.7540066530166283\n",
      "AUPR+AUROC: 1.2934767324605527\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.573374310376865\n",
      "AUROCperdrug: 0.7927626595072768\n",
      "AUPR+AUROCperdrug: 1.366136969884142\n",
      "AUPR: 0.5600815995728002\n",
      "AUROC: 0.7606438991694578\n",
      "AUPR+AUROC: 1.320725498742258\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5662712975275224, std: 0.004686506479220147\n",
      "Mean AUROCperdrug: 0.7997331849730649, std: 0.004400060781739197\n",
      "Mean AUPR+AUROCperdrug: 1.3660044825005875, std: 0.005578028937963989\n",
      "Mean AUPR: 0.5479450677963501, std: 0.01072553208434741\n",
      "Mean AUROC: 0.7652058017516083, std: 0.008507733143655593\n",
      "Mean AUPR+AUROC: 1.3131508695479586, std: 0.016784305671728523\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.48189424290011296\n",
      "AUPR for each fold: [0.50052675 0.49739038 0.46115503 0.46850481]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.522912383596369\n",
      "AUROCperdrug: 0.7681780043984119\n",
      "AUPR+AUROCperdrug: 1.2910903879947808\n",
      "AUPR: 0.484614534538619\n",
      "AUROC: 0.7279298621264978\n",
      "AUPR+AUROC: 1.2125443966651168\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.48322151090221466\n",
      "AUPR for each fold: [0.50410398 0.49783082 0.45694411 0.47400714]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5240439551175942\n",
      "AUROCperdrug: 0.7688343474917237\n",
      "AUPR+AUROCperdrug: 1.292878302609318\n",
      "AUPR: 0.47704415697279856\n",
      "AUROC: 0.7238124490735436\n",
      "AUPR+AUROC: 1.2008566060463421\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.48186794815406714\n",
      "AUPR for each fold: [0.48861299 0.49871712 0.45894481 0.48119687]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.525796408364939\n",
      "AUROCperdrug: 0.7673383777048004\n",
      "AUPR+AUROCperdrug: 1.2931347860697393\n",
      "AUPR: 0.48305468810854596\n",
      "AUROC: 0.7276278273869781\n",
      "AUPR+AUROC: 1.210682515495524\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.48415460642653596\n",
      "AUPR for each fold: [0.48811387 0.48399132 0.48367574 0.4808375 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5224400851120493\n",
      "AUROCperdrug: 0.7702899957260365\n",
      "AUPR+AUROCperdrug: 1.2927300808380857\n",
      "AUPR: 0.47314445502422164\n",
      "AUROC: 0.7124999940095442\n",
      "AUPR+AUROC: 1.1856444490337659\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4796037566063191\n",
      "AUPR for each fold: [0.47279882 0.49049311 0.48368818 0.47143491]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5357892649160206\n",
      "AUROCperdrug: 0.7584109139402055\n",
      "AUPR+AUROCperdrug: 1.2942001788562263\n",
      "AUPR: 0.49224633592699496\n",
      "AUROC: 0.7183090288503764\n",
      "AUPR+AUROC: 1.2105553647773712\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5261964194213944, std: 0.004933776137033472\n",
      "Mean AUROCperdrug: 0.7666103278522357, std: 0.004211989407877336\n",
      "Mean AUPR+AUROCperdrug: 1.2928067472736298, std: 0.0010006146220824296\n",
      "Mean AUPR: 0.4820208341142361, std: 0.006571368874374382\n",
      "Mean AUROC: 0.7220358322893881, std: 0.005898942950433032\n",
      "Mean AUPR+AUROC: 1.2040566664036239, std: 0.010073992818129181\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5668640447448403\n",
      "AUROCperdrug: 0.8019672606008506\n",
      "AUPR+AUROCperdrug: 1.3688313053456909\n",
      "AUPR: 0.5528096104271415\n",
      "AUROC: 0.7720062152254044\n",
      "AUPR+AUROC: 1.324815825652546\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5687963363026584\n",
      "AUROCperdrug: 0.802843039243655\n",
      "AUPR+AUROCperdrug: 1.3716393755463132\n",
      "AUPR: 0.5359183834952881\n",
      "AUROC: 0.7611006258902537\n",
      "AUPR+AUROC: 1.2970190093855418\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5715899665810009\n",
      "AUROCperdrug: 0.8015331884881799\n",
      "AUPR+AUROCperdrug: 1.3731231550691807\n",
      "AUPR: 0.5611998101862088\n",
      "AUROC: 0.7759180336714465\n",
      "AUPR+AUROC: 1.3371178438576554\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5614472919662845\n",
      "AUROCperdrug: 0.7942826673653223\n",
      "AUPR+AUROCperdrug: 1.3557299593316068\n",
      "AUPR: 0.5424108895199096\n",
      "AUROC: 0.7525252132646585\n",
      "AUPR+AUROC: 1.294936102784568\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5763571871017535\n",
      "AUROCperdrug: 0.7929696564807605\n",
      "AUPR+AUROCperdrug: 1.369326843582514\n",
      "AUPR: 0.5635662970398068\n",
      "AUROC: 0.7606465423127989\n",
      "AUPR+AUROC: 1.3242128393526058\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5690109653393074, std: 0.004949398148134564\n",
      "Mean AUROCperdrug: 0.7987191624357537, std: 0.004200346449450331\n",
      "Mean AUPR+AUROCperdrug: 1.367730127775061, std: 0.006198920835359389\n",
      "Mean AUPR: 0.5511809981336709, std: 0.010642244242994994\n",
      "Mean AUROC: 0.7644393260729123, std: 0.008443894257357925\n",
      "Mean AUPR+AUROC: 1.3156203242065836, std: 0.016699567919152943\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.48493152236995035\n",
      "AUPR for each fold: [0.50377972 0.50047696 0.46405053 0.47141888]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5253796060876981\n",
      "AUROCperdrug: 0.7661442927899171\n",
      "AUPR+AUROCperdrug: 1.2915238988776152\n",
      "AUPR: 0.48757599848199196\n",
      "AUROC: 0.7262010294504444\n",
      "AUPR+AUROC: 1.2137770279324362\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.48623779481272766\n",
      "AUPR for each fold: [0.50718063 0.50093076 0.45988135 0.47695844]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5267940962812347\n",
      "AUROCperdrug: 0.7675031530389069\n",
      "AUPR+AUROCperdrug: 1.2942972493201417\n",
      "AUPR: 0.48016584814312696\n",
      "AUROC: 0.7225160939209848\n",
      "AUPR+AUROC: 1.2026819420641117\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4849032633218284\n",
      "AUPR for each fold: [0.49175719 0.50175814 0.46194376 0.48415396]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5286158996543843\n",
      "AUROCperdrug: 0.7660928086148222\n",
      "AUPR+AUROCperdrug: 1.2947087082692064\n",
      "AUPR: 0.4860393165374142\n",
      "AUROC: 0.7259489696059273\n",
      "AUPR+AUROC: 1.2119882861433415\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.48730114451865614\n",
      "AUPR for each fold: [0.49143011 0.48711122 0.48683959 0.48382366]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5246485355682627\n",
      "AUROCperdrug: 0.7672897946628713\n",
      "AUPR+AUROCperdrug: 1.291938330231134\n",
      "AUPR: 0.4757588382471557\n",
      "AUROC: 0.7095765283797428\n",
      "AUPR+AUROC: 1.1853353666268984\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4825147694584956\n",
      "AUPR for each fold: [0.47591976 0.49333139 0.48667049 0.47413744]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5386595629957589\n",
      "AUROCperdrug: 0.7585781842721612\n",
      "AUPR+AUROCperdrug: 1.29723774726792\n",
      "AUPR: 0.49574667614129203\n",
      "AUROC: 0.7179769190509142\n",
      "AUPR+AUROC: 1.2137235951922063\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5288195401174678, std: 0.005102947530513884\n",
      "Mean AUROCperdrug: 0.7651216466757358, std: 0.0033219963595921996\n",
      "Mean AUPR+AUROCperdrug: 1.2939411867932034, std: 0.0020706470475555213\n",
      "Mean AUPR: 0.4850573355101961, std: 0.0068111475251073075\n",
      "Mean AUROC: 0.7204439080816027, std: 0.0061956449132764425\n",
      "Mean AUPR+AUROC: 1.2055012435917987, std: 0.010888419979285406\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5711650591032895\n",
      "AUROCperdrug: 0.8012206722167488\n",
      "AUPR+AUROCperdrug: 1.3723857313200383\n",
      "AUPR: 0.5577795792476113\n",
      "AUROC: 0.7704332889857342\n",
      "AUPR+AUROC: 1.3282128682333454\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.57259769757416\n",
      "AUROCperdrug: 0.8018332730801092\n",
      "AUPR+AUROCperdrug: 1.3744309706542692\n",
      "AUPR: 0.5406779780863464\n",
      "AUROC: 0.7602919479035928\n",
      "AUPR+AUROC: 1.3009699259899392\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5765553934645616\n",
      "AUROCperdrug: 0.8023869441455647\n",
      "AUPR+AUROCperdrug: 1.3789423376101264\n",
      "AUPR: 0.565615362043667\n",
      "AUROC: 0.7741180721472295\n",
      "AUPR+AUROC: 1.3397334341908964\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5652858421303616\n",
      "AUROCperdrug: 0.7921271943355603\n",
      "AUPR+AUROCperdrug: 1.357413036465922\n",
      "AUPR: 0.5469362775526025\n",
      "AUROC: 0.7509355055349569\n",
      "AUPR+AUROC: 1.2978717830875595\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5816260279956943\n",
      "AUROCperdrug: 0.7948039173484515\n",
      "AUPR+AUROCperdrug: 1.3764299453441458\n",
      "AUPR: 0.5686161911318819\n",
      "AUROC: 0.7596846231989336\n",
      "AUPR+AUROC: 1.3283008143308155\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5734460040536133, std: 0.005460616642195512\n",
      "Mean AUROCperdrug: 0.7984744002252868, std: 0.004192648418118892\n",
      "Mean AUPR+AUROCperdrug: 1.3719204042789004, std: 0.007571349971685423\n",
      "Mean AUPR: 0.5559250776124218, std: 0.01069278000812353\n",
      "Mean AUROC: 0.7630926875540893, std: 0.008278884643356032\n",
      "Mean AUPR+AUROC: 1.3190177651665111, std: 0.016569495600960348\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.48917530891624916\n",
      "AUPR for each fold: [0.50811847 0.50467911 0.46836112 0.47554255]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5294171153994506\n",
      "AUROCperdrug: 0.76498248110152\n",
      "AUPR+AUROCperdrug: 1.2943995965009707\n",
      "AUPR: 0.4917033217474043\n",
      "AUROC: 0.7234237330307012\n",
      "AUPR+AUROC: 1.2151270547781055\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.49045762532171155\n",
      "AUPR for each fold: [0.51121647 0.50530959 0.46412406 0.48118038]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5305868755527037\n",
      "AUROCperdrug: 0.7647236622375074\n",
      "AUPR+AUROCperdrug: 1.2953105377902112\n",
      "AUPR: 0.48445759972282454\n",
      "AUROC: 0.720188734533712\n",
      "AUPR+AUROC: 1.2046463342565366\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4891840141354082\n",
      "AUPR for each fold: [0.49594593 0.50605334 0.46624254 0.48849424]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5332120007721146\n",
      "AUROCperdrug: 0.7668324957326215\n",
      "AUPR+AUROCperdrug: 1.3000444965047362\n",
      "AUPR: 0.4900368326987746\n",
      "AUROC: 0.7227371056449062\n",
      "AUPR+AUROC: 1.2127739383436809\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.491550405324806\n",
      "AUPR for each fold: [0.49572073 0.49123318 0.49117768 0.48807004]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5283480711104203\n",
      "AUROCperdrug: 0.7648464030512956\n",
      "AUPR+AUROCperdrug: 1.2931944741617158\n",
      "AUPR: 0.4798629678129756\n",
      "AUROC: 0.7065638620976857\n",
      "AUPR+AUROC: 1.1864268299106613\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.486662411481751\n",
      "AUPR for each fold: [0.48009203 0.49726294 0.49094532 0.47834935]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5438426853536449\n",
      "AUROCperdrug: 0.7607887137554763\n",
      "AUPR+AUROCperdrug: 1.3046313991091212\n",
      "AUPR: 0.5002896229180174\n",
      "AUROC: 0.7161068953196683\n",
      "AUPR+AUROC: 1.2163965182376857\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5330813496376667, std: 0.005619187756971285\n",
      "Mean AUROCperdrug: 0.7644347511756842, std: 0.0019796819325271866\n",
      "Mean AUPR+AUROCperdrug: 1.2975161008133511, std: 0.0042490897590955895\n",
      "Mean AUPR: 0.48927006897999925, std: 0.006922320815178599\n",
      "Mean AUROC: 0.7178040661253346, std: 0.006177778788102093\n",
      "Mean AUPR+AUROC: 1.207074135105334, std: 0.011103598770143979\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5735367121341455\n",
      "AUROCperdrug: 0.8011006864371574\n",
      "AUPR+AUROCperdrug: 1.374637398571303\n",
      "AUPR: 0.5604555885043312\n",
      "AUROC: 0.7699185047412812\n",
      "AUPR+AUROC: 1.3303740932456125\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5750593138174096\n",
      "AUROCperdrug: 0.8014963648374905\n",
      "AUPR+AUROCperdrug: 1.3765556786549\n",
      "AUPR: 0.5432508298476104\n",
      "AUROC: 0.7597603943973379\n",
      "AUPR+AUROC: 1.3030112242449483\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5789802771268501\n",
      "AUROCperdrug: 0.8018614356381135\n",
      "AUPR+AUROCperdrug: 1.3808417127649637\n",
      "AUPR: 0.5681019771073841\n",
      "AUROC: 0.7732274556739769\n",
      "AUPR+AUROC: 1.341329432781361\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5677782885380014\n",
      "AUROCperdrug: 0.792005825148937\n",
      "AUPR+AUROCperdrug: 1.3597841136869384\n",
      "AUPR: 0.5497830267638992\n",
      "AUROC: 0.7503768790513591\n",
      "AUPR+AUROC: 1.3001599058152582\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5842597934601829\n",
      "AUROCperdrug: 0.7944398823729851\n",
      "AUPR+AUROCperdrug: 1.378699675833168\n",
      "AUPR: 0.57116843637133\n",
      "AUROC: 0.7587767157271956\n",
      "AUPR+AUROC: 1.3299451520985257\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5759228770153177, std: 0.005506826980256706\n",
      "Mean AUROCperdrug: 0.7981808388869368, std: 0.004127724913166098\n",
      "Mean AUPR+AUROCperdrug: 1.3741037159022547, std: 0.007454815833337944\n",
      "Mean AUPR: 0.5585519717189109, std: 0.010630342217454996\n",
      "Mean AUROC: 0.7624119899182302, std: 0.00822693302672036\n",
      "Mean AUPR+AUROC: 1.3209639616371411, std: 0.01636504990784646\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4915901006396206\n",
      "AUPR for each fold: [0.5106217  0.50714227 0.47089096 0.47770547]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5319400360488536\n",
      "AUROCperdrug: 0.7650600254662314\n",
      "AUPR+AUROCperdrug: 1.2970000615150852\n",
      "AUPR: 0.4941603865049129\n",
      "AUROC: 0.7224025814607316\n",
      "AUPR+AUROC: 1.2165629679656444\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.49284210854137456\n",
      "AUPR for each fold: [0.51360073 0.50772225 0.46675692 0.48328854]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5333055869564415\n",
      "AUROCperdrug: 0.7649990188930386\n",
      "AUPR+AUROCperdrug: 1.29830460584948\n",
      "AUPR: 0.4871123094275899\n",
      "AUROC: 0.7197601059990426\n",
      "AUPR+AUROC: 1.2068724154266324\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4916084679415679\n",
      "AUPR for each fold: [0.49844942 0.50856473 0.46890152 0.49051821]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5355348110323448\n",
      "AUROCperdrug: 0.7663024229476453\n",
      "AUPR+AUROCperdrug: 1.30183723397999\n",
      "AUPR: 0.49252953542817934\n",
      "AUROC: 0.7217670727553376\n",
      "AUPR+AUROC: 1.214296608183517\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.49404418479695944\n",
      "AUPR for each fold: [0.49827415 0.49377745 0.49389327 0.49023187]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.530267281106945\n",
      "AUROCperdrug: 0.7639575029187647\n",
      "AUPR+AUROCperdrug: 1.2942247840257097\n",
      "AUPR: 0.48202032155641633\n",
      "AUROC: 0.7044826416027097\n",
      "AUPR+AUROC: 1.186502963159126\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.48909027143546385\n",
      "AUPR for each fold: [0.48251422 0.49974209 0.49351705 0.48058773]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5460474248882083\n",
      "AUROCperdrug: 0.7602774865862603\n",
      "AUPR+AUROCperdrug: 1.3063249114744686\n",
      "AUPR: 0.5027231781052335\n",
      "AUROC: 0.7148195952659728\n",
      "AUPR+AUROC: 1.2175427733712063\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5354190280065587, std: 0.005587248700652166\n",
      "Mean AUROCperdrug: 0.7641192913623881, std: 0.0020596409463415942\n",
      "Mean AUPR+AUROCperdrug: 1.2995383193689467, std: 0.004184287289855548\n",
      "Mean AUPR: 0.4917091462044664, std: 0.006971294680530144\n",
      "Mean AUROC: 0.7166463994167589, std: 0.006638438271288109\n",
      "Mean AUPR+AUROC: 1.2083555456212252, std: 0.011548144397051156\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5772695262358665\n",
      "AUROCperdrug: 0.8001439419043599\n",
      "AUPR+AUROCperdrug: 1.3774134681402264\n",
      "AUPR: 0.5645649980208342\n",
      "AUROC: 0.7681649541748412\n",
      "AUPR+AUROC: 1.3327299521956752\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5791236030035705\n",
      "AUROCperdrug: 0.8016846254270543\n",
      "AUPR+AUROCperdrug: 1.3808082284306247\n",
      "AUPR: 0.5473596821741271\n",
      "AUROC: 0.7589454253992248\n",
      "AUPR+AUROC: 1.306305107573352\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5830206094986714\n",
      "AUROCperdrug: 0.8012660548929614\n",
      "AUPR+AUROCperdrug: 1.3842866643916327\n",
      "AUPR: 0.571544964662704\n",
      "AUROC: 0.77171658268711\n",
      "AUPR+AUROC: 1.343261547349814\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5716658122976992\n",
      "AUROCperdrug: 0.7912793987280973\n",
      "AUPR+AUROCperdrug: 1.3629452110257965\n",
      "AUPR: 0.5540492284418617\n",
      "AUROC: 0.7499589596970948\n",
      "AUPR+AUROC: 1.3040081881389565\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5886740112880398\n",
      "AUROCperdrug: 0.7948960893450118\n",
      "AUPR+AUROCperdrug: 1.3835701006330514\n",
      "AUPR: 0.5753235816108923\n",
      "AUROC: 0.7575805678184735\n",
      "AUPR+AUROC: 1.3329041494293659\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5799507124647695, std: 0.005692673371835306\n",
      "Mean AUROCperdrug: 0.7978540220594968, std: 0.004087401644205896\n",
      "Mean AUPR+AUROCperdrug: 1.3778047345242666, std: 0.007813249833509405\n",
      "Mean AUPR: 0.5625684909820838, std: 0.01049896334530202\n",
      "Mean AUROC: 0.7612732979553487, std: 0.0077926454835291524\n",
      "Mean AUPR+AUROC: 1.3238417889374328, std: 0.015742679279492338\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4954374929222202\n",
      "AUPR for each fold: [0.51441345 0.51089676 0.47477056 0.4816692 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5354454852706776\n",
      "AUROCperdrug: 0.7640807179456338\n",
      "AUPR+AUROCperdrug: 1.2995262032163115\n",
      "AUPR: 0.49768250915921597\n",
      "AUROC: 0.719897607885765\n",
      "AUPR+AUROC: 1.217580117044981\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4965747693116241\n",
      "AUPR for each fold: [0.51724392 0.5112526  0.47064341 0.48715915]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5374084259008665\n",
      "AUROCperdrug: 0.7652250942999681\n",
      "AUPR+AUROCperdrug: 1.3026335202008346\n",
      "AUPR: 0.49109592187190265\n",
      "AUROC: 0.7186581776621136\n",
      "AUPR+AUROC: 1.2097540995340164\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.49539660742915775\n",
      "AUPR for each fold: [0.50231562 0.51213675 0.47284189 0.49429216]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5396205573100791\n",
      "AUROCperdrug: 0.7666928745923337\n",
      "AUPR+AUROCperdrug: 1.3063134319024128\n",
      "AUPR: 0.4962770284303103\n",
      "AUROC: 0.7198527901366931\n",
      "AUPR+AUROC: 1.2161298185670035\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.49776867565543076\n",
      "AUPR for each fold: [0.50200465 0.49719826 0.49814434 0.49372745]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5340557441838026\n",
      "AUROCperdrug: 0.7635810651332334\n",
      "AUPR+AUROCperdrug: 1.297636809317036\n",
      "AUPR: 0.4858835033012\n",
      "AUROC: 0.7029742705779999\n",
      "AUPR+AUROC: 1.1888577738791999\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.4929004203736006\n",
      "AUPR for each fold: [0.48632138 0.50343778 0.49769873 0.4841438 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5504333199627389\n",
      "AUROCperdrug: 0.761017774303049\n",
      "AUPR+AUROCperdrug: 1.311451094265788\n",
      "AUPR: 0.5064037007454864\n",
      "AUROC: 0.7124449355521895\n",
      "AUPR+AUROC: 1.2188486362976758\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5393927065256329, std: 0.005830062663798522\n",
      "Mean AUROCperdrug: 0.7641195052548435, std: 0.001884500676628682\n",
      "Mean AUPR+AUROCperdrug: 1.3035122117804767, std: 0.00494071668000217\n",
      "Mean AUPR: 0.49546853270162305, std: 0.00687205604343813\n",
      "Mean AUROC: 0.7147655563629522, std: 0.0065083039617083605\n",
      "Mean AUPR+AUROC: 1.2102340890645753, std: 0.011136529246942087\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5800855788068979\n",
      "AUROCperdrug: 0.7983713251630292\n",
      "AUPR+AUROCperdrug: 1.3784569039699273\n",
      "AUPR: 0.5682788201163889\n",
      "AUROC: 0.7666890421787147\n",
      "AUPR+AUROC: 1.3349678622951036\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5817636414296282\n",
      "AUROCperdrug: 0.7995052686690358\n",
      "AUPR+AUROCperdrug: 1.381268910098664\n",
      "AUPR: 0.5511895065730452\n",
      "AUROC: 0.758124711241119\n",
      "AUPR+AUROC: 1.3093142178141641\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5854019515219282\n",
      "AUROCperdrug: 0.7987707754831525\n",
      "AUPR+AUROCperdrug: 1.3841727270050805\n",
      "AUPR: 0.5745914815110379\n",
      "AUROC: 0.769848208994709\n",
      "AUPR+AUROC: 1.3444396905057467\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5745490817499898\n",
      "AUROCperdrug: 0.7888618926789546\n",
      "AUPR+AUROCperdrug: 1.3634109744289442\n",
      "AUPR: 0.5581894362980295\n",
      "AUROC: 0.7495700530878315\n",
      "AUPR+AUROC: 1.307759489385861\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5922150817369592\n",
      "AUROCperdrug: 0.7937698890354205\n",
      "AUPR+AUROCperdrug: 1.3859849707723797\n",
      "AUPR: 0.5792542442886199\n",
      "AUROC: 0.7568921115783437\n",
      "AUPR+AUROC: 1.3361463558669637\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5828030670490807, std: 0.0058640198204036546\n",
      "Mean AUROCperdrug: 0.7958558302059185, std: 0.00403507954425811\n",
      "Mean AUPR+AUROCperdrug: 1.3786588972549991, std: 0.008042708381330057\n",
      "Mean AUPR: 0.5663006977574243, std: 0.010340068592863282\n",
      "Mean AUROC: 0.7602248254161434, std: 0.007258612047694425\n",
      "Mean AUPR+AUROC: 1.326525523173568, std: 0.015054195156557688\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.499132613488919\n",
      "AUPR for each fold: [0.51829629 0.51471505 0.47840899 0.48511012]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5384847515863667\n",
      "AUROCperdrug: 0.7625627665751652\n",
      "AUPR+AUROCperdrug: 1.301047518161532\n",
      "AUPR: 0.5011456580583793\n",
      "AUROC: 0.7177758041444849\n",
      "AUPR+AUROC: 1.2189214622028643\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5002168029909946\n",
      "AUPR for each fold: [0.52091325 0.51491154 0.47431104 0.49073138]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5402868476102263\n",
      "AUROCperdrug: 0.7628265571387556\n",
      "AUPR+AUROCperdrug: 1.3031134047489819\n",
      "AUPR: 0.49486115725082647\n",
      "AUROC: 0.7174854577737914\n",
      "AUPR+AUROC: 1.2123466150246178\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.49913725075608417\n",
      "AUPR for each fold: [0.50616874 0.51588949 0.47669628 0.4977945 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5423416933331625\n",
      "AUROCperdrug: 0.7636224127698461\n",
      "AUPR+AUROCperdrug: 1.3059641061030085\n",
      "AUPR: 0.4996894458034734\n",
      "AUROC: 0.7174702380952381\n",
      "AUPR+AUROC: 1.2171596838987115\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5013919732451095\n",
      "AUPR for each fold: [0.50569505 0.50079813 0.50204    0.49703471]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5371005813464588\n",
      "AUROCperdrug: 0.7622765449269631\n",
      "AUPR+AUROCperdrug: 1.2993771262734217\n",
      "AUPR: 0.48960973127372753\n",
      "AUROC: 0.7016371799338964\n",
      "AUPR+AUROC: 1.191246911207624\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.49649073551293965\n",
      "AUPR for each fold: [0.48965829 0.50690824 0.50160146 0.48779495]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5538034690429354\n",
      "AUROCperdrug: 0.7600120293794536\n",
      "AUPR+AUROCperdrug: 1.313815498422389\n",
      "AUPR: 0.5103200689096699\n",
      "AUROC: 0.7114770866205112\n",
      "AUPR+AUROC: 1.2217971555301812\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5424034685838299, std: 0.005965247135761952\n",
      "Mean AUROCperdrug: 0.7622600621580367, std: 0.001210162697498313\n",
      "Mean AUPR+AUROCperdrug: 1.3046635307418666, std: 0.005076899023504149\n",
      "Mean AUPR: 0.49912521225921525, std: 0.006905822465771868\n",
      "Mean AUROC: 0.7131691533135844, std: 0.006232183342836643\n",
      "Mean AUPR+AUROC: 1.2122943655727998, std: 0.010962580119571718\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5854345620847804\n",
      "AUROCperdrug: 0.7962624743498652\n",
      "AUPR+AUROCperdrug: 1.3816970364346455\n",
      "AUPR: 0.5742790180446149\n",
      "AUROC: 0.7638421148544553\n",
      "AUPR+AUROC: 1.33812113289907\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5868007805405057\n",
      "AUROCperdrug: 0.796806000275376\n",
      "AUPR+AUROCperdrug: 1.3836067808158816\n",
      "AUPR: 0.5571656743650185\n",
      "AUROC: 0.7557169566985726\n",
      "AUPR+AUROC: 1.3128826310635913\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5900512007367088\n",
      "AUROCperdrug: 0.7953791030054091\n",
      "AUPR+AUROCperdrug: 1.385430303742118\n",
      "AUPR: 0.5795082719196332\n",
      "AUROC: 0.7666035624640898\n",
      "AUPR+AUROC: 1.346111834383723\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5797874070729967\n",
      "AUROCperdrug: 0.7865440343715492\n",
      "AUPR+AUROCperdrug: 1.366331441444546\n",
      "AUPR: 0.5640178463694243\n",
      "AUROC: 0.747364207693329\n",
      "AUPR+AUROC: 1.3113820540627534\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5982349507678919\n",
      "AUROCperdrug: 0.7928121472742653\n",
      "AUPR+AUROCperdrug: 1.3910470980421572\n",
      "AUPR: 0.5854877265006875\n",
      "AUROC: 0.7557250729375073\n",
      "AUPR+AUROC: 1.3412127994381948\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5880617802405768, std: 0.006073036131727822\n",
      "Mean AUROCperdrug: 0.793560751855293, std: 0.0037664857816343566\n",
      "Mean AUPR+AUROCperdrug: 1.3816225320958695, std: 0.008259319770686443\n",
      "Mean AUPR: 0.5720917074398757, std: 0.010268561525143804\n",
      "Mean AUROC: 0.7578503829295908, std: 0.006805105797176829\n",
      "Mean AUPR+AUROC: 1.3299420903694663, std: 0.014770824896497049\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5049912457959501\n",
      "AUPR for each fold: [0.52435854 0.52141251 0.48394299 0.49025094]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5438740824661449\n",
      "AUROCperdrug: 0.7590070723741879\n",
      "AUPR+AUROCperdrug: 1.3028811548403327\n",
      "AUPR: 0.5067276017007081\n",
      "AUROC: 0.7139226205697979\n",
      "AUPR+AUROC: 1.220650222270506\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5060316582100961\n",
      "AUPR for each fold: [0.52699856 0.52147559 0.47975229 0.49590019]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5455230835718357\n",
      "AUROCperdrug: 0.7593872829440294\n",
      "AUPR+AUROCperdrug: 1.304910366515865\n",
      "AUPR: 0.5006587317570923\n",
      "AUROC: 0.714461387980079\n",
      "AUPR+AUROC: 1.2151201197371713\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.50499403824555\n",
      "AUPR for each fold: [0.51241107 0.52198475 0.48220571 0.50337462]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5473090243040095\n",
      "AUROCperdrug: 0.759364165889205\n",
      "AUPR+AUROCperdrug: 1.3066731901932145\n",
      "AUPR: 0.5053869191959504\n",
      "AUROC: 0.7139749724124155\n",
      "AUPR+AUROC: 1.219361891608366\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5072440756623874\n",
      "AUPR for each fold: [0.51173755 0.50665597 0.50778905 0.50279373]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.542284143513222\n",
      "AUROCperdrug: 0.7581835136422942\n",
      "AUPR+AUROCperdrug: 1.300467657155516\n",
      "AUPR: 0.4952550688666057\n",
      "AUROC: 0.69800588588695\n",
      "AUPR+AUROC: 1.1932609547535558\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.502152770250481\n",
      "AUPR for each fold: [0.49526894 0.51268592 0.50707708 0.49357914]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.559910439001415\n",
      "AUROCperdrug: 0.7585488774015103\n",
      "AUPR+AUROCperdrug: 1.3184593164029255\n",
      "AUPR: 0.5166412621243388\n",
      "AUROC: 0.7097460512043282\n",
      "AUPR+AUROC: 1.226387313328667\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5477801545713255, std: 0.006291640015481783\n",
      "Mean AUROCperdrug: 0.7588981824502454, std: 0.0004692509767854911\n",
      "Mean AUPR+AUROCperdrug: 1.3066783370215709, std: 0.006243530384308564\n",
      "Mean AUPR: 0.5049339167289391, std: 0.007105515543659805\n",
      "Mean AUROC: 0.7100221836107141, std: 0.00624519244391437\n",
      "Mean AUPR+AUROC: 1.2149561003396532, std: 0.011429898477517688\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5889066092557528\n",
      "AUROCperdrug: 0.7940542080038754\n",
      "AUPR+AUROCperdrug: 1.3829608172596282\n",
      "AUPR: 0.5786044148630661\n",
      "AUROC: 0.7616718660287114\n",
      "AUPR+AUROC: 1.3402762808917776\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5903885370235857\n",
      "AUROCperdrug: 0.7945294352380466\n",
      "AUPR+AUROCperdrug: 1.3849179722616323\n",
      "AUPR: 0.5616231652307366\n",
      "AUROC: 0.7538510944932468\n",
      "AUPR+AUROC: 1.3154742597239835\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5943161886966873\n",
      "AUROCperdrug: 0.7936349031989027\n",
      "AUPR+AUROCperdrug: 1.38795109189559\n",
      "AUPR: 0.583799501186149\n",
      "AUROC: 0.7644410932706109\n",
      "AUPR+AUROC: 1.34824059445676\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5828679159136393\n",
      "AUROCperdrug: 0.7830376409014803\n",
      "AUPR+AUROCperdrug: 1.3659055568151195\n",
      "AUPR: 0.5683128653455478\n",
      "AUROC: 0.7453526163765305\n",
      "AUPR+AUROC: 1.3136654817220783\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.602402430253401\n",
      "AUROCperdrug: 0.7910354913435049\n",
      "AUPR+AUROCperdrug: 1.393437921596906\n",
      "AUPR: 0.5901622537428203\n",
      "AUROC: 0.753738501203955\n",
      "AUPR+AUROC: 1.3439007549467754\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5917763362286133, std: 0.006463528399004539\n",
      "Mean AUROCperdrug: 0.7912583357371621, std: 0.004284729858039069\n",
      "Mean AUPR+AUROCperdrug: 1.3830346719657751, std: 0.00926668924892078\n",
      "Mean AUPR: 0.576500440073664, std: 0.010321994404662908\n",
      "Mean AUROC: 0.7558110342746109, std: 0.006728187413126036\n",
      "Mean AUPR+AUROC: 1.3323114743482751, std: 0.014714967025565346\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5092501131752218\n",
      "AUPR for each fold: [0.52907113 0.52576302 0.48799874 0.49416757]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5478344996208087\n",
      "AUROCperdrug: 0.7563456446205247\n",
      "AUPR+AUROCperdrug: 1.3041801442413332\n",
      "AUPR: 0.5111746173388387\n",
      "AUROC: 0.7119186183197883\n",
      "AUPR+AUROC: 1.223093235658627\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5103289655454732\n",
      "AUPR for each fold: [0.53137822 0.52607749 0.48394137 0.49991878]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5492734004914587\n",
      "AUROCperdrug: 0.7566289145355087\n",
      "AUPR+AUROCperdrug: 1.3059023150269673\n",
      "AUPR: 0.5049858533316108\n",
      "AUROC: 0.7121137741756436\n",
      "AUPR+AUROC: 1.2170996275072543\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5093198776635557\n",
      "AUPR for each fold: [0.51641883 0.52669853 0.48654932 0.50761283]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5515708667008649\n",
      "AUROCperdrug: 0.7569608992809234\n",
      "AUPR+AUROCperdrug: 1.308531765981788\n",
      "AUPR: 0.5096265386336142\n",
      "AUROC: 0.7112464788008309\n",
      "AUPR+AUROC: 1.220873017434445\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5115967014523497\n",
      "AUPR for each fold: [0.51547756 0.51126746 0.51226454 0.50737725]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5454031874505569\n",
      "AUROCperdrug: 0.7536232047944886\n",
      "AUPR+AUROCperdrug: 1.2990263922450456\n",
      "AUPR: 0.4993465795758917\n",
      "AUROC: 0.6947798515369201\n",
      "AUPR+AUROC: 1.194126431112812\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5063823307920343\n",
      "AUPR for each fold: [0.49879087 0.51719292 0.51157153 0.497974  ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5637053949524574\n",
      "AUROCperdrug: 0.7564773307712566\n",
      "AUPR+AUROCperdrug: 1.320182725723714\n",
      "AUPR: 0.521021192414347\n",
      "AUROC: 0.7072852677396629\n",
      "AUPR+AUROC: 1.22830646015401\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5515574698432293, std: 0.006395700677559813\n",
      "Mean AUROCperdrug: 0.7560071988005403, std: 0.0012095513321256728\n",
      "Mean AUPR+AUROCperdrug: 1.3075646686437696, std: 0.007032371300961402\n",
      "Mean AUPR: 0.5092309562588604, std: 0.007192576362958403\n",
      "Mean AUROC: 0.7074687981145692, std: 0.006583169790959832\n",
      "Mean AUPR+AUROC: 1.2166997543734297, std: 0.01185515219766546\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5936471812651993\n",
      "AUROCperdrug: 0.7927440048153919\n",
      "AUPR+AUROCperdrug: 1.386391186080591\n",
      "AUPR: 0.584346901736029\n",
      "AUROC: 0.7609730469069491\n",
      "AUPR+AUROC: 1.345319948642978\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5954189392968415\n",
      "AUROCperdrug: 0.7942438890677364\n",
      "AUPR+AUROCperdrug: 1.3896628283645778\n",
      "AUPR: 0.5674088225077965\n",
      "AUROC: 0.7526728852274376\n",
      "AUPR+AUROC: 1.320081707735234\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.598898676529064\n",
      "AUROCperdrug: 0.7931551749313606\n",
      "AUPR+AUROCperdrug: 1.3920538514604246\n",
      "AUPR: 0.5890118570722052\n",
      "AUROC: 0.7622395487917066\n",
      "AUPR+AUROC: 1.3512514058639118\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5873907647557114\n",
      "AUROCperdrug: 0.7816551622873068\n",
      "AUPR+AUROCperdrug: 1.3690459270430182\n",
      "AUPR: 0.5742591449399584\n",
      "AUROC: 0.7443792528387825\n",
      "AUPR+AUROC: 1.318638397778741\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6070531871911137\n",
      "AUROCperdrug: 0.7896923911182815\n",
      "AUPR+AUROCperdrug: 1.3967455783093952\n",
      "AUPR: 0.5948769513721093\n",
      "AUROC: 0.750916298443149\n",
      "AUPR+AUROC: 1.3457932498152583\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.596481749807586, std: 0.006471586781423635\n",
      "Mean AUROCperdrug: 0.7902981244440154, std: 0.0045778124568036475\n",
      "Mean AUPR+AUROCperdrug: 1.3867798742516013, std: 0.009487733970504657\n",
      "Mean AUPR: 0.5819807355256197, std: 0.0099328888654708\n",
      "Mean AUROC: 0.7542362064416049, std: 0.006634211405939701\n",
      "Mean AUPR+AUROC: 1.336216941967225, std: 0.013928076010042338\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5141672385519029\n",
      "AUPR for each fold: [0.5341188  0.53047991 0.49318182 0.49888843]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5529194138048038\n",
      "AUROCperdrug: 0.7556664798179865\n",
      "AUPR+AUROCperdrug: 1.3085858936227903\n",
      "AUPR: 0.5165078521194693\n",
      "AUROC: 0.7105391652190081\n",
      "AUPR+AUROC: 1.2270470173384773\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5153351926674289\n",
      "AUPR for each fold: [0.53632949 0.5308359  0.48912635 0.50504903]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5541139147820701\n",
      "AUROCperdrug: 0.7554176515170151\n",
      "AUPR+AUROCperdrug: 1.3095315662990852\n",
      "AUPR: 0.5100461643889082\n",
      "AUROC: 0.7097971471026656\n",
      "AUPR+AUROC: 1.2198433114915739\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5143819674426465\n",
      "AUPR for each fold: [0.52140662 0.53143991 0.49206246 0.51261889]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5557755764135999\n",
      "AUROCperdrug: 0.7563285031116508\n",
      "AUPR+AUROCperdrug: 1.3121040795252505\n",
      "AUPR: 0.5145070308609404\n",
      "AUROC: 0.7082281512314642\n",
      "AUPR+AUROC: 1.2227351820924046\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5165987211870231\n",
      "AUPR for each fold: [0.52073952 0.51599558 0.51732509 0.5123347 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5500428956820096\n",
      "AUROCperdrug: 0.7516369988238042\n",
      "AUPR+AUROCperdrug: 1.301679894505814\n",
      "AUPR: 0.5043825304991227\n",
      "AUROC: 0.6924338615287365\n",
      "AUPR+AUROC: 1.1968163920278592\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5114904895064013\n",
      "AUPR for each fold: [0.50400178 0.52222595 0.51671273 0.50302149]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5680833096285929\n",
      "AUROCperdrug: 0.7546311658594135\n",
      "AUPR+AUROCperdrug: 1.3227144754880062\n",
      "AUPR: 0.52576257369281\n",
      "AUROC: 0.7036411129731858\n",
      "AUPR+AUROC: 1.2294036866659956\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5561870220622153, std: 0.006235643862161294\n",
      "Mean AUROCperdrug: 0.754736159825974, std: 0.0016420295979257175\n",
      "Mean AUPR+AUROCperdrug: 1.3109231818881892, std: 0.006830329362525509\n",
      "Mean AUPR: 0.5142412303122501, std: 0.007109741454482841\n",
      "Mean AUROC: 0.7049278876110121, std: 0.0066909542080135255\n",
      "Mean AUPR+AUROC: 1.219169117923262, std: 0.011658674042334305\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5979231524886918\n",
      "AUROCperdrug: 0.7910525251381968\n",
      "AUPR+AUROCperdrug: 1.3889756776268887\n",
      "AUPR: 0.5897747097089626\n",
      "AUROC: 0.7596181782070068\n",
      "AUPR+AUROC: 1.3493928879159696\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.599288042460995\n",
      "AUROCperdrug: 0.7915918713021292\n",
      "AUPR+AUROCperdrug: 1.3908799137631243\n",
      "AUPR: 0.5721094412602235\n",
      "AUROC: 0.7499914852266182\n",
      "AUPR+AUROC: 1.3221009264868417\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6032911497154991\n",
      "AUROCperdrug: 0.7912583380555793\n",
      "AUPR+AUROCperdrug: 1.3945494877710785\n",
      "AUPR: 0.5934330067972109\n",
      "AUROC: 0.7598009503071221\n",
      "AUPR+AUROC: 1.353233957104333\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5911911337657573\n",
      "AUROCperdrug: 0.7789155178895817\n",
      "AUPR+AUROCperdrug: 1.3701066516553388\n",
      "AUPR: 0.5787250041845933\n",
      "AUROC: 0.7423679383674471\n",
      "AUPR+AUROC: 1.3210929425520404\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6110612723694415\n",
      "AUROCperdrug: 0.7863807079578496\n",
      "AUPR+AUROCperdrug: 1.397441980327291\n",
      "AUPR: 0.5996497909318246\n",
      "AUROC: 0.7481352803869925\n",
      "AUPR+AUROC: 1.347785071318817\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.600550950160077, std: 0.0065434239651991286\n",
      "Mean AUROCperdrug: 0.7878397920686673, std: 0.004855055202174145\n",
      "Mean AUPR+AUROCperdrug: 1.388390742228744, std: 0.009598970259521269\n",
      "Mean AUPR: 0.586738390576563, std: 0.0099896135952941\n",
      "Mean AUROC: 0.7519827664990373, std: 0.006791712309800549\n",
      "Mean AUPR+AUROC: 1.3387211570756006, std: 0.014097146926409024\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5189877541789183\n",
      "AUPR for each fold: [0.53911486 0.53527214 0.49797181 0.50359221]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5573945919658403\n",
      "AUROCperdrug: 0.7531672635947497\n",
      "AUPR+AUROCperdrug: 1.31056185556059\n",
      "AUPR: 0.5215060554108553\n",
      "AUROC: 0.7085273641395059\n",
      "AUPR+AUROC: 1.2300334195503613\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 712]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5202620570160907\n",
      "AUPR for each fold: [0.54127528 0.53575269 0.49396365 0.51005662]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5581939387891083\n",
      "AUROCperdrug: 0.7524975374264028\n",
      "AUPR+AUROCperdrug: 1.310691476215511\n",
      "AUPR: 0.5146806701810758\n",
      "AUROC: 0.706481548416916\n",
      "AUPR+AUROC: 1.2211622185979918\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5191682314031844\n",
      "AUPR for each fold: [0.52609624 0.53634244 0.49682922 0.51740501]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5608213333772839\n",
      "AUROCperdrug: 0.7555602110786503\n",
      "AUPR+AUROCperdrug: 1.3163815444559344\n",
      "AUPR: 0.5196485144209237\n",
      "AUROC: 0.7065450705253825\n",
      "AUPR+AUROC: 1.2261935849463064\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 654 706]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5214081296941242\n",
      "AUPR for each fold: [0.52529302 0.52094632 0.52237452 0.51701866]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5544533001669222\n",
      "AUROCperdrug: 0.7489948659618212\n",
      "AUPR+AUROCperdrug: 1.3034481661287434\n",
      "AUPR: 0.5093126404195487\n",
      "AUROC: 0.6902097819880755\n",
      "AUPR+AUROC: 1.1995224224076242\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 651 689]\n",
      "first few testing idx:  [ 15  50 113 119 272 505 507 605 634 732]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5163812795368027\n",
      "AUPR for each fold: [0.50853373 0.5273998  0.52185579 0.5077358 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5721217214322873\n",
      "AUROCperdrug: 0.7501655825552324\n",
      "AUPR+AUROCperdrug: 1.3222873039875198\n",
      "AUPR: 0.5303978555893393\n",
      "AUROC: 0.7000581553676272\n",
      "AUPR+AUROC: 1.2304560109569664\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5605969771462884, std: 0.006109741362658142\n",
      "Mean AUROCperdrug: 0.7520770921233713, std: 0.0023087378667360006\n",
      "Mean AUPR+AUROCperdrug: 1.3126740692696597, std: 0.0063193206080119635\n",
      "Mean AUPR: 0.5191091472043485, std: 0.007057676343902139\n",
      "Mean AUROC: 0.7023643840875013, std: 0.00671512542596837\n",
      "Mean AUPR+AUROC: 1.2214735312918499, std: 0.01147330494037242\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6155787991070095\n",
      "AUROCperdrug: 0.7841437420106151\n",
      "AUPR+AUROCperdrug: 1.3997225411176246\n",
      "AUPR: 0.6011667604264792\n",
      "AUROC: 0.7464841104142907\n",
      "AUPR+AUROC: 1.34765087084077\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5945187082809448\n",
      "AUROCperdrug: 0.7860816090898108\n",
      "AUPR+AUROCperdrug: 1.3806003173707557\n",
      "AUPR: 0.568657603993051\n",
      "AUROC: 0.7414258861725966\n",
      "AUPR+AUROC: 1.3100834901656477\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6183216265328039\n",
      "AUROCperdrug: 0.7928802831571647\n",
      "AUPR+AUROCperdrug: 1.4112019096899686\n",
      "AUPR: 0.6025212882599195\n",
      "AUROC: 0.7541028833115252\n",
      "AUPR+AUROC: 1.3566241715714447\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5952657751268293\n",
      "AUROCperdrug: 0.7820774736239787\n",
      "AUPR+AUROCperdrug: 1.3773432487508082\n",
      "AUPR: 0.5919346701674763\n",
      "AUROC: 0.7527319264072199\n",
      "AUPR+AUROC: 1.344666596574696\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5966399099211\n",
      "AUROCperdrug: 0.7883911418457461\n",
      "AUPR+AUROCperdrug: 1.385031051766846\n",
      "AUPR: 0.5795036244386753\n",
      "AUROC: 0.7438682570745621\n",
      "AUPR+AUROC: 1.3233718815132374\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6040649637937375, std: 0.010578364491730965\n",
      "Mean AUROCperdrug: 0.786714849945463, std: 0.003723959461752439\n",
      "Mean AUPR+AUROCperdrug: 1.3907798137392007, std: 0.012761238695396743\n",
      "Mean AUPR: 0.5887567894571203, std: 0.012985885042918501\n",
      "Mean AUROC: 0.747722612676039, std: 0.004936391132266371\n",
      "Mean AUPR+AUROC: 1.336479402133159, std: 0.017124221833581976\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5178326389170964\n",
      "AUPR for each fold: [0.51414954 0.51316238 0.5310621  0.51295654]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5777343168833023\n",
      "AUROCperdrug: 0.7497678461940539\n",
      "AUPR+AUROCperdrug: 1.3275021630773562\n",
      "AUPR: 0.5435077360900579\n",
      "AUROC: 0.7030564298176039\n",
      "AUPR+AUROC: 1.2465641659076616\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5263546926343114\n",
      "AUPR for each fold: [0.52756992 0.52404364 0.52979559 0.52400962]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5516217946961932\n",
      "AUROCperdrug: 0.7448929280317583\n",
      "AUPR+AUROCperdrug: 1.2965147227279514\n",
      "AUPR: 0.5089827535732374\n",
      "AUROC: 0.6952787650784104\n",
      "AUPR+AUROC: 1.2042615186516477\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5210579813663465\n",
      "AUPR for each fold: [0.51656431 0.51726515 0.51329168 0.53711078]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5757472124929185\n",
      "AUROCperdrug: 0.7579417650187557\n",
      "AUPR+AUROCperdrug: 1.3336889775116743\n",
      "AUPR: 0.5301468340624862\n",
      "AUROC: 0.7038835501351419\n",
      "AUPR+AUROC: 1.2340303841976281\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5238791101755507\n",
      "AUPR for each fold: [0.53419878 0.52486489 0.49569836 0.54075441]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5590511030343887\n",
      "AUROCperdrug: 0.7497262561102764\n",
      "AUPR+AUROCperdrug: 1.3087773591446652\n",
      "AUPR: 0.5193799669788552\n",
      "AUROC: 0.6977138548486527\n",
      "AUPR+AUROC: 1.217093821827508\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5245101850684083\n",
      "AUPR for each fold: [0.53222214 0.53353579 0.4813099  0.55097291]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5581863028654701\n",
      "AUROCperdrug: 0.754861152754761\n",
      "AUPR+AUROCperdrug: 1.313047455620231\n",
      "AUPR: 0.5149319936748427\n",
      "AUROC: 0.6977545163676775\n",
      "AUPR+AUROC: 1.2126865100425201\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5644681459944546, std: 0.010363814744924706\n",
      "Mean AUROCperdrug: 0.751437989621921, std: 0.004529335098004206\n",
      "Mean AUPR+AUROCperdrug: 1.3159061356163755, std: 0.01330951327331183\n",
      "Mean AUPR: 0.5233898568758959, std: 0.01221118419534571\n",
      "Mean AUROC: 0.6995374232494973, std: 0.003344026142615072\n",
      "Mean AUPR+AUROC: 1.222927280125393, std: 0.015292446164829738\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6175037240824601\n",
      "AUROCperdrug: 0.7836204576589552\n",
      "AUPR+AUROCperdrug: 1.4011241817414153\n",
      "AUPR: 0.6035439038287825\n",
      "AUROC: 0.7456060254587329\n",
      "AUPR+AUROC: 1.3491499292875155\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5959689005264956\n",
      "AUROCperdrug: 0.7845277547811584\n",
      "AUPR+AUROCperdrug: 1.380496655307654\n",
      "AUPR: 0.5707050761836844\n",
      "AUROC: 0.739937615355569\n",
      "AUPR+AUROC: 1.3106426915392535\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6200543169773416\n",
      "AUROCperdrug: 0.7918145202502547\n",
      "AUPR+AUROCperdrug: 1.4118688372275963\n",
      "AUPR: 0.6046852159483936\n",
      "AUROC: 0.7531551763899924\n",
      "AUPR+AUROC: 1.3578403923383862\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5973344142778699\n",
      "AUROCperdrug: 0.781657242596087\n",
      "AUPR+AUROCperdrug: 1.378991656873957\n",
      "AUPR: 0.5943758554603493\n",
      "AUROC: 0.7523269022131361\n",
      "AUPR+AUROC: 1.3467027576734854\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5985625495865401\n",
      "AUROCperdrug: 0.7868603820674781\n",
      "AUPR+AUROCperdrug: 1.385422931654018\n",
      "AUPR: 0.5815942112262033\n",
      "AUROC: 0.7425877618896124\n",
      "AUPR+AUROC: 1.3241819731158158\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6058847810901414, std: 0.010590789561563566\n",
      "Mean AUROCperdrug: 0.7856960714707867, std: 0.003486439728283812\n",
      "Mean AUPR+AUROCperdrug: 1.3915808525609283, std: 0.012821425196694766\n",
      "Mean AUPR: 0.5909808525294825, std: 0.013087261141646735\n",
      "Mean AUROC: 0.7467226962614086, std: 0.005237669019581191\n",
      "Mean AUPR+AUROC: 1.3377035487908913, std: 0.017507831727387933\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5199009378575284\n",
      "AUPR for each fold: [0.51593648 0.51518054 0.53344418 0.51504255]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5798783836240478\n",
      "AUROCperdrug: 0.7493449601765954\n",
      "AUPR+AUROCperdrug: 1.329223343800643\n",
      "AUPR: 0.545767121371064\n",
      "AUROC: 0.701998079376227\n",
      "AUPR+AUROC: 1.247765200747291\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5285659219917748\n",
      "AUPR for each fold: [0.52962656 0.52609049 0.53220271 0.52634393]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5528548841998685\n",
      "AUROCperdrug: 0.7422542417429285\n",
      "AUPR+AUROCperdrug: 1.2951091259427971\n",
      "AUPR: 0.5107541253634436\n",
      "AUROC: 0.692652214335016\n",
      "AUPR+AUROC: 1.2034063396984596\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5231339743643557\n",
      "AUPR for each fold: [0.51856419 0.51908574 0.5155259  0.53936006]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5775704940926596\n",
      "AUROCperdrug: 0.7570710473179135\n",
      "AUPR+AUROCperdrug: 1.3346415414105732\n",
      "AUPR: 0.5324082040072663\n",
      "AUROC: 0.7028427201597439\n",
      "AUPR+AUROC: 1.2352509241670102\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5259411019067536\n",
      "AUPR for each fold: [0.53619005 0.52677814 0.49787927 0.54291695]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5612162908827739\n",
      "AUROCperdrug: 0.749521107696702\n",
      "AUPR+AUROCperdrug: 1.310737398579476\n",
      "AUPR: 0.5217399231326046\n",
      "AUROC: 0.6970523929193225\n",
      "AUPR+AUROC: 1.2187923160519272\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5266699912486439\n",
      "AUPR for each fold: [0.53433184 0.5356562  0.48327137 0.55342057]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5601133953854245\n",
      "AUROCperdrug: 0.7529700477070124\n",
      "AUPR+AUROCperdrug: 1.3130834430924367\n",
      "AUPR: 0.5169155971720109\n",
      "AUROC: 0.6959201465475566\n",
      "AUPR+AUROC: 1.2128357437195674\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.566326689636955, std: 0.010547817700126215\n",
      "Mean AUROCperdrug: 0.7502322809282304, std: 0.004882751424993875\n",
      "Mean AUPR+AUROCperdrug: 1.3165589705651854, std: 0.014095613103009559\n",
      "Mean AUPR: 0.5255169942092779, std: 0.012359199132780828\n",
      "Mean AUROC: 0.6980931106675733, std: 0.00382663795893266\n",
      "Mean AUPR+AUROC: 1.223610104876851, std: 0.01591519654386346\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6202726066059856\n",
      "AUROCperdrug: 0.7824898395552548\n",
      "AUPR+AUROCperdrug: 1.4027624461612405\n",
      "AUPR: 0.6067995293412267\n",
      "AUROC: 0.7439394091843706\n",
      "AUPR+AUROC: 1.3507389385255975\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5984589739336716\n",
      "AUROCperdrug: 0.7828484328614852\n",
      "AUPR+AUROCperdrug: 1.3813074067951567\n",
      "AUPR: 0.5739353952478219\n",
      "AUROC: 0.7390331246444564\n",
      "AUPR+AUROC: 1.3129685198922783\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6226618177603995\n",
      "AUROCperdrug: 0.7898372967473536\n",
      "AUPR+AUROCperdrug: 1.412499114507753\n",
      "AUPR: 0.6080022723985844\n",
      "AUROC: 0.7516870495147019\n",
      "AUPR+AUROC: 1.3596893219132862\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5998179662814177\n",
      "AUROCperdrug: 0.7790912308441466\n",
      "AUPR+AUROCperdrug: 1.3789091971255643\n",
      "AUPR: 0.5977349852715438\n",
      "AUROC: 0.7508497989449785\n",
      "AUPR+AUROC: 1.3485847842165222\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6007968564355021\n",
      "AUROCperdrug: 0.784974119406892\n",
      "AUPR+AUROCperdrug: 1.385770975842394\n",
      "AUPR: 0.58502443770189\n",
      "AUROC: 0.7421329596416578\n",
      "AUPR+AUROC: 1.327157397343548\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6084016442033953, std: 0.010720460008740166\n",
      "Mean AUROCperdrug: 0.7838481838830265, std: 0.003538655319115502\n",
      "Mean AUPR+AUROCperdrug: 1.3922498280864217, std: 0.013116655701125794\n",
      "Mean AUPR: 0.5942993239922134, std: 0.013088489651801231\n",
      "Mean AUROC: 0.745528468386033, std: 0.004949520371444464\n",
      "Mean AUPR+AUROC: 1.3398277923782462, std: 0.017159124689718502\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5229761805140101\n",
      "AUPR for each fold: [0.51906657 0.51801386 0.53649317 0.51833113]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5826765427867441\n",
      "AUROCperdrug: 0.747899282086976\n",
      "AUPR+AUROCperdrug: 1.33057582487372\n",
      "AUPR: 0.5486442559561342\n",
      "AUROC: 0.6990780372899015\n",
      "AUPR+AUROC: 1.2477222932460357\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5315949622852858\n",
      "AUPR for each fold: [0.53254329 0.52888516 0.53524235 0.52970905]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5555733334472709\n",
      "AUROCperdrug: 0.7398806678335103\n",
      "AUPR+AUROCperdrug: 1.2954540012807811\n",
      "AUPR: 0.5137737805332074\n",
      "AUROC: 0.6905145472661959\n",
      "AUPR+AUROC: 1.2042883277994032\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.526168336469469\n",
      "AUPR for each fold: [0.52150901 0.522032   0.51858053 0.5425518 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5804675273124046\n",
      "AUROCperdrug: 0.754764868602591\n",
      "AUPR+AUROCperdrug: 1.3352323959149954\n",
      "AUPR: 0.5354062687555714\n",
      "AUROC: 0.7004184046104907\n",
      "AUPR+AUROC: 1.235824673366062\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5290134343867792\n",
      "AUPR for each fold: [0.5392606  0.52971211 0.50089203 0.54618899]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5636584692063499\n",
      "AUROCperdrug: 0.7463171786005796\n",
      "AUPR+AUROCperdrug: 1.3099756478069295\n",
      "AUPR: 0.5246266825330234\n",
      "AUROC: 0.6942469012456003\n",
      "AUPR+AUROC: 1.2188735837786235\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5296067775571449\n",
      "AUPR for each fold: [0.53723584 0.53852499 0.48607522 0.55659106]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5626555473881665\n",
      "AUROCperdrug: 0.7512508781269831\n",
      "AUPR+AUROCperdrug: 1.3139064255151496\n",
      "AUPR: 0.5202776126786955\n",
      "AUROC: 0.6951081513818562\n",
      "AUPR+AUROC: 1.2153857640605517\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5690062840281872, std: 0.010654681719270864\n",
      "Mean AUROCperdrug: 0.7480225750501279, std: 0.005001893530104835\n",
      "Mean AUPR+AUROCperdrug: 1.3170288590783152, std: 0.014421240620731938\n",
      "Mean AUPR: 0.5285457200913264, std: 0.012271502970397311\n",
      "Mean AUROC: 0.695873208358809, std: 0.0035461295281986336\n",
      "Mean AUPR+AUROC: 1.2244189284501352, std: 0.015431965635474694\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6237838055044371\n",
      "AUROCperdrug: 0.7785189609234455\n",
      "AUPR+AUROCperdrug: 1.4023027664278827\n",
      "AUPR: 0.6113621394989912\n",
      "AUROC: 0.7406136431593984\n",
      "AUPR+AUROC: 1.3519757826583896\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6024162037504192\n",
      "AUROCperdrug: 0.7802638634829464\n",
      "AUPR+AUROCperdrug: 1.3826800672333657\n",
      "AUPR: 0.5783884860555534\n",
      "AUROC: 0.7369417888371164\n",
      "AUPR+AUROC: 1.3153302748926698\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6269852375565825\n",
      "AUROCperdrug: 0.787350984819763\n",
      "AUPR+AUROCperdrug: 1.4143362223763454\n",
      "AUPR: 0.6121931178120563\n",
      "AUROC: 0.7490184436898365\n",
      "AUPR+AUROC: 1.361211561501893\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6044589778995307\n",
      "AUROCperdrug: 0.7776541431136472\n",
      "AUPR+AUROCperdrug: 1.382113121013178\n",
      "AUPR: 0.6025999455504697\n",
      "AUROC: 0.7493696035302705\n",
      "AUPR+AUROC: 1.3519695490807402\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6046502212982674\n",
      "AUROCperdrug: 0.7833579658582961\n",
      "AUPR+AUROCperdrug: 1.3880081871565635\n",
      "AUPR: 0.5895655157030559\n",
      "AUROC: 0.7403986303977044\n",
      "AUPR+AUROC: 1.3299641461007603\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6124588892018474, std: 0.010631067040833123\n",
      "Mean AUROCperdrug: 0.7814291836396197, std: 0.003545877278255639\n",
      "Mean AUPR+AUROCperdrug: 1.393888072841467, std: 0.012552098019783787\n",
      "Mean AUPR: 0.5988218409240254, std: 0.013065418143414347\n",
      "Mean AUROC: 0.7432684219228651, std: 0.005011925921434106\n",
      "Mean AUPR+AUROC: 1.3420902628468905, std: 0.01687653710533345\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5275763030252447\n",
      "AUPR for each fold: [0.52322946 0.52254887 0.54165637 0.52287051]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5863683515768415\n",
      "AUROCperdrug: 0.7432963047535498\n",
      "AUPR+AUROCperdrug: 1.3296646563303913\n",
      "AUPR: 0.55288548800481\n",
      "AUROC: 0.6944918426982554\n",
      "AUPR+AUROC: 1.2473773307030653\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5361109959578614\n",
      "AUPR for each fold: [0.53681931 0.53316677 0.54012844 0.53432946]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5593822102043442\n",
      "AUROCperdrug: 0.7359481618189246\n",
      "AUPR+AUROCperdrug: 1.295330372023269\n",
      "AUPR: 0.5183406377257864\n",
      "AUROC: 0.6875507724814309\n",
      "AUPR+AUROC: 1.2058914102072174\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.530757112407273\n",
      "AUPR for each fold: [0.52597803 0.52650835 0.5233422  0.54719988]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5845601422884753\n",
      "AUROCperdrug: 0.7509324827490172\n",
      "AUPR+AUROCperdrug: 1.3354926250374926\n",
      "AUPR: 0.5397381248151076\n",
      "AUROC: 0.6962201801631924\n",
      "AUPR+AUROC: 1.2359583049783\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5334601668102459\n",
      "AUPR for each fold: [0.54379613 0.53405583 0.50538083 0.55060787]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5681535061506249\n",
      "AUROCperdrug: 0.7442518505993232\n",
      "AUPR+AUROCperdrug: 1.312405356749948\n",
      "AUPR: 0.5294821079869554\n",
      "AUROC: 0.6920068390472764\n",
      "AUPR+AUROC: 1.2214889470342318\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5340980220982343\n",
      "AUPR for each fold: [0.54184741 0.54287118 0.4903629  0.5613106 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5665787470048534\n",
      "AUROCperdrug: 0.7490234698732974\n",
      "AUPR+AUROCperdrug: 1.3156022168781507\n",
      "AUPR: 0.524970437975823\n",
      "AUROC: 0.6927567726361439\n",
      "AUPR+AUROC: 1.217727210611967\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5730085914450278, std: 0.010606738764819042\n",
      "Mean AUROCperdrug: 0.7446904539588225, std: 0.005221142539819405\n",
      "Mean AUPR+AUROCperdrug: 1.3176990454038502, std: 0.014089462014299167\n",
      "Mean AUPR: 0.5330833593016965, std: 0.012104103008068781\n",
      "Mean AUROC: 0.6926052814052598, std: 0.0029173875249017267\n",
      "Mean AUPR+AUROC: 1.2256886407069563, std: 0.014483213797740833\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6271128767811447\n",
      "AUROCperdrug: 0.7759940690857636\n",
      "AUPR+AUROCperdrug: 1.4031069458669083\n",
      "AUPR: 0.6156726839224693\n",
      "AUROC: 0.738946072231877\n",
      "AUPR+AUROC: 1.3546187561543463\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6062943859790698\n",
      "AUROCperdrug: 0.7798734346836582\n",
      "AUPR+AUROCperdrug: 1.386167820662728\n",
      "AUPR: 0.5827055462784029\n",
      "AUROC: 0.7362018864980002\n",
      "AUPR+AUROC: 1.318907432776403\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.629756613755326\n",
      "AUROCperdrug: 0.7846959441258052\n",
      "AUPR+AUROCperdrug: 1.4144525578811313\n",
      "AUPR: 0.615931069604472\n",
      "AUROC: 0.7471430434799722\n",
      "AUPR+AUROC: 1.3630741130844441\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.607312797902684\n",
      "AUROCperdrug: 0.7752531816730073\n",
      "AUPR+AUROCperdrug: 1.3825659795756913\n",
      "AUPR: 0.6067696472730822\n",
      "AUROC: 0.7480998072896563\n",
      "AUPR+AUROC: 1.3548694545627384\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6074001476696357\n",
      "AUROCperdrug: 0.7800256380079974\n",
      "AUPR+AUROCperdrug: 1.387425785677633\n",
      "AUPR: 0.593570806137479\n",
      "AUROC: 0.7387632237574403\n",
      "AUPR+AUROC: 1.3323340298949193\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6155753644175721, std: 0.010540045155347011\n",
      "Mean AUROCperdrug: 0.7791684535152463, std: 0.0033820403976598913\n",
      "Mean AUPR+AUROCperdrug: 1.3947438179328184, std: 0.012114267716284216\n",
      "Mean AUPR: 0.6029299506431811, std: 0.012982832770016446\n",
      "Mean AUROC: 0.7418308066513892, std: 0.004836046498972925\n",
      "Mean AUPR+AUROC: 1.3447607572945703, std: 0.016477638451988373\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5313902046612524\n",
      "AUPR for each fold: [0.52688048 0.52640323 0.54572345 0.52655365]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5896882249974387\n",
      "AUROCperdrug: 0.7399437797650037\n",
      "AUPR+AUROCperdrug: 1.3296320047624424\n",
      "AUPR: 0.5566479924571728\n",
      "AUROC: 0.6913923131969215\n",
      "AUPR+AUROC: 1.2480403056540943\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5398476614568094\n",
      "AUPR for each fold: [0.54041939 0.53669816 0.54401977 0.53825332]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5630977124674733\n",
      "AUROCperdrug: 0.7349254999802735\n",
      "AUPR+AUROCperdrug: 1.2980232124477467\n",
      "AUPR: 0.5223957627802907\n",
      "AUROC: 0.685925959317735\n",
      "AUPR+AUROC: 1.2083217220980256\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5345305380671619\n",
      "AUPR for each fold: [0.52966322 0.52988633 0.52736019 0.55121241]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5876624304829191\n",
      "AUROCperdrug: 0.7481579823289395\n",
      "AUPR+AUROCperdrug: 1.3358204128118585\n",
      "AUPR: 0.5436373970679175\n",
      "AUROC: 0.693641864800217\n",
      "AUPR+AUROC: 1.2372792618681343\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5372979530164974\n",
      "AUPR for each fold: [0.54790063 0.53756312 0.50931346 0.55441461]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5709823795690782\n",
      "AUROCperdrug: 0.7409814207053954\n",
      "AUPR+AUROCperdrug: 1.3119638002744736\n",
      "AUPR: 0.5332091083422748\n",
      "AUROC: 0.6888557713677463\n",
      "AUPR+AUROC: 1.222064879710021\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5379790328223495\n",
      "AUPR for each fold: [0.545931   0.5461823  0.49442236 0.56538048]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5692844268209288\n",
      "AUROCperdrug: 0.7446193680797119\n",
      "AUPR+AUROCperdrug: 1.3139037949006407\n",
      "AUPR: 0.5285816172039759\n",
      "AUROC: 0.689559106797516\n",
      "AUPR+AUROC: 1.2181407240014919\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5761430348675677, std: 0.010583212697163214\n",
      "Mean AUROCperdrug: 0.7417256101718648, std: 0.004465858989599655\n",
      "Mean AUPR+AUROCperdrug: 1.3178686450394324, std: 0.013454151933143388\n",
      "Mean AUPR: 0.5368943755703264, std: 0.01207117755700866\n",
      "Mean AUROC: 0.6898750030960272, std: 0.0025777915971227283\n",
      "Mean AUPR+AUROC: 1.2267693786663534, std: 0.014140806231975726\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.627384934123718\n",
      "AUROCperdrug: 0.7754532511613029\n",
      "AUPR+AUROCperdrug: 1.402838185285021\n",
      "AUPR: 0.6161190591707348\n",
      "AUROC: 0.7384897279700231\n",
      "AUPR+AUROC: 1.354608787140758\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6065887563589297\n",
      "AUROCperdrug: 0.779520427406974\n",
      "AUPR+AUROCperdrug: 1.3861091837659036\n",
      "AUPR: 0.5832491119153878\n",
      "AUROC: 0.7361756041493317\n",
      "AUPR+AUROC: 1.3194247160647194\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6301193625080043\n",
      "AUROCperdrug: 0.7844625833051756\n",
      "AUPR+AUROCperdrug: 1.4145819458131799\n",
      "AUPR: 0.6164550022967225\n",
      "AUROC: 0.747093352112581\n",
      "AUPR+AUROC: 1.3635483544093034\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6076672403380387\n",
      "AUROCperdrug: 0.7749022522860759\n",
      "AUPR+AUROCperdrug: 1.3825694926241145\n",
      "AUPR: 0.607399049386286\n",
      "AUROC: 0.7481131054636343\n",
      "AUPR+AUROC: 1.3555121548499203\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6076377226399802\n",
      "AUROCperdrug: 0.7794703454981482\n",
      "AUPR+AUROCperdrug: 1.3871080681381285\n",
      "AUPR: 0.5939930936090556\n",
      "AUROC: 0.738395901738562\n",
      "AUPR+AUROC: 1.3323889953476176\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6158796031937341, std: 0.010553053764484815\n",
      "Mean AUROCperdrug: 0.7787617719315354, std: 0.0034472912997972295\n",
      "Mean AUPR+AUROCperdrug: 1.3946413751252693, std: 0.012166292835795053\n",
      "Mean AUPR: 0.6034430632756373, std: 0.012982594912944422\n",
      "Mean AUROC: 0.7416535382868265, std: 0.004938567334492744\n",
      "Mean AUPR+AUROC: 1.3450966015624637, std: 0.016492189476243004\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5319029960139013\n",
      "AUPR for each fold: [0.52729648 0.52689499 0.54640889 0.52701163]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5899354011592173\n",
      "AUROCperdrug: 0.7391095910783664\n",
      "AUPR+AUROCperdrug: 1.3290449922375838\n",
      "AUPR: 0.5570572978219126\n",
      "AUROC: 0.6907151047518454\n",
      "AUPR+AUROC: 1.247772402573758\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5403354537558772\n",
      "AUPR for each fold: [0.5407793  0.53714245 0.54463145 0.53878861]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5634262857163316\n",
      "AUROCperdrug: 0.734414985530451\n",
      "AUPR+AUROCperdrug: 1.2978412712467826\n",
      "AUPR: 0.5228918163410601\n",
      "AUROC: 0.6856305825091872\n",
      "AUPR+AUROC: 1.2085223988502474\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5349986880086075\n",
      "AUPR for each fold: [0.53001919 0.53032134 0.52791966 0.55173456]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5880522531030311\n",
      "AUROCperdrug: 0.7478627351595653\n",
      "AUPR+AUROCperdrug: 1.3359149882625965\n",
      "AUPR: 0.5442061735784003\n",
      "AUROC: 0.6935678336488468\n",
      "AUPR+AUROC: 1.2377740072272472\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5377865288105679\n",
      "AUPR for each fold: [0.54834982 0.5380277  0.50977669 0.55499191]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5713165050853329\n",
      "AUROCperdrug: 0.7403759080277715\n",
      "AUPR+AUROCperdrug: 1.3116924131131045\n",
      "AUPR: 0.5337100178229404\n",
      "AUROC: 0.6885366111516551\n",
      "AUPR+AUROC: 1.2222466289745955\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5384672401626651\n",
      "AUPR for each fold: [0.54643727 0.546622   0.49488309 0.5659266 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5696116805536053\n",
      "AUROCperdrug: 0.744077034322669\n",
      "AUPR+AUROCperdrug: 1.3136887148762744\n",
      "AUPR: 0.5290727253901402\n",
      "AUROC: 0.6892589938284968\n",
      "AUPR+AUROC: 1.218331719218637\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5764684251235037, std: 0.010575435127675966\n",
      "Mean AUROCperdrug: 0.7411680508237646, std: 0.004555208468145836\n",
      "Mean AUPR+AUROCperdrug: 1.3176364759472683, std: 0.013468667981595435\n",
      "Mean AUPR: 0.5373876061908908, std: 0.012051385417309733\n",
      "Mean AUROC: 0.6895418251780063, std: 0.0026066682639375957\n",
      "Mean AUPR+AUROC: 1.2269294313688968, std: 0.014047792800433858\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6284169073097062\n",
      "AUROCperdrug: 0.7757716915326474\n",
      "AUPR+AUROCperdrug: 1.4041885988423535\n",
      "AUPR: 0.6173063408143056\n",
      "AUROC: 0.7384424187225983\n",
      "AUPR+AUROC: 1.3557487595369038\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6077912814170635\n",
      "AUROCperdrug: 0.7787615507723404\n",
      "AUPR+AUROCperdrug: 1.386552832189404\n",
      "AUPR: 0.5841145733580109\n",
      "AUROC: 0.7352323477459526\n",
      "AUPR+AUROC: 1.3193469211039635\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6312418428140766\n",
      "AUROCperdrug: 0.7843345796854592\n",
      "AUPR+AUROCperdrug: 1.4155764224995357\n",
      "AUPR: 0.6174809757640922\n",
      "AUROC: 0.7467310363491395\n",
      "AUPR+AUROC: 1.3642120121132317\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6089379015022861\n",
      "AUROCperdrug: 0.7750370095764015\n",
      "AUPR+AUROCperdrug: 1.3839749110786876\n",
      "AUPR: 0.6085301185908729\n",
      "AUROC: 0.7480947470359798\n",
      "AUPR+AUROC: 1.3566248656268527\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6085635126402203\n",
      "AUROCperdrug: 0.778804222034513\n",
      "AUPR+AUROCperdrug: 1.3873677346747333\n",
      "AUPR: 0.5951073288484117\n",
      "AUROC: 0.7378552820270327\n",
      "AUPR+AUROC: 1.3329626108754442\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6169902891366705, std: 0.010527560371265867\n",
      "Mean AUROCperdrug: 0.7785418107202723, std: 0.003275072794430141\n",
      "Mean AUPR+AUROCperdrug: 1.3955320998569427, std: 0.012309041912470595\n",
      "Mean AUPR: 0.6045078674751386, std: 0.013057852303871206\n",
      "Mean AUROC: 0.7412711663761404, std: 0.005147986844691698\n",
      "Mean AUPR+AUROC: 1.345779033851279, std: 0.016850634806668735\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5329375095000659\n",
      "AUPR for each fold: [0.52818342 0.52798919 0.54757735 0.52800008]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5909760680927502\n",
      "AUROCperdrug: 0.7390858885303854\n",
      "AUPR+AUROCperdrug: 1.3300619566231355\n",
      "AUPR: 0.558204527971949\n",
      "AUROC: 0.6905925174680568\n",
      "AUPR+AUROC: 1.2487970454400057\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.541448419916123\n",
      "AUPR for each fold: [0.54184049 0.53829844 0.54586081 0.53979395]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5646267866869656\n",
      "AUROCperdrug: 0.7333900840108086\n",
      "AUPR+AUROCperdrug: 1.2980168706977744\n",
      "AUPR: 0.5237587046213893\n",
      "AUROC: 0.6845322274545422\n",
      "AUPR+AUROC: 1.2082909320759314\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5360382808548526\n",
      "AUPR for each fold: [0.53096263 0.53149063 0.52903223 0.55266764]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.589270755966454\n",
      "AUROCperdrug: 0.7480804430759953\n",
      "AUPR+AUROCperdrug: 1.3373511990424491\n",
      "AUPR: 0.5453643165617217\n",
      "AUROC: 0.693460740456447\n",
      "AUPR+AUROC: 1.2388250570181687\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5388073812231475\n",
      "AUPR for each fold: [0.54937667 0.53906866 0.51093091 0.55585328]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5726438902261451\n",
      "AUROCperdrug: 0.7405886321648386\n",
      "AUPR+AUROCperdrug: 1.3132325223909838\n",
      "AUPR: 0.5349328903735411\n",
      "AUROC: 0.68869061058504\n",
      "AUPR+AUROC: 1.2236235009585812\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5395836637575568\n",
      "AUPR for each fold: [0.54750445 0.54772269 0.49615623 0.56695129]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5705249528244697\n",
      "AUROCperdrug: 0.7433190652250631\n",
      "AUPR+AUROCperdrug: 1.3138440180495328\n",
      "AUPR: 0.5299756577326488\n",
      "AUROC: 0.6883186920600293\n",
      "AUPR+AUROC: 1.2182943497926781\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5776084907593569, std: 0.010564553585243516\n",
      "Mean AUROCperdrug: 0.7408928226014182, std: 0.0048414289269416945\n",
      "Mean AUPR+AUROCperdrug: 1.3185013133607753, std: 0.013842179105653692\n",
      "Mean AUPR: 0.5384472194522499, std: 0.012149632151989774\n",
      "Mean AUROC: 0.689118957604823, std: 0.002928633011636169\n",
      "Mean AUPR+AUROC: 1.2275661770570732, std: 0.014495231595205311\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6294983666002151\n",
      "AUROCperdrug: 0.7743984295863662\n",
      "AUPR+AUROCperdrug: 1.4038967961865811\n",
      "AUPR: 0.6187943841974789\n",
      "AUROC: 0.7375438538000683\n",
      "AUPR+AUROC: 1.356338237997547\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.60890275409282\n",
      "AUROCperdrug: 0.7775717455546175\n",
      "AUPR+AUROCperdrug: 1.3864744996474374\n",
      "AUPR: 0.5859396785220031\n",
      "AUROC: 0.7348539018428235\n",
      "AUPR+AUROC: 1.3207935803648265\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6328179899339732\n",
      "AUROCperdrug: 0.7840157778516362\n",
      "AUPR+AUROCperdrug: 1.4168337677856093\n",
      "AUPR: 0.6191287584303964\n",
      "AUROC: 0.7462740744272722\n",
      "AUPR+AUROC: 1.3654028328576686\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6099539648087112\n",
      "AUROCperdrug: 0.773605297892203\n",
      "AUPR+AUROCperdrug: 1.3835592627009143\n",
      "AUPR: 0.6098904142595414\n",
      "AUROC: 0.7472525569897932\n",
      "AUPR+AUROC: 1.3571429712493346\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6096723804158409\n",
      "AUROCperdrug: 0.7776187676381929\n",
      "AUPR+AUROCperdrug: 1.3872911480540338\n",
      "AUPR: 0.5965205122886517\n",
      "AUROC: 0.7369902868210544\n",
      "AUPR+AUROC: 1.333510799109706\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.618169091170312, std: 0.01066292750018038\n",
      "Mean AUROCperdrug: 0.7774420037046033, std: 0.0036673216350947683\n",
      "Mean AUPR+AUROCperdrug: 1.3956110948749152, std: 0.012782802806143889\n",
      "Mean AUPR: 0.6060547495396144, std: 0.012988133703785095\n",
      "Mean AUROC: 0.7405829347762024, std: 0.005134936842082338\n",
      "Mean AUPR+AUROC: 1.3466376843158165, std: 0.016714218015386997\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5344636647369186\n",
      "AUPR for each fold: [0.52965612 0.52938058 0.54941342 0.52940454]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.592054549540762\n",
      "AUROCperdrug: 0.7371874301111343\n",
      "AUPR+AUROCperdrug: 1.3292419796518962\n",
      "AUPR: 0.5596806483435904\n",
      "AUROC: 0.6893663044407962\n",
      "AUPR+AUROC: 1.2490469527843866\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.542992770155393\n",
      "AUPR for each fold: [0.54329023 0.5397383  0.54762811 0.54131444]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5656863054288662\n",
      "AUROCperdrug: 0.7317571432478981\n",
      "AUPR+AUROCperdrug: 1.2974434486767643\n",
      "AUPR: 0.5252026576362632\n",
      "AUROC: 0.6833329267683546\n",
      "AUPR+AUROC: 1.2085355844046177\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5375121375076809\n",
      "AUPR for each fold: [0.53235686 0.53283566 0.53069615 0.55415988]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5910016414656531\n",
      "AUROCperdrug: 0.7478958522144677\n",
      "AUPR+AUROCperdrug: 1.338897493680121\n",
      "AUPR: 0.5470581531061524\n",
      "AUROC: 0.6930573286658729\n",
      "AUPR+AUROC: 1.2401154817720252\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5403352608151375\n",
      "AUPR for each fold: [0.55083761 0.54064636 0.51237346 0.55748361]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5735904550291394\n",
      "AUROCperdrug: 0.7387676067210683\n",
      "AUPR+AUROCperdrug: 1.3123580617502077\n",
      "AUPR: 0.5364262111351286\n",
      "AUROC: 0.6875578593878059\n",
      "AUPR+AUROC: 1.2239840705229343\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5410966204106653\n",
      "AUPR for each fold: [0.54890877 0.54940325 0.49745732 0.56861713]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5717134350171511\n",
      "AUROCperdrug: 0.741783973036632\n",
      "AUPR+AUROCperdrug: 1.3134974080537831\n",
      "AUPR: 0.5314919868518226\n",
      "AUROC: 0.6874358305848687\n",
      "AUPR+AUROC: 1.2189278174366913\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5788092772963144, std: 0.010713453738251432\n",
      "Mean AUROCperdrug: 0.7394784010662401, std: 0.005320540287584147\n",
      "Mean AUPR+AUROCperdrug: 1.3182876783625546, std: 0.014403820036062403\n",
      "Mean AUPR: 0.5399719314145914, std: 0.012175886833215901\n",
      "Mean AUROC: 0.6881500499695397, std: 0.003150432798593462\n",
      "Mean AUPR+AUROC: 1.228121981384131, std: 0.014608082579740776\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6315860037796532\n",
      "AUROCperdrug: 0.7724923119624958\n",
      "AUPR+AUROCperdrug: 1.404078315742149\n",
      "AUPR: 0.6217153001341598\n",
      "AUROC: 0.7364119550245554\n",
      "AUPR+AUROC: 1.3581272551587151\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6121251729828111\n",
      "AUROCperdrug: 0.778075765291197\n",
      "AUPR+AUROCperdrug: 1.3902009382740081\n",
      "AUPR: 0.5890764830318804\n",
      "AUROC: 0.7353216713617295\n",
      "AUPR+AUROC: 1.3243981543936099\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6352904284243895\n",
      "AUROCperdrug: 0.7827715788814138\n",
      "AUPR+AUROCperdrug: 1.4180620073058035\n",
      "AUPR: 0.6222187724524892\n",
      "AUROC: 0.7454153179475569\n",
      "AUPR+AUROC: 1.3676340904000461\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6119137697138194\n",
      "AUROCperdrug: 0.7713154892080802\n",
      "AUPR+AUROCperdrug: 1.3832292589218995\n",
      "AUPR: 0.6124371171866789\n",
      "AUROC: 0.7458241082898449\n",
      "AUPR+AUROC: 1.3582612254765238\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6120132777978207\n",
      "AUROCperdrug: 0.7771602751659041\n",
      "AUPR+AUROCperdrug: 1.3891735529637248\n",
      "AUPR: 0.5995556974604117\n",
      "AUROC: 0.7367738077006347\n",
      "AUPR+AUROC: 1.3363295051610464\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6205857305396988, std: 0.010559403733018419\n",
      "Mean AUROCperdrug: 0.7763630841018182, std: 0.004125498441523369\n",
      "Mean AUPR+AUROCperdrug: 1.3969488146415168, std: 0.012576258817281154\n",
      "Mean AUPR: 0.6090006740531241, std: 0.012917971619212513\n",
      "Mean AUROC: 0.7399493720648643, std: 0.0046562266321958645\n",
      "Mean AUPR+AUROC: 1.3489500461179884, std: 0.01601303330945992\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5371205019798616\n",
      "AUPR for each fold: [0.53223417 0.53188125 0.55221199 0.5321546 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5940439293589828\n",
      "AUROCperdrug: 0.7342958705459551\n",
      "AUPR+AUROCperdrug: 1.328339799904938\n",
      "AUPR: 0.5621633360918006\n",
      "AUROC: 0.6871455386679003\n",
      "AUPR+AUROC: 1.2493088747597008\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5455100179591199\n",
      "AUPR for each fold: [0.54568319 0.54234045 0.55013746 0.54387897]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5686828378440871\n",
      "AUROCperdrug: 0.7318635819365329\n",
      "AUPR+AUROCperdrug: 1.30054641978062\n",
      "AUPR: 0.5281801770232996\n",
      "AUROC: 0.6832935277704592\n",
      "AUPR+AUROC: 1.2114737047937587\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5401274724682825\n",
      "AUPR for each fold: [0.53474476 0.53552935 0.53323515 0.55700063]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5932713758778603\n",
      "AUROCperdrug: 0.7458138972564119\n",
      "AUPR+AUROCperdrug: 1.3390852731342722\n",
      "AUPR: 0.5496575802798825\n",
      "AUROC: 0.6913001300738864\n",
      "AUPR+AUROC: 1.240957710353769\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5430322361891884\n",
      "AUPR for each fold: [0.55344974 0.54339977 0.51493285 0.56034658]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5753454594693672\n",
      "AUROCperdrug: 0.7354387241602076\n",
      "AUPR+AUROCperdrug: 1.3107841836295748\n",
      "AUPR: 0.5387751284761487\n",
      "AUROC: 0.6848858869765047\n",
      "AUPR+AUROC: 1.2236610154526533\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5437006622721704\n",
      "AUPR for each fold: [0.55148695 0.55210219 0.49985067 0.57136284]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5739921480449971\n",
      "AUROCperdrug: 0.7408185608933265\n",
      "AUPR+AUROCperdrug: 1.3148107089383236\n",
      "AUPR: 0.5341861933550356\n",
      "AUROC: 0.6863731267862937\n",
      "AUPR+AUROC: 1.2205593201413292\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5810671501190589, std: 0.010521449658447968\n",
      "Mean AUROCperdrug: 0.7376461269584869, std: 0.005026161174993783\n",
      "Mean AUPR+AUROCperdrug: 1.3187132770775458, std: 0.013533834860204045\n",
      "Mean AUPR: 0.5425924830452333, std: 0.012048953108356618\n",
      "Mean AUROC: 0.6865996420550088, std: 0.0026948561381320854\n",
      "Mean AUPR+AUROC: 1.2291921251002422, std: 0.013872083670226508\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6369913684311547\n",
      "AUROCperdrug: 0.771585136602122\n",
      "AUPR+AUROCperdrug: 1.4085765050332766\n",
      "AUPR: 0.6273597530432977\n",
      "AUROC: 0.7339642181671564\n",
      "AUPR+AUROC: 1.3613239712104541\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6176006328346773\n",
      "AUROCperdrug: 0.776109610431269\n",
      "AUPR+AUROCperdrug: 1.3937102432659463\n",
      "AUPR: 0.5946327790605593\n",
      "AUROC: 0.7328610425583457\n",
      "AUPR+AUROC: 1.327493821618905\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6397423078505755\n",
      "AUROCperdrug: 0.7795566751863092\n",
      "AUPR+AUROCperdrug: 1.4192989830368847\n",
      "AUPR: 0.6272858813850002\n",
      "AUROC: 0.7425259906972368\n",
      "AUPR+AUROC: 1.369811872082237\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.617170280437827\n",
      "AUROCperdrug: 0.7695024880465565\n",
      "AUPR+AUROCperdrug: 1.3866727684843836\n",
      "AUPR: 0.6180631119940909\n",
      "AUROC: 0.744332810668694\n",
      "AUPR+AUROC: 1.3623959226627849\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6168009979229181\n",
      "AUROCperdrug: 0.7744640470901749\n",
      "AUPR+AUROCperdrug: 1.391265045013093\n",
      "AUPR: 0.6052075492816024\n",
      "AUROC: 0.7345100243977573\n",
      "AUPR+AUROC: 1.3397175736793596\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6256611174954305, std: 0.010413663657220129\n",
      "Mean AUROCperdrug: 0.7742435914712864, std: 0.003501569076203525\n",
      "Mean AUPR+AUROCperdrug: 1.399904708966717, std: 0.012160899318770525\n",
      "Mean AUPR: 0.6145098149529101, std: 0.012826561540430303\n",
      "Mean AUROC: 0.7376388172978381, std: 0.004791934188383364\n",
      "Mean AUPR+AUROC: 1.3521486322507479, std: 0.015897010735708476\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5424758226632779\n",
      "AUPR for each fold: [0.53725148 0.53704264 0.55773384 0.53787533]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5995674959057635\n",
      "AUROCperdrug: 0.7320503007285066\n",
      "AUPR+AUROCperdrug: 1.3316177966342702\n",
      "AUPR: 0.5675247732700954\n",
      "AUROC: 0.6832182503970775\n",
      "AUPR+AUROC: 1.250743023667173\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5508724347909195\n",
      "AUPR for each fold: [0.55089287 0.54750576 0.5555216  0.54956951]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5741062169503444\n",
      "AUROCperdrug: 0.7293143485380966\n",
      "AUPR+AUROCperdrug: 1.303420565488441\n",
      "AUPR: 0.5334523255611172\n",
      "AUROC: 0.679556254741482\n",
      "AUPR+AUROC: 1.2130085803025992\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5454689297519926\n",
      "AUPR for each fold: [0.54006256 0.54074769 0.53840963 0.56265584]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5978274309160906\n",
      "AUROCperdrug: 0.7416853864619942\n",
      "AUPR+AUROCperdrug: 1.3395128173780848\n",
      "AUPR: 0.5550352316494385\n",
      "AUROC: 0.6874470612388753\n",
      "AUPR+AUROC: 1.242482292888314\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5483344154216129\n",
      "AUPR for each fold: [0.55895355 0.54858834 0.51994445 0.56585132]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5805702450620165\n",
      "AUROCperdrug: 0.7331220760369458\n",
      "AUPR+AUROCperdrug: 1.3136923210989622\n",
      "AUPR: 0.5443216701163749\n",
      "AUROC: 0.681713512904713\n",
      "AUPR+AUROC: 1.226035183021088\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5490825117639607\n",
      "AUPR for each fold: [0.55712283 0.55741299 0.50465535 0.57713888]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5785924545669047\n",
      "AUROCperdrug: 0.7377574424957483\n",
      "AUPR+AUROCperdrug: 1.3163498970626528\n",
      "AUPR: 0.5393946666182958\n",
      "AUROC: 0.6825241839986788\n",
      "AUPR+AUROC: 1.2219188506169747\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5861327686802239, std: 0.010485160684298233\n",
      "Mean AUROCperdrug: 0.7347859108522583, std: 0.004395967861510726\n",
      "Mean AUPR+AUROCperdrug: 1.320918679532482, std: 0.01295755450340566\n",
      "Mean AUPR: 0.5479457334430644, std: 0.012082327890242432\n",
      "Mean AUROC: 0.6828918526561654, std: 0.002588680705581827\n",
      "Mean AUPR+AUROC: 1.2308375860992298, std: 0.013800768142380323\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.640106276942299\n",
      "AUROCperdrug: 0.7705337452878115\n",
      "AUPR+AUROCperdrug: 1.4106400222301105\n",
      "AUPR: 0.6311201233767354\n",
      "AUROC: 0.7333787260506094\n",
      "AUPR+AUROC: 1.3644988494273447\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6207289118320987\n",
      "AUROCperdrug: 0.7735057433404626\n",
      "AUPR+AUROCperdrug: 1.3942346551725613\n",
      "AUPR: 0.5974670185574473\n",
      "AUROC: 0.7303884393271659\n",
      "AUPR+AUROC: 1.3278554578846133\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6431617945376463\n",
      "AUROCperdrug: 0.7778411369792557\n",
      "AUPR+AUROCperdrug: 1.421002931516902\n",
      "AUPR: 0.6307406148612442\n",
      "AUROC: 0.7412568273251997\n",
      "AUPR+AUROC: 1.3719974421864438\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6201073215169753\n",
      "AUROCperdrug: 0.7682217267568173\n",
      "AUPR+AUROCperdrug: 1.3883290482737927\n",
      "AUPR: 0.6210627699864718\n",
      "AUROC: 0.7429625773513593\n",
      "AUPR+AUROC: 1.3640253473378312\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6202553651327721\n",
      "AUROCperdrug: 0.7728651485435468\n",
      "AUPR+AUROCperdrug: 1.393120513676319\n",
      "AUPR: 0.609543952238789\n",
      "AUROC: 0.7337284695983103\n",
      "AUPR+AUROC: 1.3432724218370993\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6288719339923583, std: 0.010466929603076262\n",
      "Mean AUROCperdrug: 0.7725935001815787, std: 0.0032186539259035666\n",
      "Mean AUPR+AUROCperdrug: 1.401465434173937, std: 0.012331856032428019\n",
      "Mean AUPR: 0.6179868958041376, std: 0.012937918507346508\n",
      "Mean AUROC: 0.736343007930529, std: 0.004879425895882665\n",
      "Mean AUPR+AUROC: 1.3543299037346663, std: 0.016326145822515733\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5460030060257224\n",
      "AUPR for each fold: [0.54041277 0.54078665 0.56125575 0.54155685]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6031454586437434\n",
      "AUROCperdrug: 0.7315294713917159\n",
      "AUPR+AUROCperdrug: 1.3346749300354592\n",
      "AUPR: 0.5713661859737477\n",
      "AUROC: 0.6827111206136901\n",
      "AUPR+AUROC: 1.2540773065874378\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5545179076259147\n",
      "AUPR for each fold: [0.55440775 0.55121666 0.559071   0.55337623]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5777009227320131\n",
      "AUROCperdrug: 0.7273575148263262\n",
      "AUPR+AUROCperdrug: 1.3050584375583392\n",
      "AUPR: 0.5367586805204116\n",
      "AUROC: 0.6771646550913599\n",
      "AUPR+AUROC: 1.2139233356117716\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5490125999385754\n",
      "AUPR for each fold: [0.54352504 0.54428691 0.54188801 0.56635044]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6016595790731194\n",
      "AUROCperdrug: 0.7415521083154465\n",
      "AUPR+AUROCperdrug: 1.3432116873885658\n",
      "AUPR: 0.5586538816756307\n",
      "AUROC: 0.685946723341141\n",
      "AUPR+AUROC: 1.2446006050167717\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5518695685686765\n",
      "AUPR for each fold: [0.56243267 0.55200107 0.52343953 0.56960501]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5841096008752275\n",
      "AUROCperdrug: 0.732249308713384\n",
      "AUPR+AUROCperdrug: 1.3163589095886115\n",
      "AUPR: 0.5480376915457321\n",
      "AUROC: 0.6806253372974603\n",
      "AUPR+AUROC: 1.2286630288431923\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5527293410804625\n",
      "AUPR for each fold: [0.56077053 0.56076253 0.50835448 0.58102982]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5816747533226873\n",
      "AUROCperdrug: 0.735409972917213\n",
      "AUPR+AUROCperdrug: 1.3170847262399001\n",
      "AUPR: 0.542754153872038\n",
      "AUROC: 0.6804454293504255\n",
      "AUPR+AUROC: 1.2231995832224634\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5896580629293582, std: 0.010615442506522606\n",
      "Mean AUROCperdrug: 0.733619675232817, std: 0.0047241966483351815\n",
      "Mean AUPR+AUROCperdrug: 1.3232777381621752, std: 0.013750816807371932\n",
      "Mean AUPR: 0.551514118717512, std: 0.012260720009912195\n",
      "Mean AUROC: 0.6813786531388154, std: 0.0028927117341686925\n",
      "Mean AUPR+AUROC: 1.2328927718563274, std: 0.014543355956391396\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6429613230605096\n",
      "AUROCperdrug: 0.769346570495591\n",
      "AUPR+AUROCperdrug: 1.4123078935561004\n",
      "AUPR: 0.6346028727939041\n",
      "AUROC: 0.7326264174926498\n",
      "AUPR+AUROC: 1.367229290286554\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6237398962758302\n",
      "AUROCperdrug: 0.7728119425053322\n",
      "AUPR+AUROCperdrug: 1.3965518387811624\n",
      "AUPR: 0.6004483163325659\n",
      "AUROC: 0.7292794223435686\n",
      "AUPR+AUROC: 1.3297277386761346\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6462497637259537\n",
      "AUROCperdrug: 0.7766630273204669\n",
      "AUPR+AUROCperdrug: 1.4229127910464205\n",
      "AUPR: 0.6334265701048536\n",
      "AUROC: 0.7396410068528003\n",
      "AUPR+AUROC: 1.373067576957654\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6225416022533405\n",
      "AUROCperdrug: 0.7657869286138405\n",
      "AUPR+AUROCperdrug: 1.3883285308671809\n",
      "AUPR: 0.6237257057347474\n",
      "AUROC: 0.7412850902289951\n",
      "AUPR+AUROC: 1.3650107959637425\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6234844019315346\n",
      "AUROCperdrug: 0.7720509969442408\n",
      "AUPR+AUROCperdrug: 1.3955353988757755\n",
      "AUPR: 0.6124304604948759\n",
      "AUROC: 0.732049742011035\n",
      "AUPR+AUROC: 1.344480202505911\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6317953974494337, std: 0.010518584224082448\n",
      "Mean AUROCperdrug: 0.7713318931758943, std: 0.00362813411146852\n",
      "Mean AUPR+AUROCperdrug: 1.403127290625328, std: 0.012614485124306732\n",
      "Mean AUPR: 0.6209267850921893, std: 0.012982058167740156\n",
      "Mean AUROC: 0.7349763357858098, std: 0.004649761900637421\n",
      "Mean AUPR+AUROC: 1.3559031208779992, std: 0.01625720830276974\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5488682544134112\n",
      "AUPR for each fold: [0.54323301 0.54368409 0.56415572 0.54440019]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6059364571506399\n",
      "AUROCperdrug: 0.7289893704256806\n",
      "AUPR+AUROCperdrug: 1.3349258275763205\n",
      "AUPR: 0.5742877678857234\n",
      "AUROC: 0.6806983219665376\n",
      "AUPR+AUROC: 1.254986089852261\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5573449247877867\n",
      "AUPR for each fold: [0.55720059 0.55425157 0.56184931 0.55607823]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.58092168454946\n",
      "AUROCperdrug: 0.7267611238170715\n",
      "AUPR+AUROCperdrug: 1.3076828083665315\n",
      "AUPR: 0.5398220871690684\n",
      "AUROC: 0.6759796776888942\n",
      "AUPR+AUROC: 1.2158017648579627\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5518641329168641\n",
      "AUPR for each fold: [0.54638191 0.54747747 0.54459936 0.56899779]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6046821389900551\n",
      "AUROCperdrug: 0.7400543064507472\n",
      "AUPR+AUROCperdrug: 1.3447364454408022\n",
      "AUPR: 0.5616347947701221\n",
      "AUROC: 0.6841184058474687\n",
      "AUPR+AUROC: 1.2457532006175909\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5548084646102165\n",
      "AUPR for each fold: [0.5653145  0.55526023 0.52629413 0.572365  ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5864272988598289\n",
      "AUROCperdrug: 0.7288112032752007\n",
      "AUPR+AUROCperdrug: 1.3152385021350295\n",
      "AUPR: 0.5507343282142544\n",
      "AUROC: 0.6776829972608682\n",
      "AUPR+AUROC: 1.2284173254751227\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5556597703055408\n",
      "AUPR for each fold: [0.56373321 0.56402757 0.51105481 0.58382349]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5844423190345035\n",
      "AUROCperdrug: 0.7341456876838593\n",
      "AUPR+AUROCperdrug: 1.3185880067183628\n",
      "AUPR: 0.5454664872008719\n",
      "AUROC: 0.6779014952717681\n",
      "AUPR+AUROC: 1.22336798247264\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5924819797168974, std: 0.010628288458945399\n",
      "Mean AUROCperdrug: 0.7317523383305119, std: 0.004813466218276786\n",
      "Mean AUPR+AUROCperdrug: 1.3242343180474094, std: 0.013575003586974447\n",
      "Mean AUPR: 0.5543890930480081, std: 0.012277013603588025\n",
      "Mean AUROC: 0.6792761796071073, std: 0.0028553303052469463\n",
      "Mean AUPR+AUROC: 1.2336652726551154, std: 0.014514649798773142\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6461710880393751\n",
      "AUROCperdrug: 0.7680992772703967\n",
      "AUPR+AUROCperdrug: 1.414270365309772\n",
      "AUPR: 0.6379203016873733\n",
      "AUROC: 0.7309751625803319\n",
      "AUPR+AUROC: 1.3688954642677054\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6260751799244779\n",
      "AUROCperdrug: 0.7704178527221842\n",
      "AUPR+AUROCperdrug: 1.3964930326466622\n",
      "AUPR: 0.6035933155461767\n",
      "AUROC: 0.7276172025904962\n",
      "AUPR+AUROC: 1.331210518136673\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6492780743651377\n",
      "AUROCperdrug: 0.7748273042052718\n",
      "AUPR+AUROCperdrug: 1.4241053785704096\n",
      "AUPR: 0.6374369946077292\n",
      "AUROC: 0.7383708103598592\n",
      "AUPR+AUROC: 1.3758078049675884\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6251182263521559\n",
      "AUROCperdrug: 0.7633898143216049\n",
      "AUPR+AUROCperdrug: 1.3885080406737607\n",
      "AUPR: 0.6269811629922368\n",
      "AUROC: 0.739933578401097\n",
      "AUPR+AUROC: 1.3669147413933338\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6262418369596827\n",
      "AUROCperdrug: 0.7695578332154566\n",
      "AUPR+AUROCperdrug: 1.3957996701751392\n",
      "AUPR: 0.6157462167260471\n",
      "AUROC: 0.7301435842599128\n",
      "AUPR+AUROC: 1.34588980098596\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6345768811281658, std: 0.010786739556601982\n",
      "Mean AUROCperdrug: 0.7692584163469828, std: 0.003694064110938079\n",
      "Mean AUPR+AUROCperdrug: 1.4038352974751487, std: 0.013214929347473836\n",
      "Mean AUPR: 0.6243355983119125, std: 0.013169734496476536\n",
      "Mean AUROC: 0.7334080676383394, std: 0.004843988083934485\n",
      "Mean AUPR+AUROC: 1.357743665950252, std: 0.01660907219818384\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5526148751968671\n",
      "AUPR for each fold: [0.5470851  0.54743539 0.56795759 0.54798141]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6096063533995912\n",
      "AUROCperdrug: 0.7278644585567279\n",
      "AUPR+AUROCperdrug: 1.3374708119563192\n",
      "AUPR: 0.5782172730583937\n",
      "AUROC: 0.6795008913255298\n",
      "AUPR+AUROC: 1.2577181643839235\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5611636177534668\n",
      "AUPR for each fold: [0.56100672 0.55803522 0.56581241 0.55980012]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5838990308150488\n",
      "AUROCperdrug: 0.7243129115719249\n",
      "AUPR+AUROCperdrug: 1.3082119423869738\n",
      "AUPR: 0.5434941116456834\n",
      "AUROC: 0.6739837034017068\n",
      "AUPR+AUROC: 1.2174778150473902\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.555624244247098\n",
      "AUPR for each fold: [0.55026175 0.55115171 0.54838951 0.57269401]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6083980100303947\n",
      "AUROCperdrug: 0.738918987888441\n",
      "AUPR+AUROCperdrug: 1.3473169979188357\n",
      "AUPR: 0.5655187737947933\n",
      "AUROC: 0.6825969098074568\n",
      "AUPR+AUROC: 1.2481156836022502\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5585518948998699\n",
      "AUPR for each fold: [0.56916528 0.55878009 0.53001596 0.57624624]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5895432556682748\n",
      "AUROCperdrug: 0.7263777360596678\n",
      "AUPR+AUROCperdrug: 1.3159209917279426\n",
      "AUPR: 0.5546309042095514\n",
      "AUROC: 0.676225716687697\n",
      "AUPR+AUROC: 1.2308566208972485\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5595071401227107\n",
      "AUPR for each fold: [0.56760934 0.56762809 0.514796   0.58799514]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5872974050090793\n",
      "AUROCperdrug: 0.7314981127683783\n",
      "AUPR+AUROCperdrug: 1.3187955177774575\n",
      "AUPR: 0.5490906770294295\n",
      "AUROC: 0.6758030699419978\n",
      "AUPR+AUROC: 1.2248937469714272\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5957488109844779, std: 0.01097621235305825\n",
      "Mean AUROCperdrug: 0.729794441369028, std: 0.005130413690243885\n",
      "Mean AUPR+AUROCperdrug: 1.325543252353506, std: 0.014524853187784476\n",
      "Mean AUPR: 0.5581903479475703, std: 0.012379309890104953\n",
      "Mean AUROC: 0.6776220582328777, std: 0.0030586034711873795\n",
      "Mean AUPR+AUROC: 1.2358124061804479, std: 0.014907495004186835\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6498305970064945\n",
      "AUROCperdrug: 0.7660980369909548\n",
      "AUPR+AUROCperdrug: 1.4159286339974493\n",
      "AUPR: 0.6429702188914788\n",
      "AUROC: 0.7297778685363745\n",
      "AUPR+AUROC: 1.3727480874278533\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6299369263231587\n",
      "AUROCperdrug: 0.7695429691114156\n",
      "AUPR+AUROCperdrug: 1.3994798954345744\n",
      "AUPR: 0.6081538621717288\n",
      "AUROC: 0.7268776810385794\n",
      "AUPR+AUROC: 1.3350315432103081\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6532027346300944\n",
      "AUROCperdrug: 0.7730278813542553\n",
      "AUPR+AUROCperdrug: 1.4262306159843496\n",
      "AUPR: 0.642464464144221\n",
      "AUROC: 0.7373075601263126\n",
      "AUPR+AUROC: 1.3797720242705336\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6287092470040718\n",
      "AUROCperdrug: 0.7604065075199067\n",
      "AUPR+AUROCperdrug: 1.3891157545239785\n",
      "AUPR: 0.6313478913390367\n",
      "AUROC: 0.7380400695689184\n",
      "AUPR+AUROC: 1.3693879609079551\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6302365407222569\n",
      "AUROCperdrug: 0.767532010696636\n",
      "AUPR+AUROCperdrug: 1.397768551418893\n",
      "AUPR: 0.6201838593787087\n",
      "AUROC: 0.7290897492021668\n",
      "AUPR+AUROC: 1.3492736085808756\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6383832091372151, std: 0.010788461130815797\n",
      "Mean AUROCperdrug: 0.7673214811346336, std: 0.004167877413241267\n",
      "Mean AUPR+AUROCperdrug: 1.405704690271849, std: 0.013437007193314079\n",
      "Mean AUPR: 0.6290240591850347, std: 0.013373513434356015\n",
      "Mean AUROC: 0.7322185856944705, std: 0.004562002101119952\n",
      "Mean AUPR+AUROC: 1.3612426448795054, std: 0.016567069521700117\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5572289719135526\n",
      "AUPR for each fold: [0.55148741 0.55216313 0.57229732 0.55296803]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6137732486877557\n",
      "AUROCperdrug: 0.7254655177614673\n",
      "AUPR+AUROCperdrug: 1.3392387664492231\n",
      "AUPR: 0.5826828281982173\n",
      "AUROC: 0.6767480053428302\n",
      "AUPR+AUROC: 1.2594308335410473\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.56566431543261\n",
      "AUPR for each fold: [0.56522173 0.56257976 0.57014462 0.56471116]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5878344987279966\n",
      "AUROCperdrug: 0.7227146003921223\n",
      "AUPR+AUROCperdrug: 1.310549099120119\n",
      "AUPR: 0.548236586229433\n",
      "AUROC: 0.6727385958722598\n",
      "AUPR+AUROC: 1.220975182101693\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5602135471138354\n",
      "AUPR for each fold: [0.55459003 0.55578448 0.55292646 0.57755322]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6123785923023228\n",
      "AUROCperdrug: 0.7358808223945082\n",
      "AUPR+AUROCperdrug: 1.3482594146968312\n",
      "AUPR: 0.5699433801259133\n",
      "AUROC: 0.6795443880752311\n",
      "AUPR+AUROC: 1.2494877682011443\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5631275495962422\n",
      "AUPR for each fold: [0.57376061 0.56306879 0.53473615 0.58094466]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.593179738529408\n",
      "AUROCperdrug: 0.7229425533935298\n",
      "AUPR+AUROCperdrug: 1.3161222919229378\n",
      "AUPR: 0.5591095634362003\n",
      "AUROC: 0.673393635388129\n",
      "AUPR+AUROC: 1.2325031988243293\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5640427512930284\n",
      "AUPR for each fold: [0.57227736 0.57182124 0.51925166 0.59282074]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5912647552888459\n",
      "AUROCperdrug: 0.7295611683812939\n",
      "AUPR+AUROCperdrug: 1.3208259236701398\n",
      "AUPR: 0.5537771624412371\n",
      "AUROC: 0.6744828428432177\n",
      "AUPR+AUROC: 1.2282600052844548\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.5996861667072658, std: 0.011074830545104082\n",
      "Mean AUROCperdrug: 0.7273129324645844, std: 0.004942086902253185\n",
      "Mean AUPR+AUROCperdrug: 1.3269990991718503, std: 0.014344518149379632\n",
      "Mean AUPR: 0.5627499040862002, std: 0.012275716916548787\n",
      "Mean AUROC: 0.6753814935043335, std: 0.002487613579624654\n",
      "Mean AUPR+AUROC: 1.2381313975905335, std: 0.014185132093622033\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6521180612703845\n",
      "AUROCperdrug: 0.7643902159497314\n",
      "AUPR+AUROCperdrug: 1.416508277220116\n",
      "AUPR: 0.6460402797094951\n",
      "AUROC: 0.7288693971192353\n",
      "AUPR+AUROC: 1.3749096768287303\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6320388067407711\n",
      "AUROCperdrug: 0.7678416629062568\n",
      "AUPR+AUROCperdrug: 1.399880469647028\n",
      "AUPR: 0.6103384594267424\n",
      "AUROC: 0.724873864519341\n",
      "AUPR+AUROC: 1.3352123239460834\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6548308403691693\n",
      "AUROCperdrug: 0.770176794238139\n",
      "AUPR+AUROCperdrug: 1.4250076346073084\n",
      "AUPR: 0.6446698882338229\n",
      "AUROC: 0.7352852024502414\n",
      "AUPR+AUROC: 1.3799550906840643\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6312648344734403\n",
      "AUROCperdrug: 0.7591863582186252\n",
      "AUPR+AUROCperdrug: 1.3904511926920655\n",
      "AUPR: 0.6339153991202371\n",
      "AUROC: 0.7370218966543451\n",
      "AUPR+AUROC: 1.3709372957745822\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.632321045686654\n",
      "AUROCperdrug: 0.7653798498563811\n",
      "AUPR+AUROCperdrug: 1.3977008955430352\n",
      "AUPR: 0.6228937359054606\n",
      "AUROC: 0.7276056894767292\n",
      "AUPR+AUROC: 1.3504994253821898\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6405147177080839, std: 0.010621926545096638\n",
      "Mean AUROCperdrug: 0.7653949762338267, std: 0.0036988854752178055\n",
      "Mean AUPR+AUROCperdrug: 1.4059096939419107, std: 0.012804393642863027\n",
      "Mean AUPR: 0.6315715524791516, std: 0.013509647111186922\n",
      "Mean AUROC: 0.7307312100439783, std: 0.004644465688196584\n",
      "Mean AUPR+AUROC: 1.36230276252313, std: 0.016842237216236646\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5598253049497744\n",
      "AUPR for each fold: [0.55411763 0.55462765 0.57491097 0.55564497]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.616091561559758\n",
      "AUROCperdrug: 0.7233223733648432\n",
      "AUPR+AUROCperdrug: 1.3394139349246013\n",
      "AUPR: 0.5852338188246304\n",
      "AUROC: 0.674713641519015\n",
      "AUPR+AUROC: 1.2599474603436454\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5682676715257168\n",
      "AUPR for each fold: [0.56790978 0.56500785 0.57266532 0.56748773]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5901984842724514\n",
      "AUROCperdrug: 0.7215177599349749\n",
      "AUPR+AUROCperdrug: 1.3117162442074264\n",
      "AUPR: 0.5507716559590866\n",
      "AUROC: 0.6708390410807489\n",
      "AUPR+AUROC: 1.2216106970398355\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5628033820393081\n",
      "AUPR for each fold: [0.557236   0.55828646 0.55539692 0.58029414]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6141061743289832\n",
      "AUROCperdrug: 0.73301866703592\n",
      "AUPR+AUROCperdrug: 1.347124841364903\n",
      "AUPR: 0.5724980295262432\n",
      "AUROC: 0.6774487863362902\n",
      "AUPR+AUROC: 1.2499468158625335\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5656508362609327\n",
      "AUPR for each fold: [0.5764869  0.56550491 0.53706404 0.58354749]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5958458915107792\n",
      "AUROCperdrug: 0.722000365573633\n",
      "AUPR+AUROCperdrug: 1.3178462570844123\n",
      "AUPR: 0.5618914478314342\n",
      "AUROC: 0.6722495521285872\n",
      "AUPR+AUROC: 1.2341409999600215\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5666220417700732\n",
      "AUPR for each fold: [0.57515031 0.57429717 0.5215199  0.59552079]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5935723113664886\n",
      "AUROCperdrug: 0.7277452063769942\n",
      "AUPR+AUROCperdrug: 1.3213175177434828\n",
      "AUPR: 0.5563443347626554\n",
      "AUROC: 0.6728212304515104\n",
      "AUPR+AUROC: 1.2291655652141658\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6019628846076921, std: 0.010893111922518234\n",
      "Mean AUROCperdrug: 0.725520874457273, std: 0.0043455002421664175\n",
      "Mean AUPR+AUROCperdrug: 1.327483759064965, std: 0.013473082135854447\n",
      "Mean AUPR: 0.5653478573808101, std: 0.012264193888305333\n",
      "Mean AUROC: 0.6736144503032303, std: 0.0022849680634889295\n",
      "Mean AUPR+AUROC: 1.2389623076840404, std: 0.014009536860361393\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6534801689669684\n",
      "AUROCperdrug: 0.7641893550990017\n",
      "AUPR+AUROCperdrug: 1.41766952406597\n",
      "AUPR: 0.6472778822933088\n",
      "AUROC: 0.728192854025465\n",
      "AUPR+AUROC: 1.375470736318774\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6328190336538951\n",
      "AUROCperdrug: 0.7664553141092043\n",
      "AUPR+AUROCperdrug: 1.3992743477630993\n",
      "AUPR: 0.6117849786426761\n",
      "AUROC: 0.7240125084150895\n",
      "AUPR+AUROC: 1.3357974870577656\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.655873336761713\n",
      "AUROCperdrug: 0.7690338772864052\n",
      "AUPR+AUROCperdrug: 1.424907214048118\n",
      "AUPR: 0.645862823297743\n",
      "AUROC: 0.7343299568411896\n",
      "AUPR+AUROC: 1.3801927801389327\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6325237083606187\n",
      "AUROCperdrug: 0.758828724002901\n",
      "AUPR+AUROCperdrug: 1.3913524323635196\n",
      "AUPR: 0.6353686414544875\n",
      "AUROC: 0.7366838938640972\n",
      "AUPR+AUROC: 1.3720525353185846\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6337045962716642\n",
      "AUROCperdrug: 0.7650442058355812\n",
      "AUPR+AUROCperdrug: 1.3987488021072454\n",
      "AUPR: 0.6243559798794376\n",
      "AUROC: 0.727105820879284\n",
      "AUPR+AUROC: 1.3514618007587216\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6416801688029719, std: 0.010645715210732295\n",
      "Mean AUROCperdrug: 0.7647102952666186, std: 0.003367913529153943\n",
      "Mean AUPR+AUROCperdrug: 1.4063904640695906, std: 0.012690655858514834\n",
      "Mean AUPR: 0.6329300611135306, std: 0.01341411470137074\n",
      "Mean AUROC: 0.7300650068050251, std: 0.004709436035132526\n",
      "Mean AUPR+AUROC: 1.3629950679185558, std: 0.016770008821756884\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5610481034775298\n",
      "AUPR for each fold: [0.55516411 0.55576849 0.57628704 0.55697277]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6174906262834576\n",
      "AUROCperdrug: 0.7234139965966647\n",
      "AUPR+AUROCperdrug: 1.3409046228801222\n",
      "AUPR: 0.5866526574513907\n",
      "AUROC: 0.6742058217652789\n",
      "AUPR+AUROC: 1.2608584792166697\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5696055981034494\n",
      "AUPR for each fold: [0.56909726 0.56636089 0.57411886 0.56884538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5908471415146469\n",
      "AUROCperdrug: 0.7191699148684133\n",
      "AUPR+AUROCperdrug: 1.3100170563830602\n",
      "AUPR: 0.5517779423100326\n",
      "AUROC: 0.6686293130865337\n",
      "AUPR+AUROC: 1.2204072553965664\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5640827802587048\n",
      "AUPR for each fold: [0.55837623 0.5595816  0.55675667 0.58161662]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6150329564600583\n",
      "AUROCperdrug: 0.731469270806489\n",
      "AUPR+AUROCperdrug: 1.3465022272665474\n",
      "AUPR: 0.5737036930848709\n",
      "AUROC: 0.6759631376895501\n",
      "AUPR+AUROC: 1.249666830774421\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5668737660885794\n",
      "AUPR for each fold: [0.57766679 0.56667006 0.53843227 0.58472594]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5971550604862599\n",
      "AUROCperdrug: 0.721473104737787\n",
      "AUPR+AUROCperdrug: 1.3186281652240468\n",
      "AUPR: 0.563337447418142\n",
      "AUROC: 0.6717821755368983\n",
      "AUPR+AUROC: 1.2351196229550403\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5678906150365646\n",
      "AUPR for each fold: [0.57641435 0.57561622 0.52280062 0.59673127]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5947735762272149\n",
      "AUROCperdrug: 0.7266503238114662\n",
      "AUPR+AUROCperdrug: 1.3214239000386812\n",
      "AUPR: 0.5576015728345878\n",
      "AUROC: 0.6717441570344331\n",
      "AUPR+AUROC: 1.229345729869021\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6030598721943276, std: 0.010993468090024787\n",
      "Mean AUROCperdrug: 0.7244353221641641, std: 0.0042877737297231915\n",
      "Mean AUPR+AUROCperdrug: 1.3274951943584916, std: 0.013871194618501404\n",
      "Mean AUPR: 0.5666146626198048, std: 0.012360257168118298\n",
      "Mean AUROC: 0.6724649210225389, std: 0.0024886054572344704\n",
      "Mean AUPR+AUROC: 1.2390795836423436, std: 0.014460256804888001\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.654157060727282\n",
      "AUROCperdrug: 0.762702370796132\n",
      "AUPR+AUROCperdrug: 1.416859431523414\n",
      "AUPR: 0.6481726782725769\n",
      "AUROC: 0.7272914406028252\n",
      "AUPR+AUROC: 1.375464118875402\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6335604679076305\n",
      "AUROCperdrug: 0.7654466711229972\n",
      "AUPR+AUROCperdrug: 1.3990071390306278\n",
      "AUPR: 0.6123889589246443\n",
      "AUROC: 0.722427065621269\n",
      "AUPR+AUROC: 1.3348160245459133\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.656673792910903\n",
      "AUROCperdrug: 0.7676961390907657\n",
      "AUPR+AUROCperdrug: 1.4243699320016687\n",
      "AUPR: 0.6468690574439979\n",
      "AUROC: 0.7333870828541277\n",
      "AUPR+AUROC: 1.3802561402981257\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6333175471497037\n",
      "AUROCperdrug: 0.7570310128651022\n",
      "AUPR+AUROCperdrug: 1.390348560014806\n",
      "AUPR: 0.6360298353881393\n",
      "AUROC: 0.735371420106803\n",
      "AUPR+AUROC: 1.3714012554949422\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6346165412358578\n",
      "AUROCperdrug: 0.76361070793802\n",
      "AUPR+AUROCperdrug: 1.3982272491738779\n",
      "AUPR: 0.625426243426132\n",
      "AUROC: 0.7261551298722502\n",
      "AUPR+AUROC: 1.3515813732983821\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6424650819862754, std: 0.010612812731850507\n",
      "Mean AUROCperdrug: 0.7632973803626035, std: 0.003568980282622665\n",
      "Mean AUPR+AUROCperdrug: 1.405762462348879, std: 0.012723072487659814\n",
      "Mean AUPR: 0.6337773546910981, std: 0.013497379183371933\n",
      "Mean AUROC: 0.728926427811455, std: 0.00477557019456859\n",
      "Mean AUPR+AUROC: 1.362703782502553, std: 0.01701759392710109\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5623556998706325\n",
      "AUPR for each fold: [0.55631861 0.55686053 0.57779108 0.55845258]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6188409684947309\n",
      "AUROCperdrug: 0.7230037279055699\n",
      "AUPR+AUROCperdrug: 1.3418446964003008\n",
      "AUPR: 0.5881315289496626\n",
      "AUROC: 0.6738836211445869\n",
      "AUPR+AUROC: 1.2620151500942494\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.570979281606633\n",
      "AUPR for each fold: [0.57053489 0.56754129 0.57545511 0.57038583]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5920606554337641\n",
      "AUROCperdrug: 0.718867652864251\n",
      "AUPR+AUROCperdrug: 1.3109283082980152\n",
      "AUPR: 0.5530831697292404\n",
      "AUROC: 0.6676142588860908\n",
      "AUPR+AUROC: 1.2206974286153311\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5654278847700254\n",
      "AUPR for each fold: [0.55983436 0.56072861 0.55804596 0.5831026 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.616088081848656\n",
      "AUROCperdrug: 0.7303914173329313\n",
      "AUPR+AUROCperdrug: 1.3464794991815874\n",
      "AUPR: 0.5750981420421728\n",
      "AUROC: 0.6751777293520935\n",
      "AUPR+AUROC: 1.2502758713942663\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5682346919004958\n",
      "AUPR for each fold: [0.57928111 0.56790316 0.53960006 0.58615444]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5983035329997041\n",
      "AUROCperdrug: 0.7201969012754378\n",
      "AUPR+AUROCperdrug: 1.3185004342751419\n",
      "AUPR: 0.5646392635481424\n",
      "AUROC: 0.670613747634275\n",
      "AUPR+AUROC: 1.2352530111824174\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5692820266352631\n",
      "AUPR for each fold: [0.5782351  0.57695277 0.52379745 0.59814279]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5958013626522191\n",
      "AUROCperdrug: 0.7253033868702868\n",
      "AUPR+AUROCperdrug: 1.321104749522506\n",
      "AUPR: 0.5588235465671901\n",
      "AUROC: 0.6704128237495525\n",
      "AUPR+AUROC: 1.2292363703167426\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6042189202858148, std: 0.011030428618153452\n",
      "Mean AUROCperdrug: 0.7235526172496953, std: 0.004082778008849323\n",
      "Mean AUPR+AUROCperdrug: 1.3277715375355104, std: 0.013871808956342251\n",
      "Mean AUPR: 0.5679551301672816, std: 0.012439177498713845\n",
      "Mean AUROC: 0.6715404361533197, std: 0.002693159742581564\n",
      "Mean AUPR+AUROC: 1.2394955663206013, std: 0.014832174410733319\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6557783406655292\n",
      "AUROCperdrug: 0.7601513510234963\n",
      "AUPR+AUROCperdrug: 1.4159296916890254\n",
      "AUPR: 0.6504190479563174\n",
      "AUROC: 0.7252085611928177\n",
      "AUPR+AUROC: 1.3756276091491353\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.635482506461344\n",
      "AUROCperdrug: 0.7632243974418306\n",
      "AUPR+AUROCperdrug: 1.3987069039031745\n",
      "AUPR: 0.6149827039773648\n",
      "AUROC: 0.7208142292249249\n",
      "AUPR+AUROC: 1.3357969332022896\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6594290522189125\n",
      "AUROCperdrug: 0.7674039237535463\n",
      "AUPR+AUROCperdrug: 1.4268329759724587\n",
      "AUPR: 0.6494402692003576\n",
      "AUROC: 0.73268190205264\n",
      "AUPR+AUROC: 1.3821221712529976\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.636455470626698\n",
      "AUROCperdrug: 0.7577511616323699\n",
      "AUPR+AUROCperdrug: 1.3942066322590678\n",
      "AUPR: 0.6392345218399403\n",
      "AUROC: 0.735463530987345\n",
      "AUPR+AUROC: 1.3746980528272852\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6365099866756778\n",
      "AUROCperdrug: 0.7626502263041339\n",
      "AUPR+AUROCperdrug: 1.3991602129798117\n",
      "AUPR: 0.6275757071188508\n",
      "AUROC: 0.7249428607065648\n",
      "AUPR+AUROC: 1.3525185678254155\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6447310713296323, std: 0.010579986332754138\n",
      "Mean AUROCperdrug: 0.7622362120310754, std: 0.0032346710859294694\n",
      "Mean AUPR+AUROCperdrug: 1.4069672833607076, std: 0.012385386059712141\n",
      "Mean AUPR: 0.6363304500185663, std: 0.013499343452585551\n",
      "Mean AUROC: 0.7278222168328584, std: 0.005408142014825639\n",
      "Mean AUPR+AUROC: 1.3641526668514246, std: 0.017350403139301925\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5651705725658122\n",
      "AUPR for each fold: [0.55888418 0.55959627 0.58090185 0.5613    ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.62128635563755\n",
      "AUROCperdrug: 0.7199351050042916\n",
      "AUPR+AUROCperdrug: 1.3412214606418416\n",
      "AUPR: 0.5906025492918624\n",
      "AUROC: 0.670711693461488\n",
      "AUPR+AUROC: 1.2613142427533504\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5738050578675669\n",
      "AUPR for each fold: [0.57305651 0.57039661 0.57834522 0.57342189]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.594269404677623\n",
      "AUROCperdrug: 0.7156896794921989\n",
      "AUPR+AUROCperdrug: 1.3099590841698219\n",
      "AUPR: 0.5554708263953689\n",
      "AUROC: 0.6642943512686947\n",
      "AUPR+AUROC: 1.2197651776640637\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5680429785803416\n",
      "AUPR for each fold: [0.56219488 0.56343999 0.56073334 0.5858037 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6197432857010138\n",
      "AUROCperdrug: 0.7310668807868032\n",
      "AUPR+AUROCperdrug: 1.350810166487817\n",
      "AUPR: 0.5782264490421606\n",
      "AUROC: 0.6747840193275741\n",
      "AUPR+AUROC: 1.2530104683697347\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5708956473225065\n",
      "AUPR for each fold: [0.58201106 0.57049852 0.54225801 0.58881499]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6012979632070942\n",
      "AUROCperdrug: 0.7201744041582215\n",
      "AUPR+AUROCperdrug: 1.3214723673653157\n",
      "AUPR: 0.5675986520130807\n",
      "AUROC: 0.669507339585105\n",
      "AUPR+AUROC: 1.2371059915981857\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5719911404938864\n",
      "AUPR for each fold: [0.58105631 0.5796076  0.52638412 0.60091654]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5982856849632519\n",
      "AUROCperdrug: 0.7234937398681737\n",
      "AUPR+AUROCperdrug: 1.3217794248314254\n",
      "AUPR: 0.5615961402895835\n",
      "AUROC: 0.6689339463671976\n",
      "AUPR+AUROC: 1.2305300866567812\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6069765388373065, std: 0.011287241497716942\n",
      "Mean AUROCperdrug: 0.7220719618619378, std: 0.00513479171690537\n",
      "Mean AUPR+AUROCperdrug: 1.3290485006992445, std: 0.014808066284001886\n",
      "Mean AUPR: 0.5706989234064113, std: 0.012467439571514985\n",
      "Mean AUROC: 0.6696462700020118, std: 0.0033675313221945063\n",
      "Mean AUPR+AUROC: 1.240345193408423, std: 0.015036462464471323\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6570035039401452\n",
      "AUROCperdrug: 0.7593747612232004\n",
      "AUPR+AUROCperdrug: 1.4163782651633454\n",
      "AUPR: 0.6516324048918798\n",
      "AUROC: 0.7244730242661322\n",
      "AUPR+AUROC: 1.3761054291580122\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6367854981792233\n",
      "AUROCperdrug: 0.7626458703212222\n",
      "AUPR+AUROCperdrug: 1.3994313685004456\n",
      "AUPR: 0.6166042086138365\n",
      "AUROC: 0.7203191741682482\n",
      "AUPR+AUROC: 1.3369233827820848\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6604919171912607\n",
      "AUROCperdrug: 0.7664730431886843\n",
      "AUPR+AUROCperdrug: 1.4269649603799448\n",
      "AUPR: 0.6504835369467133\n",
      "AUROC: 0.7314349753294833\n",
      "AUPR+AUROC: 1.3819185122761968\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6377758113730876\n",
      "AUROCperdrug: 0.7569959181002385\n",
      "AUPR+AUROCperdrug: 1.3947717294733262\n",
      "AUPR: 0.6405799361626976\n",
      "AUROC: 0.7348755060309471\n",
      "AUPR+AUROC: 1.3754554421936447\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6378669566547687\n",
      "AUROCperdrug: 0.762329010484801\n",
      "AUPR+AUROCperdrug: 1.4001959671395696\n",
      "AUPR: 0.6288392748411866\n",
      "AUROC: 0.7241270010186492\n",
      "AUPR+AUROC: 1.3529662758598358\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.645984737467697, std: 0.010486012726925618\n",
      "Mean AUROCperdrug: 0.7615637206636292, std: 0.0032098139427945717\n",
      "Mean AUPR+AUROCperdrug: 1.4075484581313265, std: 0.01215036719488821\n",
      "Mean AUPR: 0.6376278722912627, std: 0.013336743288803275\n",
      "Mean AUROC: 0.727045936162692, std: 0.005309523783956455\n",
      "Mean AUPR+AUROC: 1.364673808453955, std: 0.017037944901586232\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5665859393409027\n",
      "AUPR for each fold: [0.56026796 0.5610609  0.5822705  0.5627444 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6226106415444964\n",
      "AUROCperdrug: 0.7191419998159503\n",
      "AUPR+AUROCperdrug: 1.3417526413604466\n",
      "AUPR: 0.592110653682746\n",
      "AUROC: 0.6702301260230784\n",
      "AUPR+AUROC: 1.2623407797058244\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5752270596474311\n",
      "AUPR for each fold: [0.57449194 0.57178566 0.57971979 0.57491085]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.595588202324753\n",
      "AUROCperdrug: 0.7149270284436166\n",
      "AUPR+AUROCperdrug: 1.3105152307683694\n",
      "AUPR: 0.5569530770243512\n",
      "AUROC: 0.6637622455967235\n",
      "AUPR+AUROC: 1.2207153226210745\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5694998244499591\n",
      "AUPR for each fold: [0.56373987 0.5647575  0.56213766 0.58736427]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6208575782562912\n",
      "AUROCperdrug: 0.7299137792701907\n",
      "AUPR+AUROCperdrug: 1.350771357526482\n",
      "AUPR: 0.579596199637989\n",
      "AUROC: 0.6736109941259941\n",
      "AUPR+AUROC: 1.2532071937639833\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5723367921937406\n",
      "AUPR for each fold: [0.58348248 0.57181293 0.54371197 0.59033979]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6028353762044625\n",
      "AUROCperdrug: 0.7195877623507847\n",
      "AUPR+AUROCperdrug: 1.3224231385552472\n",
      "AUPR: 0.5690274683075816\n",
      "AUROC: 0.6685876840658896\n",
      "AUPR+AUROC: 1.237615152373471\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.573443050640083\n",
      "AUPR for each fold: [0.58259468 0.58086973 0.5278608  0.60244699]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5996240992564433\n",
      "AUROCperdrug: 0.7228337481222731\n",
      "AUPR+AUROCperdrug: 1.3224578473787165\n",
      "AUPR: 0.5629989501776206\n",
      "AUROC: 0.6681249642664817\n",
      "AUPR+AUROC: 1.2311239144441024\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6083031795172893, std: 0.011217935189744241\n",
      "Mean AUROCperdrug: 0.7212808636005631, std: 0.004995022214754371\n",
      "Mean AUPR+AUROCperdrug: 1.3295840431178523, std: 0.014578462877318722\n",
      "Mean AUPR: 0.5721372697660576, std: 0.012476467121318105\n",
      "Mean AUROC: 0.6688632028156334, std: 0.003195330113395226\n",
      "Mean AUPR+AUROC: 1.2410004725816912, std: 0.014999379004856223\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6570035039401452\n",
      "AUROCperdrug: 0.7593747612232004\n",
      "AUPR+AUROCperdrug: 1.4163782651633454\n",
      "AUPR: 0.6516324048918798\n",
      "AUROC: 0.7244730242661322\n",
      "AUPR+AUROC: 1.3761054291580122\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6367854981792233\n",
      "AUROCperdrug: 0.7626458703212222\n",
      "AUPR+AUROCperdrug: 1.3994313685004456\n",
      "AUPR: 0.6166042086138365\n",
      "AUROC: 0.7203191741682482\n",
      "AUPR+AUROC: 1.3369233827820848\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6604919171912607\n",
      "AUROCperdrug: 0.7664730431886843\n",
      "AUPR+AUROCperdrug: 1.4269649603799448\n",
      "AUPR: 0.6504835369467133\n",
      "AUROC: 0.7314349753294833\n",
      "AUPR+AUROC: 1.3819185122761968\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6377758113730876\n",
      "AUROCperdrug: 0.7569959181002385\n",
      "AUPR+AUROCperdrug: 1.3947717294733262\n",
      "AUPR: 0.6405799361626976\n",
      "AUROC: 0.7348755060309471\n",
      "AUPR+AUROC: 1.3754554421936447\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6378669566547687\n",
      "AUROCperdrug: 0.762329010484801\n",
      "AUPR+AUROCperdrug: 1.4001959671395696\n",
      "AUPR: 0.6288392748411866\n",
      "AUROC: 0.7241270010186492\n",
      "AUPR+AUROC: 1.3529662758598358\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.645984737467697, std: 0.010486012726925618\n",
      "Mean AUROCperdrug: 0.7615637206636292, std: 0.0032098139427945717\n",
      "Mean AUPR+AUROCperdrug: 1.4075484581313265, std: 0.01215036719488821\n",
      "Mean AUPR: 0.6376278722912627, std: 0.013336743288803275\n",
      "Mean AUROC: 0.727045936162692, std: 0.005309523783956455\n",
      "Mean AUPR+AUROC: 1.364673808453955, std: 0.017037944901586232\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5665859393409027\n",
      "AUPR for each fold: [0.56026796 0.5610609  0.5822705  0.5627444 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6226106415444964\n",
      "AUROCperdrug: 0.7191419998159503\n",
      "AUPR+AUROCperdrug: 1.3417526413604466\n",
      "AUPR: 0.592110653682746\n",
      "AUROC: 0.6702301260230784\n",
      "AUPR+AUROC: 1.2623407797058244\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5752270596474311\n",
      "AUPR for each fold: [0.57449194 0.57178566 0.57971979 0.57491085]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.595588202324753\n",
      "AUROCperdrug: 0.7149270284436166\n",
      "AUPR+AUROCperdrug: 1.3105152307683694\n",
      "AUPR: 0.5569530770243512\n",
      "AUROC: 0.6637622455967235\n",
      "AUPR+AUROC: 1.2207153226210745\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5694998244499591\n",
      "AUPR for each fold: [0.56373987 0.5647575  0.56213766 0.58736427]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6208575782562912\n",
      "AUROCperdrug: 0.7299137792701907\n",
      "AUPR+AUROCperdrug: 1.350771357526482\n",
      "AUPR: 0.579596199637989\n",
      "AUROC: 0.6736109941259941\n",
      "AUPR+AUROC: 1.2532071937639833\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5723367921937406\n",
      "AUPR for each fold: [0.58348248 0.57181293 0.54371197 0.59033979]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6028353762044625\n",
      "AUROCperdrug: 0.7195877623507847\n",
      "AUPR+AUROCperdrug: 1.3224231385552472\n",
      "AUPR: 0.5690274683075816\n",
      "AUROC: 0.6685876840658896\n",
      "AUPR+AUROC: 1.237615152373471\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.573443050640083\n",
      "AUPR for each fold: [0.58259468 0.58086973 0.5278608  0.60244699]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5996240992564433\n",
      "AUROCperdrug: 0.7228337481222731\n",
      "AUPR+AUROCperdrug: 1.3224578473787165\n",
      "AUPR: 0.5629989501776206\n",
      "AUROC: 0.6681249642664817\n",
      "AUPR+AUROC: 1.2311239144441024\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6083031795172893, std: 0.011217935189744241\n",
      "Mean AUROCperdrug: 0.7212808636005631, std: 0.004995022214754371\n",
      "Mean AUPR+AUROCperdrug: 1.3295840431178523, std: 0.014578462877318722\n",
      "Mean AUPR: 0.5721372697660576, std: 0.012476467121318105\n",
      "Mean AUROC: 0.6688632028156334, std: 0.003195330113395226\n",
      "Mean AUPR+AUROC: 1.2410004725816912, std: 0.014999379004856223\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6609552412761326\n",
      "AUROCperdrug: 0.7571901792287603\n",
      "AUPR+AUROCperdrug: 1.418145420504893\n",
      "AUPR: 0.6556405033324801\n",
      "AUROC: 0.7220384818364004\n",
      "AUPR+AUROC: 1.3776789851688807\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6401989196795688\n",
      "AUROCperdrug: 0.7597349896874172\n",
      "AUPR+AUROCperdrug: 1.399933909366986\n",
      "AUPR: 0.6204887450777883\n",
      "AUROC: 0.7181531335445414\n",
      "AUPR+AUROC: 1.3386418786223295\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6644649691719317\n",
      "AUROCperdrug: 0.765135666635243\n",
      "AUPR+AUROCperdrug: 1.4296006358071747\n",
      "AUPR: 0.6548484872835876\n",
      "AUROC: 0.7302601844693682\n",
      "AUPR+AUROC: 1.3851086717529557\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6420468613157708\n",
      "AUROCperdrug: 0.7543341875328605\n",
      "AUPR+AUROCperdrug: 1.3963810488486312\n",
      "AUPR: 0.6451246158421708\n",
      "AUROC: 0.7331725341927356\n",
      "AUPR+AUROC: 1.3782971500349066\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6407431865701191\n",
      "AUROCperdrug: 0.7589604562459911\n",
      "AUPR+AUROCperdrug: 1.3997036428161103\n",
      "AUPR: 0.6326041365633985\n",
      "AUROC: 0.7213857232405991\n",
      "AUPR+AUROC: 1.3539898598039977\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6496818356027045, std: 0.010712130384740762\n",
      "Mean AUROCperdrug: 0.7590710958660545, std: 0.0035555073533772843\n",
      "Mean AUPR+AUROCperdrug: 1.408752931468759, std: 0.012927288052740434\n",
      "Mean AUPR: 0.6417412976198851, std: 0.01350253223837155\n",
      "Mean AUROC: 0.7250020114567289, std: 0.005712670166203992\n",
      "Mean AUPR+AUROC: 1.366743309076614, std: 0.017565350327529723\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5711116629863281\n",
      "AUPR for each fold: [0.56465674 0.56566673 0.58679469 0.56732849]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6267634940801511\n",
      "AUROCperdrug: 0.7171581297335629\n",
      "AUPR+AUROCperdrug: 1.343921623813714\n",
      "AUPR: 0.5964596375941141\n",
      "AUROC: 0.6673485923266813\n",
      "AUPR+AUROC: 1.2638082299207953\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5797409859654004\n",
      "AUPR for each fold: [0.57888465 0.57645404 0.58413495 0.57949031]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5994096439678294\n",
      "AUROCperdrug: 0.7123477721518883\n",
      "AUPR+AUROCperdrug: 1.3117574161197176\n",
      "AUPR: 0.5613367438003877\n",
      "AUROC: 0.6612535048730257\n",
      "AUPR+AUROC: 1.2225902486734133\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.573894956442556\n",
      "AUPR for each fold: [0.56815465 0.56926268 0.56627041 0.59189209]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6254394386755845\n",
      "AUROCperdrug: 0.7295084136458261\n",
      "AUPR+AUROCperdrug: 1.3549478523214105\n",
      "AUPR: 0.584420954973647\n",
      "AUROC: 0.6725901785932844\n",
      "AUPR+AUROC: 1.2570111335669314\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5768196982485293\n",
      "AUPR for each fold: [0.58792672 0.57628722 0.54797408 0.59509077]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6071783105880503\n",
      "AUROCperdrug: 0.7170480173742452\n",
      "AUPR+AUROCperdrug: 1.3242263279622954\n",
      "AUPR: 0.5735401755079657\n",
      "AUROC: 0.66618773368614\n",
      "AUPR+AUROC: 1.2397279091941056\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5779396470917009\n",
      "AUPR for each fold: [0.58695486 0.58525957 0.53201608 0.60752807]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6028311389369593\n",
      "AUROCperdrug: 0.7196644712874984\n",
      "AUPR+AUROCperdrug: 1.3224956102244576\n",
      "AUPR: 0.5673754313541575\n",
      "AUROC: 0.6658459701435335\n",
      "AUPR+AUROC: 1.233221401497691\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6123244052497149, std: 0.011522906252631818\n",
      "Mean AUROCperdrug: 0.7191453608386041, std: 0.005695919384428158\n",
      "Mean AUPR+AUROCperdrug: 1.331469766088319, std: 0.015670666256550704\n",
      "Mean AUPR: 0.5766265886460544, std: 0.012513921765200456\n",
      "Mean AUROC: 0.6666451959245331, std: 0.00362645698647546\n",
      "Mean AUPR+AUROC: 1.2432717845705874, std: 0.015177684132485528\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6613662085950625\n",
      "AUROCperdrug: 0.7565549370198285\n",
      "AUPR+AUROCperdrug: 1.417921145614891\n",
      "AUPR: 0.6562017465097907\n",
      "AUROC: 0.7214665651569443\n",
      "AUPR+AUROC: 1.377668311666735\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6406136227832043\n",
      "AUROCperdrug: 0.7591226787271902\n",
      "AUPR+AUROCperdrug: 1.3997363015103945\n",
      "AUPR: 0.6212483834510188\n",
      "AUROC: 0.7179541331340176\n",
      "AUPR+AUROC: 1.3392025165850363\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6648969169355445\n",
      "AUROCperdrug: 0.7648640313499652\n",
      "AUPR+AUROCperdrug: 1.4297609482855096\n",
      "AUPR: 0.65550414763765\n",
      "AUROC: 0.7302415638961979\n",
      "AUPR+AUROC: 1.3857457115338478\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6426695210932034\n",
      "AUROCperdrug: 0.754008949498428\n",
      "AUPR+AUROCperdrug: 1.3966784705916315\n",
      "AUPR: 0.6459897218788797\n",
      "AUROC: 0.733040371676088\n",
      "AUPR+AUROC: 1.3790300935549678\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6413069890352958\n",
      "AUROCperdrug: 0.7586474315235007\n",
      "AUPR+AUROCperdrug: 1.3999544205587964\n",
      "AUPR: 0.6335281977831442\n",
      "AUROC: 0.7212144113496795\n",
      "AUPR+AUROC: 1.3547426091328236\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6501706516884621, std: 0.010661816542302237\n",
      "Mean AUROCperdrug: 0.7586396056237825, std: 0.0035990475358989573\n",
      "Mean AUPR+AUROCperdrug: 1.4088102573122445, std: 0.012883186759902562\n",
      "Mean AUPR: 0.6424944394520967, std: 0.013424963004471437\n",
      "Mean AUROC: 0.7247834090425854, std: 0.005802535543468908\n",
      "Mean AUPR+AUROC: 1.3672778484946821, std: 0.017507115363851584\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.571908686093966\n",
      "AUPR for each fold: [0.56536604 0.5665332  0.58772352 0.56801199]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6272541773079395\n",
      "AUROCperdrug: 0.716437358734749\n",
      "AUPR+AUROCperdrug: 1.3436915360426887\n",
      "AUPR: 0.597222802128841\n",
      "AUROC: 0.66695008969717\n",
      "AUPR+AUROC: 1.2641728918260111\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5805508076468278\n",
      "AUPR for each fold: [0.57957511 0.57732129 0.58512853 0.5801783 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.5999078783987187\n",
      "AUROCperdrug: 0.7116147173998137\n",
      "AUPR+AUROCperdrug: 1.3115225957985324\n",
      "AUPR: 0.5620694755644943\n",
      "AUROC: 0.660747587727461\n",
      "AUPR+AUROC: 1.2228170632919553\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.574655253431605\n",
      "AUPR for each fold: [0.56885292 0.57010258 0.56712181 0.5925437 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6260199760722367\n",
      "AUROCperdrug: 0.7293876301947303\n",
      "AUPR+AUROCperdrug: 1.3554076062669669\n",
      "AUPR: 0.5853272215346412\n",
      "AUROC: 0.6727803696443486\n",
      "AUPR+AUROC: 1.2581075911789898\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5776181550264361\n",
      "AUPR for each fold: [0.58867921 0.57715013 0.54877191 0.59587136]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6077419007326358\n",
      "AUROCperdrug: 0.7163802868545736\n",
      "AUPR+AUROCperdrug: 1.3241221875872093\n",
      "AUPR: 0.5742866043847337\n",
      "AUROC: 0.6656638618881017\n",
      "AUPR+AUROC: 1.2399504662728353\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5787197459229412\n",
      "AUPR for each fold: [0.58770404 0.58609261 0.53277302 0.60830931]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6033900775323405\n",
      "AUROCperdrug: 0.7191997456670922\n",
      "AUPR+AUROCperdrug: 1.3225898231994329\n",
      "AUPR: 0.5681730661139387\n",
      "AUROC: 0.6656908117426108\n",
      "AUPR+AUROC: 1.2338638778565496\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6128628020087743, std: 0.01152396717251859\n",
      "Mean AUROCperdrug: 0.7186039477701918, std: 0.00591829196396419\n",
      "Mean AUPR+AUROCperdrug: 1.331466749778966, std: 0.015831119390965414\n",
      "Mean AUPR: 0.5774158339453297, std: 0.012535051596159351\n",
      "Mean AUROC: 0.6663665441399385, std: 0.0038470958086211727\n",
      "Mean AUPR+AUROC: 1.2437823780852681, std: 0.015320505214254643\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.662801942384854\n",
      "AUROCperdrug: 0.7567615001920089\n",
      "AUPR+AUROCperdrug: 1.4195634425768628\n",
      "AUPR: 0.6579820290773577\n",
      "AUROC: 0.7215409138396647\n",
      "AUPR+AUROC: 1.3795229429170224\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.642245700825646\n",
      "AUROCperdrug: 0.7583864877781116\n",
      "AUPR+AUROCperdrug: 1.4006321886037576\n",
      "AUPR: 0.6227585217699033\n",
      "AUROC: 0.7171898272994963\n",
      "AUPR+AUROC: 1.3399483490693997\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6659493062271635\n",
      "AUROCperdrug: 0.7636185463236249\n",
      "AUPR+AUROCperdrug: 1.4295678525507884\n",
      "AUPR: 0.6568942747804611\n",
      "AUROC: 0.7294870557430158\n",
      "AUPR+AUROC: 1.386381330523477\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6442926361091023\n",
      "AUROCperdrug: 0.7533274800738816\n",
      "AUPR+AUROCperdrug: 1.397620116182984\n",
      "AUPR: 0.6479521166243265\n",
      "AUROC: 0.7326748388463457\n",
      "AUPR+AUROC: 1.3806269554706723\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.642260155791449\n",
      "AUROCperdrug: 0.7575947495044697\n",
      "AUPR+AUROCperdrug: 1.3998549052959186\n",
      "AUPR: 0.6351057887638873\n",
      "AUROC: 0.7206689469871657\n",
      "AUPR+AUROC: 1.355774735751053\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.651509948267643, std: 0.010578078518703852\n",
      "Mean AUROCperdrug: 0.7579377527744193, std: 0.0033235106200035225\n",
      "Mean AUPR+AUROCperdrug: 1.4094477010420623, std: 0.012781044377583702\n",
      "Mean AUPR: 0.6441385462031872, std: 0.013472862358879543\n",
      "Mean AUROC: 0.7243123165431375, std: 0.005803350286694638\n",
      "Mean AUPR+AUROC: 1.3684508627463248, std: 0.017694221370545295\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5733575551225216\n",
      "AUPR for each fold: [0.56670457 0.56777829 0.58946162 0.56948574]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6286913514521636\n",
      "AUROCperdrug: 0.7163487564149328\n",
      "AUPR+AUROCperdrug: 1.3450401078670964\n",
      "AUPR: 0.5989188211864671\n",
      "AUROC: 0.6669048313738604\n",
      "AUPR+AUROC: 1.2658236525603275\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5821084616708802\n",
      "AUPR for each fold: [0.58112336 0.57861119 0.58692304 0.58177626]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6012500711614466\n",
      "AUROCperdrug: 0.710350349664339\n",
      "AUPR+AUROCperdrug: 1.3116004208257857\n",
      "AUPR: 0.5634616395926214\n",
      "AUROC: 0.6593113302922243\n",
      "AUPR+AUROC: 1.2227729698848457\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5761742795658488\n",
      "AUPR for each fold: [0.57034142 0.57147174 0.56874048 0.59414347]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6270284945533883\n",
      "AUROCperdrug: 0.7280143284096423\n",
      "AUPR+AUROCperdrug: 1.3550428229630307\n",
      "AUPR: 0.5868597873553699\n",
      "AUROC: 0.6718466956490116\n",
      "AUPR+AUROC: 1.2587064830043815\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5791628386448503\n",
      "AUPR for each fold: [0.5902236  0.57852049 0.55032797 0.59757929]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6089936527253912\n",
      "AUROCperdrug: 0.7147153766985944\n",
      "AUPR+AUROCperdrug: 1.3237090294239855\n",
      "AUPR: 0.5756961912176259\n",
      "AUROC: 0.6641606844476825\n",
      "AUPR+AUROC: 1.2398568756653083\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5802292668875173\n",
      "AUPR for each fold: [0.58939956 0.58755216 0.53412314 0.60984222]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6044150651234917\n",
      "AUROCperdrug: 0.7182499950765933\n",
      "AUPR+AUROCperdrug: 1.3226650602000851\n",
      "AUPR: 0.569664091855482\n",
      "AUROC: 0.6648123251129845\n",
      "AUPR+AUROC: 1.2344764169684663\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6140757270031763, std: 0.011532943942746541\n",
      "Mean AUROCperdrug: 0.7175357612528204, std: 0.005853275814957234\n",
      "Mean AUPR+AUROCperdrug: 1.3316114882559968, std: 0.015951711638945546\n",
      "Mean AUPR: 0.5789201062415132, std: 0.01263343783116709\n",
      "Mean AUROC: 0.6654071733751526, std: 0.004068840340677266\n",
      "Mean AUPR+AUROC: 1.2443272796166656, std: 0.01581434674095342\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6643789810456396\n",
      "AUROCperdrug: 0.7562682336702797\n",
      "AUPR+AUROCperdrug: 1.4206472147159195\n",
      "AUPR: 0.6598498635228157\n",
      "AUROC: 0.7214997221860718\n",
      "AUPR+AUROC: 1.3813495857088876\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6440126690922983\n",
      "AUROCperdrug: 0.7594998531373314\n",
      "AUPR+AUROCperdrug: 1.4035125222296296\n",
      "AUPR: 0.6247674527845135\n",
      "AUROC: 0.7177380317441999\n",
      "AUPR+AUROC: 1.3425054845287134\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6672742895122521\n",
      "AUROCperdrug: 0.7626765810986751\n",
      "AUPR+AUROCperdrug: 1.4299508706109272\n",
      "AUPR: 0.6586523234175559\n",
      "AUROC: 0.7288695085136991\n",
      "AUPR+AUROC: 1.387521831931255\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6458263397493035\n",
      "AUROCperdrug: 0.7522817545770941\n",
      "AUPR+AUROCperdrug: 1.3981080943263975\n",
      "AUPR: 0.6497319461784166\n",
      "AUROC: 0.7321494363350582\n",
      "AUPR+AUROC: 1.3818813825134748\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6440205949009813\n",
      "AUROCperdrug: 0.7567206240336424\n",
      "AUPR+AUROCperdrug: 1.4007412189346238\n",
      "AUPR: 0.6368471934163822\n",
      "AUROC: 0.7201726749444026\n",
      "AUPR+AUROC: 1.3570198683607848\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6531025748600949, std: 0.010450331830867729\n",
      "Mean AUROCperdrug: 0.7574894093034045, std: 0.0034684464565401326\n",
      "Mean AUPR+AUROCperdrug: 1.4105919841634993, std: 0.012481009640883688\n",
      "Mean AUPR: 0.6459697558639368, std: 0.01341952149532763\n",
      "Mean AUROC: 0.7240858747446863, std: 0.0054808868999451895\n",
      "Mean AUPR+AUROC: 1.3700556306086231, std: 0.017328656410530677\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5748356576010192\n",
      "AUPR for each fold: [0.56806603 0.56921672 0.5907953  0.57126458]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6303061524046759\n",
      "AUROCperdrug: 0.7154083938702753\n",
      "AUPR+AUROCperdrug: 1.3457145462749511\n",
      "AUPR: 0.6004759835658833\n",
      "AUROC: 0.666078735479696\n",
      "AUPR+AUROC: 1.2665547190455793\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5835557335169244\n",
      "AUPR for each fold: [0.58258623 0.58006212 0.58830838 0.58326621]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6028384645712926\n",
      "AUROCperdrug: 0.7099630652050422\n",
      "AUPR+AUROCperdrug: 1.3128015297763347\n",
      "AUPR: 0.5651031255024043\n",
      "AUROC: 0.6589165456575479\n",
      "AUPR+AUROC: 1.2240196711599522\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5776552324765782\n",
      "AUPR for each fold: [0.57182282 0.57309045 0.57020883 0.59549882]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.628453974211384\n",
      "AUROCperdrug: 0.7265358823129514\n",
      "AUPR+AUROCperdrug: 1.3549898565243355\n",
      "AUPR: 0.5883738091959964\n",
      "AUROC: 0.6707124418520689\n",
      "AUPR+AUROC: 1.2590862510480654\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5806879973181109\n",
      "AUPR for each fold: [0.59184483 0.58000772 0.55187766 0.59902178]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6106191463455667\n",
      "AUROCperdrug: 0.7133099555146017\n",
      "AUPR+AUROCperdrug: 1.3239291018601684\n",
      "AUPR: 0.5770910657317354\n",
      "AUROC: 0.6624600953808208\n",
      "AUPR+AUROC: 1.2395511611125563\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5817777829999004\n",
      "AUPR for each fold: [0.59092328 0.5890072  0.53595921 0.61122144]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6060937526191382\n",
      "AUROCperdrug: 0.716937984525031\n",
      "AUPR+AUROCperdrug: 1.323031737144169\n",
      "AUPR: 0.5709944747825806\n",
      "AUROC: 0.6630647698235889\n",
      "AUPR+AUROC: 1.2340592446061693\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6156622980304115, std: 0.011484864781482555\n",
      "Mean AUROCperdrug: 0.7164310562855803, std: 0.005567521932414644\n",
      "Mean AUPR+AUROCperdrug: 1.3320933543159919, std: 0.015689035035715296\n",
      "Mean AUPR: 0.5804076917557199, std: 0.012649377640173797\n",
      "Mean AUROC: 0.6642465176387444, std: 0.0039537736872948875\n",
      "Mean AUPR+AUROC: 1.2446542093944646, std: 0.015823998850190115\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6660113976856424\n",
      "AUROCperdrug: 0.7563910839460499\n",
      "AUPR+AUROCperdrug: 1.4224024816316923\n",
      "AUPR: 0.6615848832205246\n",
      "AUROC: 0.7213124674274058\n",
      "AUPR+AUROC: 1.3828973506479305\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6461572884703867\n",
      "AUROCperdrug: 0.7615212377375994\n",
      "AUPR+AUROCperdrug: 1.407678526207986\n",
      "AUPR: 0.6265985368154907\n",
      "AUROC: 0.7182305114149563\n",
      "AUPR+AUROC: 1.344829048230447\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6683303946311039\n",
      "AUROCperdrug: 0.760751993391104\n",
      "AUPR+AUROCperdrug: 1.4290823880222079\n",
      "AUPR: 0.6603614130637407\n",
      "AUROC: 0.7278271029343044\n",
      "AUPR+AUROC: 1.3881885159980452\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6472928059079298\n",
      "AUROCperdrug: 0.7524730296781229\n",
      "AUPR+AUROCperdrug: 1.3997658355860527\n",
      "AUPR: 0.6513943820423482\n",
      "AUROC: 0.7322659024776343\n",
      "AUPR+AUROC: 1.3836602845199826\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6451801688378889\n",
      "AUROCperdrug: 0.7561049235313926\n",
      "AUPR+AUROCperdrug: 1.4012850923692814\n",
      "AUPR: 0.6384246973025167\n",
      "AUROC: 0.7196259679196905\n",
      "AUPR+AUROC: 1.358050665222207\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6545944111065903, std: 0.010316503867892606\n",
      "Mean AUROCperdrug: 0.7574484536568538, std: 0.0033220142268094582\n",
      "Mean AUPR+AUROCperdrug: 1.412042864763444, std: 0.011689051098157014\n",
      "Mean AUPR: 0.6476727824889241, std: 0.013401858872452654\n",
      "Mean AUROC: 0.7238523904347982, std: 0.005338630989722155\n",
      "Mean AUPR+AUROC: 1.3715251729237223, std: 0.017020574570174456\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.576412850137097\n",
      "AUPR for each fold: [0.56954963 0.57088167 0.59240557 0.57281454]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6315410149275625\n",
      "AUROCperdrug: 0.7143170311704842\n",
      "AUPR+AUROCperdrug: 1.3458580460980467\n",
      "AUPR: 0.6020721544546629\n",
      "AUROC: 0.6653107560005322\n",
      "AUPR+AUROC: 1.2673829104551952\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5851030669219911\n",
      "AUPR for each fold: [0.58404196 0.58170946 0.58982592 0.58483493]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6044074474301544\n",
      "AUROCperdrug: 0.711453828818358\n",
      "AUPR+AUROCperdrug: 1.3158612762485125\n",
      "AUPR: 0.5668306252653542\n",
      "AUROC: 0.6588026688469478\n",
      "AUPR+AUROC: 1.225633294112302\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5793077179089705\n",
      "AUPR for each fold: [0.57335085 0.57478822 0.57189342 0.59719839]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6294002071775948\n",
      "AUROCperdrug: 0.7237513410145675\n",
      "AUPR+AUROCperdrug: 1.3531515481921623\n",
      "AUPR: 0.5897016994562734\n",
      "AUROC: 0.6686000628846369\n",
      "AUPR+AUROC: 1.2583017623409103\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5822389197226134\n",
      "AUPR for each fold: [0.59328193 0.5815588  0.55344595 0.600669  ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.612114901032365\n",
      "AUROCperdrug: 0.7129157533810714\n",
      "AUPR+AUROCperdrug: 1.3250306544134363\n",
      "AUPR: 0.5787996079304778\n",
      "AUROC: 0.662051214557613\n",
      "AUPR+AUROC: 1.2408508224880908\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5833614638622892\n",
      "AUPR for each fold: [0.59226353 0.59077512 0.5373487  0.61305851]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6072327042033498\n",
      "AUROCperdrug: 0.7157650517780394\n",
      "AUPR+AUROCperdrug: 1.3229977559813892\n",
      "AUPR: 0.5725626920553548\n",
      "AUROC: 0.6623084696058186\n",
      "AUPR+AUROC: 1.2348711616611734\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6169392549542053, std: 0.011340409540180646\n",
      "Mean AUROCperdrug: 0.7156406012325041, std: 0.00430128549438463\n",
      "Mean AUPR+AUROCperdrug: 1.3325798561867095, std: 0.014337523120797566\n",
      "Mean AUPR: 0.5819933558324246, std: 0.012582706852840722\n",
      "Mean AUROC: 0.6634146343791096, std: 0.0033116970324693\n",
      "Mean AUPR+AUROC: 1.2454079902115343, std: 0.015309981181019268\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6691671597988696\n",
      "AUROCperdrug: 0.7559936903953605\n",
      "AUPR+AUROCperdrug: 1.4251608501942301\n",
      "AUPR: 0.6655101544902466\n",
      "AUROC: 0.7217407079646017\n",
      "AUPR+AUROC: 1.3872508624548483\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6495748940010405\n",
      "AUROCperdrug: 0.7610741023126458\n",
      "AUPR+AUROCperdrug: 1.4106489963136863\n",
      "AUPR: 0.6305650710205561\n",
      "AUROC: 0.7177610449155216\n",
      "AUPR+AUROC: 1.3483261159360778\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.672480359789406\n",
      "AUROCperdrug: 0.7603528478961756\n",
      "AUPR+AUROCperdrug: 1.4328332076855816\n",
      "AUPR: 0.6643609762881384\n",
      "AUROC: 0.7277007386969042\n",
      "AUPR+AUROC: 1.3920617149850427\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6505831254517731\n",
      "AUROCperdrug: 0.752430498638121\n",
      "AUPR+AUROCperdrug: 1.403013624089894\n",
      "AUPR: 0.655453718542288\n",
      "AUROC: 0.732239215495547\n",
      "AUPR+AUROC: 1.387692934037835\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6493765449451763\n",
      "AUROCperdrug: 0.7563367826884333\n",
      "AUPR+AUROCperdrug: 1.4057133276336096\n",
      "AUPR: 0.642022571964928\n",
      "AUROC: 0.7193887402181453\n",
      "AUPR+AUROC: 1.361411312183073\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6582364167972531, std: 0.010338889972665575\n",
      "Mean AUROCperdrug: 0.7572375843861472, std: 0.00315881388768179\n",
      "Mean AUPR+AUROCperdrug: 1.4154740011834004, std: 0.011567104318667767\n",
      "Mean AUPR: 0.6515824984612314, std: 0.0134564474791088\n",
      "Mean AUROC: 0.723766089458144, std: 0.00541478062344125\n",
      "Mean AUPR+AUROC: 1.3753485879193754, std: 0.017308017122484386\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5796087844634301\n",
      "AUPR for each fold: [0.57283832 0.57414962 0.59533654 0.57611065]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6348175797163571\n",
      "AUROCperdrug: 0.7132496084497677\n",
      "AUPR+AUROCperdrug: 1.3480671881661248\n",
      "AUPR: 0.6054868408431073\n",
      "AUROC: 0.6645062594431255\n",
      "AUPR+AUROC: 1.2699931002862328\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5883878556444013\n",
      "AUPR for each fold: [0.58761276 0.58517022 0.59281659 0.58795185]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.607621567818383\n",
      "AUROCperdrug: 0.7097914828868136\n",
      "AUPR+AUROCperdrug: 1.3174130507051967\n",
      "AUPR: 0.5699774944111213\n",
      "AUROC: 0.656755877348427\n",
      "AUPR+AUROC: 1.2267333717595483\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5825825864023553\n",
      "AUPR for each fold: [0.57682093 0.578211   0.57501463 0.60028379]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6328233931830831\n",
      "AUROCperdrug: 0.7226762610437643\n",
      "AUPR+AUROCperdrug: 1.3554996542268474\n",
      "AUPR: 0.5928991670964894\n",
      "AUROC: 0.6664435192487574\n",
      "AUPR+AUROC: 1.2593426863452468\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.585490178050361\n",
      "AUPR for each fold: [0.59669183 0.58473711 0.55655635 0.60397542]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6155210010184432\n",
      "AUROCperdrug: 0.7113430492027221\n",
      "AUPR+AUROCperdrug: 1.3268640502211653\n",
      "AUPR: 0.5820429672004765\n",
      "AUROC: 0.6600499183201747\n",
      "AUPR+AUROC: 1.2420928855206512\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5866140540816456\n",
      "AUPR for each fold: [0.59562321 0.59385713 0.54072038 0.6162555 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6110696217144223\n",
      "AUROCperdrug: 0.7152417079517508\n",
      "AUPR+AUROCperdrug: 1.326311329666173\n",
      "AUPR: 0.5757828335607249\n",
      "AUROC: 0.6608265393876083\n",
      "AUPR+AUROC: 1.2366093729483332\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6203706326901377, std: 0.011281417551874805\n",
      "Mean AUROCperdrug: 0.7144604219069637, std: 0.00449652074352428\n",
      "Mean AUPR+AUROCperdrug: 1.3348310545971014, std: 0.014434901965133258\n",
      "Mean AUPR: 0.5852378606223839, std: 0.012658597667082355\n",
      "Mean AUROC: 0.6617164227496186, std: 0.00341481390934353\n",
      "Mean AUPR+AUROC: 1.2469542833720024, std: 0.015644777021207184\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6724938542277287\n",
      "AUROCperdrug: 0.7557978783916897\n",
      "AUPR+AUROCperdrug: 1.4282917326194182\n",
      "AUPR: 0.6697798435078122\n",
      "AUROC: 0.7220145593259576\n",
      "AUPR+AUROC: 1.3917944028337699\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6537878668677081\n",
      "AUROCperdrug: 0.7626661628173733\n",
      "AUPR+AUROCperdrug: 1.4164540296850814\n",
      "AUPR: 0.6344071497736165\n",
      "AUROC: 0.7180107784266443\n",
      "AUPR+AUROC: 1.3524179282002606\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6772631269592336\n",
      "AUROCperdrug: 0.7604657587744864\n",
      "AUPR+AUROCperdrug: 1.43772888573372\n",
      "AUPR: 0.6678470587805965\n",
      "AUROC: 0.7269727083486174\n",
      "AUPR+AUROC: 1.394819767129214\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6541978433786956\n",
      "AUROCperdrug: 0.7532913899826207\n",
      "AUPR+AUROCperdrug: 1.4074892333613163\n",
      "AUPR: 0.6591967700873343\n",
      "AUROC: 0.732481514928173\n",
      "AUPR+AUROC: 1.3916782850155074\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6529214289037371\n",
      "AUROCperdrug: 0.7558904413131875\n",
      "AUPR+AUROCperdrug: 1.4088118702169246\n",
      "AUPR: 0.6460817351963735\n",
      "AUROC: 0.719098501663533\n",
      "AUPR+AUROC: 1.3651802368599064\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6621328240674206, std: 0.010523583435672708\n",
      "Mean AUROCperdrug: 0.7576223262558714, std: 0.003423753502045149\n",
      "Mean AUPR+AUROCperdrug: 1.419755150323292, std: 0.011636441876923823\n",
      "Mean AUPR: 0.6554625114691467, std: 0.013443473627391626\n",
      "Mean AUROC: 0.723715612538585, std: 0.005370403056177292\n",
      "Mean AUPR+AUROC: 1.3791781240077317, std: 0.017158871993426097\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5829672650109585\n",
      "AUPR for each fold: [0.57603159 0.57750295 0.59870323 0.5796313 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6379513639441058\n",
      "AUROCperdrug: 0.7106552274593853\n",
      "AUPR+AUROCperdrug: 1.348606591403491\n",
      "AUPR: 0.6087812894699239\n",
      "AUROC: 0.6625554560532927\n",
      "AUPR+AUROC: 1.2713367455232167\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5916884437214581\n",
      "AUPR for each fold: [0.59085535 0.58847727 0.59611289 0.59130827]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.611868038571204\n",
      "AUROCperdrug: 0.7098282544607285\n",
      "AUPR+AUROCperdrug: 1.3216962930319325\n",
      "AUPR: 0.573475810209463\n",
      "AUROC: 0.6558502246880957\n",
      "AUPR+AUROC: 1.2293260348975588\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5859414767078408\n",
      "AUPR for each fold: [0.58010963 0.58166297 0.57832725 0.60366605]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6366563455307284\n",
      "AUROCperdrug: 0.7225752781513972\n",
      "AUPR+AUROCperdrug: 1.3592316236821256\n",
      "AUPR: 0.5961702651539529\n",
      "AUROC: 0.6640907443819252\n",
      "AUPR+AUROC: 1.2602610095358782\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5887576537488742\n",
      "AUPR for each fold: [0.60000142 0.58781151 0.55979964 0.60741804]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6192267337094642\n",
      "AUROCperdrug: 0.710951724749039\n",
      "AUPR+AUROCperdrug: 1.3301784584585032\n",
      "AUPR: 0.5856784115313042\n",
      "AUROC: 0.6593243999295979\n",
      "AUPR+AUROC: 1.245002811460902\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5900450181935788\n",
      "AUPR for each fold: [0.5990213  0.59723487 0.544071   0.61985291]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6142453914920397\n",
      "AUROCperdrug: 0.7116114832615604\n",
      "AUPR+AUROCperdrug: 1.3258568747536001\n",
      "AUPR: 0.5787856588045114\n",
      "AUROC: 0.6577566179693723\n",
      "AUPR+AUROC: 1.2365422767738838\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6239895746495084, std: 0.01113502618755923\n",
      "Mean AUROCperdrug: 0.7131243936164221, std: 0.00476004035880638\n",
      "Mean AUPR+AUROCperdrug: 1.3371139682659305, std: 0.014379146205160034\n",
      "Mean AUPR: 0.5885782870338311, std: 0.012634786037029522\n",
      "Mean AUROC: 0.6599154886044568, std: 0.0030311274433266516\n",
      "Mean AUPR+AUROC: 1.248493775638288, std: 0.01537983425048407\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.674374956892906\n",
      "AUROCperdrug: 0.755500136590873\n",
      "AUPR+AUROCperdrug: 1.429875093483779\n",
      "AUPR: 0.6728027333305285\n",
      "AUROC: 0.7225174141353817\n",
      "AUPR+AUROC: 1.3953201474659103\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6554852886194339\n",
      "AUROCperdrug: 0.760910953134082\n",
      "AUPR+AUROCperdrug: 1.4163962417535159\n",
      "AUPR: 0.6369427613755996\n",
      "AUROC: 0.7172255449882918\n",
      "AUPR+AUROC: 1.3541683063638914\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6793661176113973\n",
      "AUROCperdrug: 0.7598138061496318\n",
      "AUPR+AUROCperdrug: 1.4391799237610292\n",
      "AUPR: 0.6706078418029721\n",
      "AUROC: 0.7269897241867738\n",
      "AUPR+AUROC: 1.397597565989746\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.656196666885411\n",
      "AUROCperdrug: 0.7516500207523887\n",
      "AUPR+AUROCperdrug: 1.4078466876377997\n",
      "AUPR: 0.6624159894346093\n",
      "AUROC: 0.7322962914170558\n",
      "AUPR+AUROC: 1.3947122808516652\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6545229254794128\n",
      "AUROCperdrug: 0.7539886690326536\n",
      "AUPR+AUROCperdrug: 1.4085115945120665\n",
      "AUPR: 0.6490062900851608\n",
      "AUROC: 0.7183835636714944\n",
      "AUPR+AUROC: 1.3673898537566551\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6639891910977122, std: 0.010648605315959982\n",
      "Mean AUROCperdrug: 0.7563727171319259, std: 0.0034981601699351334\n",
      "Mean AUPR+AUROCperdrug: 1.4203619082296381, std: 0.012307766608823547\n",
      "Mean AUPR: 0.658355123205774, std: 0.01357382116967005\n",
      "Mean AUROC: 0.7234825076797995, std: 0.005586833970436967\n",
      "Mean AUPR+AUROC: 1.3818376308855735, std: 0.01772140063894061\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5854513062154876\n",
      "AUPR for each fold: [0.57857292 0.58003881 0.60143769 0.58175581]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6400395418125499\n",
      "AUROCperdrug: 0.7096374218470785\n",
      "AUPR+AUROCperdrug: 1.3496769636596282\n",
      "AUPR: 0.6116080373388224\n",
      "AUROC: 0.66254014082623\n",
      "AUPR+AUROC: 1.2741481781650523\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5943040561232049\n",
      "AUPR for each fold: [0.59353406 0.5909141  0.59918131 0.59358676]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6137494949736518\n",
      "AUROCperdrug: 0.7076220996097429\n",
      "AUPR+AUROCperdrug: 1.3213715945833946\n",
      "AUPR: 0.5759713622526667\n",
      "AUROC: 0.6541769633234952\n",
      "AUPR+AUROC: 1.2301483255761618\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5884313717887308\n",
      "AUPR for each fold: [0.58279363 0.58389279 0.58106588 0.60597319]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6390821226286566\n",
      "AUROCperdrug: 0.7228576877536622\n",
      "AUPR+AUROCperdrug: 1.3619398103823188\n",
      "AUPR: 0.5990824391190086\n",
      "AUROC: 0.6641057602180265\n",
      "AUPR+AUROC: 1.263188199337035\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5914130688762627\n",
      "AUPR for each fold: [0.60293217 0.59014151 0.56251299 0.61006561]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6211362017767947\n",
      "AUROCperdrug: 0.7082977158782146\n",
      "AUPR+AUROCperdrug: 1.3294339176550092\n",
      "AUPR: 0.5880635885379106\n",
      "AUROC: 0.6567669988264443\n",
      "AUPR+AUROC: 1.2448305873643548\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5927070770769856\n",
      "AUPR for each fold: [0.60200716 0.59959744 0.54668919 0.62253452]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6159175300506683\n",
      "AUROCperdrug: 0.7081095939002294\n",
      "AUPR+AUROCperdrug: 1.3240271239508976\n",
      "AUPR: 0.5810683917841282\n",
      "AUROC: 0.6552093343244105\n",
      "AUPR+AUROC: 1.2362777261085387\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6259849782484642, std: 0.011345811080290927\n",
      "Mean AUROCperdrug: 0.7113049037977854, std: 0.005814869635677033\n",
      "Mean AUPR+AUROCperdrug: 1.3372898820462498, std: 0.015824459311029868\n",
      "Mean AUPR: 0.5911587638065073, std: 0.012829733449361534\n",
      "Mean AUROC: 0.6585598395037213, std: 0.004006240168766842\n",
      "Mean AUPR+AUROC: 1.2497186033102285, std: 0.016527430502890218\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.677353856543635\n",
      "AUROCperdrug: 0.7542482848952998\n",
      "AUPR+AUROCperdrug: 1.4316021414389348\n",
      "AUPR: 0.6749066550174716\n",
      "AUROC: 0.7206039266307124\n",
      "AUPR+AUROC: 1.395510581648184\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.658094180154802\n",
      "AUROCperdrug: 0.7595066155860511\n",
      "AUPR+AUROCperdrug: 1.4176007957408532\n",
      "AUPR: 0.6388337383094653\n",
      "AUROC: 0.7140503243239915\n",
      "AUPR+AUROC: 1.3528840626334568\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6827823429750439\n",
      "AUROCperdrug: 0.7597402729952691\n",
      "AUPR+AUROCperdrug: 1.442522615970313\n",
      "AUPR: 0.672766075470136\n",
      "AUROC: 0.7248033615033195\n",
      "AUPR+AUROC: 1.3975694369734555\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6608164864802366\n",
      "AUROCperdrug: 0.753764043347105\n",
      "AUPR+AUROCperdrug: 1.4145805298273415\n",
      "AUPR: 0.6652408520921143\n",
      "AUROC: 0.732469633858758\n",
      "AUPR+AUROC: 1.3977104859508722\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6571887328889686\n",
      "AUROCperdrug: 0.7530106860617387\n",
      "AUPR+AUROCperdrug: 1.4101994189507074\n",
      "AUPR: 0.6515563472235923\n",
      "AUROC: 0.7165345683371331\n",
      "AUPR+AUROC: 1.3680909155607255\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6672471198085372, std: 0.010675109207848496\n",
      "Mean AUROCperdrug: 0.7560539805770927, std: 0.002941952794220309\n",
      "Mean AUPR+AUROCperdrug: 1.4233011003856302, std: 0.01198807594460773\n",
      "Mean AUPR: 0.660660733622556, std: 0.013636499836331837\n",
      "Mean AUROC: 0.7216923629307829, std: 0.00651177661611\n",
      "Mean AUPR+AUROC: 1.3823530965533388, std: 0.018505888823542836\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5892980055352679\n",
      "AUPR for each fold: [0.58239583 0.58372276 0.6055664  0.58550704]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6447444432805334\n",
      "AUROCperdrug: 0.710542722474762\n",
      "AUPR+AUROCperdrug: 1.3552871657552954\n",
      "AUPR: 0.6153412436947356\n",
      "AUROC: 0.6618413694306552\n",
      "AUPR+AUROC: 1.2771826131253907\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5982265496473191\n",
      "AUPR for each fold: [0.59753446 0.59477325 0.60320494 0.59739355]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6172765577970479\n",
      "AUROCperdrug: 0.7054935168141718\n",
      "AUPR+AUROCperdrug: 1.3227700746112196\n",
      "AUPR: 0.5795475996810154\n",
      "AUROC: 0.6521877285013802\n",
      "AUPR+AUROC: 1.2317353281823955\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5922142495444495\n",
      "AUPR for each fold: [0.58650442 0.58775462 0.58478986 0.6098081 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6432255595778517\n",
      "AUROCperdrug: 0.7243001009122328\n",
      "AUPR+AUROCperdrug: 1.3675256604900845\n",
      "AUPR: 0.6030381282813063\n",
      "AUROC: 0.6639613187087763\n",
      "AUPR+AUROC: 1.2669994469900825\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5950267319607143\n",
      "AUPR for each fold: [0.60659318 0.5937058  0.56608095 0.613727  ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6266550319334739\n",
      "AUROCperdrug: 0.7130071099500778\n",
      "AUPR+AUROCperdrug: 1.3396621418835517\n",
      "AUPR: 0.5926586415075834\n",
      "AUROC: 0.6595588256665414\n",
      "AUPR+AUROC: 1.2522174671741249\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUPR: 0.5966049407174246\n",
      "AUPR for each fold: [0.60595229 0.60343163 0.55038744 0.6266484 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.6200734891951597\n",
      "AUROCperdrug: 0.7072834840271448\n",
      "AUPR+AUROCperdrug: 1.3273569732223045\n",
      "AUPR: 0.5846153655104768\n",
      "AUROC: 0.653610310523377\n",
      "AUPR+AUROC: 1.2382256760338537\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.6303950163568134, std: 0.011516459992601645\n",
      "Mean AUROCperdrug: 0.7121253868356778, std: 0.0066171239638543435\n",
      "Mean AUPR+AUROCperdrug: 1.342520403192491, std: 0.016831089472122657\n",
      "Mean AUPR: 0.5950401957350235, std: 0.012887737516871993\n",
      "Mean AUROC: 0.658231910566146, std: 0.004593611616809556\n",
      "Mean AUPR+AUROC: 1.2532721063011694, std: 0.01703814754129925\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "SEs = {}\n",
    "SIDER = Pairs2Mat(path=\"data/drug_se.tsv\",colname1=\"1_x\",colname2=\"5\")\n",
    "column_sums = np.sum(SIDER, axis=0)\n",
    "results[\"KRR\"] = {}\n",
    "results[\"Naive\"] = {}\n",
    "for i in range(0, 300, 5):\n",
    "    results[\"KRR\"][i] = {}\n",
    "    results[\"Naive\"][i] = {}\n",
    "    SEs[\"SIDER\"] = SIDER.loc[:, (column_sums >= i)]\n",
    "    \n",
    "    validation = \"nested_cv\"\n",
    "    method = \"KRR\"\n",
    "    str = \"DGI\"\n",
    "    print(f\"using feature {str}\")\n",
    "    hyperparList = loadHyperpar(*all_hyperparlist[method],method_option=method)\n",
    "    results[method][i], _ = evaluation(Y=SEs[\"SIDER\"], X=features_dict[str], method_option=method,tuning_metrice=metrice,hyperparList=hyperparList,hyperparfixed=hyperpars[validation][method][str],Validation=validation, n_jobs=1)\n",
    "\n",
    "    method = \"Naive\"\n",
    "    print(f\"using feature {str}\")\n",
    "    hyperparList = loadHyperpar(*all_hyperparlist[method],method_option=method)\n",
    "    results[method][i], _ = evaluation(Y=SEs[\"SIDER\"], X=features_dict[str], method_option=method,tuning_metrice=metrice,hyperparList=hyperparList,Validation=validation,n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3500x1750 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "vector1 = []\n",
    "metrice = \"AUPR\"\n",
    "for i in range(0, 300, 5):\n",
    "    vector1.append(np.array(results[\"KRR\"][i][metrice]).mean())\n",
    "    vector2 = []\n",
    "x = []\n",
    "for i in range(0, 300, 5):\n",
    "    vector2.append(np.array(results[\"Naive\"][i][metrice]).mean())\n",
    "    x.append(i)\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot the first series\n",
    "plt.plot(x, vector1, marker='o', linestyle='-', color='b', label='KRR')\n",
    "\n",
    "# Plot the second series\n",
    "plt.plot(x, vector2, marker='s', linestyle='--', color='r', label='Naive')\n",
    "\n",
    "# Add titles and labels\n",
    "# plt.title(f\"{metrice}\", \" - $\\{tau}$\")\n",
    "plt.xlabel('threshold (ADRs greater than)')\n",
    "plt.ylabel('Value')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show grid\n",
    "plt.grid(True)\n",
    "\n",
    "# Display the chart\n",
    "plt.show()\n",
    "\n",
    "vector1 = []\n",
    "metrice = \"AUROC\"\n",
    "for i in range(0, 300, 5):\n",
    "    vector1.append(np.array(results[\"KRR\"][i][metrice]).mean())\n",
    "    vector2 = []\n",
    "x = []\n",
    "for i in range(0, 300, 5):\n",
    "    vector2.append(np.array(results[\"Naive\"][i][metrice]).mean())\n",
    "    x.append(i)\n",
    "plt.figure(figsize=(10, 5), dpi=350)\n",
    "\n",
    "# Plot the first series\n",
    "plt.plot(x, vector1, marker='o', linestyle='-', color='b', label='KRR')\n",
    "\n",
    "# Plot the second series\n",
    "plt.plot(x, vector2, marker='s', linestyle='--', color='r', label='Naive')\n",
    "plt.axvline(x=5, color='black', linestyle='--', linewidth=2)\n",
    "# Add titles and labels\n",
    "plt.title(f\"{metrice} - \"+\"$\\\\tau$\")\n",
    "plt.xlabel('$\\\\tau$')\n",
    "plt.ylabel('Value')\n",
    "plt.text(18, 0.9, \"$\\\\tau=5$\", color='black', fontsize=12, ha='center')\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show grid\n",
    "plt.grid(True)\n",
    "plt.savefig(fname=f\"figs/define_tau.jpg\", bbox_inches=\"tight\")\n",
    "# Display the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 91  96 164 184 261 315 379 433 470 498]\n",
      "first few testing idx:  [ 78 117 140 292 343 381 401 542 553 565]\n",
      "--- tuning end ---\n",
      "target size: 113\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.03250106567304588\n",
      "AUROCperdrug: 0.5647942617266507\n",
      "AUPR+AUROCperdrug: 0.5972953273996966\n",
      "AUPR: 0.005219135204051869\n",
      "AUROC: 0.5229937610375358\n",
      "AUPR+AUROC: 0.5282128962415876\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 78 117 140 292 343 381 401 542 553 565]\n",
      "first few testing idx:  [ 91  96 164 184 261 315 379 433 470 498]\n",
      "--- tuning end ---\n",
      "target size: 113\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.043965607817668194\n",
      "AUROCperdrug: 0.5530996226141979\n",
      "AUPR+AUROCperdrug: 0.5970652304318661\n",
      "AUPR: 0.004483495349716421\n",
      "AUROC: 0.5535203712909393\n",
      "AUPR+AUROC: 0.5580038666406557\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 78 117 140 292 343 381 401 542 553 565]\n",
      "first few testing idx:  [ 30  70  75 125 149 234 279 300 385 422]\n",
      "--- tuning end ---\n",
      "target size: 113\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.022382958131813444\n",
      "AUROCperdrug: 0.5275027505676537\n",
      "AUPR+AUROCperdrug: 0.5498857086994672\n",
      "AUPR: 0.004826781199664485\n",
      "AUROC: 0.5359236208148522\n",
      "AUPR+AUROC: 0.5407504020145167\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 78 117 140 292 343 381 401 542 553 565]\n",
      "first few testing idx:  [ 19 151 160 196 244 272 310 517 536 562]\n",
      "--- tuning end ---\n",
      "target size: 113\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.024340134155456824\n",
      "AUROCperdrug: 0.5721402816198687\n",
      "AUPR+AUROCperdrug: 0.5964804157753255\n",
      "AUPR: 0.005146364889038797\n",
      "AUROC: 0.5273119054374625\n",
      "AUPR+AUROC: 0.5324582703265013\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 78 117 140 292 343 381 401 542 553 565]\n",
      "first few testing idx:  [  5  81 154 195 241 246 276 291 319 348]\n",
      "--- tuning end ---\n",
      "target size: 113\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.0707985358571176\n",
      "AUROCperdrug: 0.5956760804675438\n",
      "AUPR+AUROCperdrug: 0.6664746163246614\n",
      "AUPR: 0.004079884554268252\n",
      "AUROC: 0.542728337657099\n",
      "AUPR+AUROC: 0.5468082222113673\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.03879766032702039, std: 0.017713685846565668\n",
      "Mean AUROCperdrug: 0.5626425993991829, std: 0.02241394151706398\n",
      "Mean AUPR+AUROCperdrug: 0.6014402597262034, std: 0.03727803821844288\n",
      "Mean AUPR: 0.004751132239347965, std: 0.00042500855214142947\n",
      "Mean AUROC: 0.5364955992475778, std: 0.010914732407031778\n",
      "Mean AUPR+AUROC: 0.5412467314869257, std: 0.010574459904453853\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 91  96 164 184 261 315 379 433 470 498]\n",
      "first few testing idx:  [ 78 117 140 292 343 381 401 542 553 565]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.4575106653059076\n",
      "AUROC for each fold: [0.45844611 0.44695578 0.46995282 0.45468796]\n",
      "--- tuning end ---\n",
      "target size: 113\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.002143974485453211\n",
      "AUROCperdrug: 0.47905525948819205\n",
      "AUPR+AUROCperdrug: 0.4811992339736453\n",
      "AUPR: 0.002000619435963916\n",
      "AUROC: 0.41961930468105424\n",
      "AUPR+AUROC: 0.42161992411701815\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 78 117 140 292 343 381 401 542 553 565]\n",
      "first few testing idx:  [ 91  96 164 184 261 315 379 433 470 498]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.4396518345550445\n",
      "AUROC for each fold: [0.42895121 0.43532242 0.44587883 0.44845488]\n",
      "--- tuning end ---\n",
      "target size: 113\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.0016097148328884474\n",
      "AUROCperdrug: 0.4244047794090875\n",
      "AUPR+AUROCperdrug: 0.42601449424197596\n",
      "AUPR: 0.0013731935921433532\n",
      "AUROC: 0.42766120763600396\n",
      "AUPR+AUROC: 0.4290344012281473\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 78 117 140 292 343 381 401 542 553 565]\n",
      "first few testing idx:  [ 30  70  75 125 149 234 279 300 385 422]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.4495385440285491\n",
      "AUROC for each fold: [0.43708301 0.45040255 0.44362785 0.46704076]\n",
      "--- tuning end ---\n",
      "target size: 113\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.0018117435489734249\n",
      "AUROCperdrug: 0.45826022708006825\n",
      "AUPR+AUROCperdrug: 0.46007197062904165\n",
      "AUPR: 0.0016773527322627197\n",
      "AUROC: 0.42718460151923593\n",
      "AUPR+AUROC: 0.42886195425149864\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 78 117 140 292 343 381 401 542 553 565]\n",
      "first few testing idx:  [ 19 151 160 196 244 272 310 517 536 562]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.43804758567578705\n",
      "AUROC for each fold: [0.44048186 0.433053   0.43643605 0.44221942]\n",
      "--- tuning end ---\n",
      "target size: 113\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.001586080770879652\n",
      "AUROCperdrug: 0.45376435730706777\n",
      "AUPR+AUROCperdrug: 0.4553504380779474\n",
      "AUPR: 0.0014431019560603687\n",
      "AUROC: 0.4277673050673189\n",
      "AUPR+AUROC: 0.42921040702337926\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 78 117 140 292 343 381 401 542 553 565]\n",
      "first few testing idx:  [  5  81 154 195 241 246 276 291 319 348]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.43502969069278796\n",
      "AUROC for each fold: [0.44532981 0.43720592 0.42777181 0.42981122]\n",
      "--- tuning end ---\n",
      "target size: 113\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.001600711694305843\n",
      "AUROCperdrug: 0.463103817867331\n",
      "AUPR+AUROCperdrug: 0.4647045295616369\n",
      "AUPR: 0.001431576859727234\n",
      "AUROC: 0.43357942421621953\n",
      "AUPR+AUROC: 0.43501100107594676\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.0017504450665001155, std: 0.00021347768530268727\n",
      "Mean AUROCperdrug: 0.45571768823034925, std: 0.017832416592128062\n",
      "Mean AUPR+AUROCperdrug: 0.45746813329684943, std: 0.017978468132297535\n",
      "Mean AUPR: 0.0015851689152315183, std: 0.00023229467032188345\n",
      "Mean AUROC: 0.4271623686239665, std: 0.004442785137343183\n",
      "Mean AUPR+AUROC: 0.42874753753919803, std: 0.00425072884789649\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 78 402 411 445 452 495 537 545 570 676]\n",
      "first few testing idx:  [129 142 186 262 316 398 429 448 498 550]\n",
      "--- tuning end ---\n",
      "target size: 144\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.10063286119046104\n",
      "AUROCperdrug: 0.7354629826189132\n",
      "AUPR+AUROCperdrug: 0.8360958438093742\n",
      "AUPR: 0.05190652541364869\n",
      "AUROC: 0.6840955156956265\n",
      "AUPR+AUROC: 0.7360020411092753\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [129 142 186 262 316 398 429 448 498 550]\n",
      "first few testing idx:  [ 78 402 411 445 452 495 537 545 570 676]\n",
      "--- tuning end ---\n",
      "target size: 144\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.10064585607102826\n",
      "AUROCperdrug: 0.7091287821315834\n",
      "AUPR+AUROCperdrug: 0.8097746382026116\n",
      "AUPR: 0.048197276251003\n",
      "AUROC: 0.6521370279268042\n",
      "AUPR+AUROC: 0.7003343041778072\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [129 142 186 262 316 398 429 448 498 550]\n",
      "first few testing idx:  [106 111 227 301 323 474 521 551 667 679]\n",
      "--- tuning end ---\n",
      "target size: 144\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.08147061884873133\n",
      "AUROCperdrug: 0.6864956734215095\n",
      "AUPR+AUROCperdrug: 0.7679662922702408\n",
      "AUPR: 0.040909980118659886\n",
      "AUROC: 0.6603108767498447\n",
      "AUPR+AUROC: 0.7012208568685045\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [129 142 186 262 316 398 429 448 498 550]\n",
      "first few testing idx:  [107 130 162 285 403 417 418 426 534 711]\n",
      "--- tuning end ---\n",
      "target size: 144\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.09466366620382582\n",
      "AUROCperdrug: 0.72262696926142\n",
      "AUPR+AUROCperdrug: 0.8172906354652458\n",
      "AUPR: 0.03456069673240636\n",
      "AUROC: 0.6828887755556945\n",
      "AUPR+AUROC: 0.7174494722881009\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [129 142 186 262 316 398 429 448 498 550]\n",
      "first few testing idx:  [ 15 152 158 198 208 278 465 541 564 589]\n",
      "--- tuning end ---\n",
      "target size: 144\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.0740415106955315\n",
      "AUROCperdrug: 0.6855295980825983\n",
      "AUPR+AUROCperdrug: 0.7595711087781298\n",
      "AUPR: 0.03758040311489512\n",
      "AUROC: 0.6646576704349793\n",
      "AUPR+AUROC: 0.7022380735498743\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.09029090260191559, std: 0.01072513284884449\n",
      "Mean AUROCperdrug: 0.7078488011032049, std: 0.019680846077309876\n",
      "Mean AUPR+AUROCperdrug: 0.7981397037051204, std: 0.029464452249843166\n",
      "Mean AUPR: 0.042630976326122616, std: 0.006490285604773522\n",
      "Mean AUROC: 0.6688179732725898, std: 0.012643761528555746\n",
      "Mean AUPR+AUROC: 0.7114489495987124, std: 0.013797463800200225\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 78 402 411 445 452 495 537 545 570 676]\n",
      "first few testing idx:  [129 142 186 262 316 398 429 448 498 550]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.7173368692747054\n",
      "AUROC for each fold: [0.71680787 0.7169972  0.72396244 0.71157997]\n",
      "--- tuning end ---\n",
      "target size: 144\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.013967581652109876\n",
      "AUROCperdrug: 0.7498526872431598\n",
      "AUPR+AUROCperdrug: 0.7638202688952697\n",
      "AUPR: 0.011046183136322725\n",
      "AUROC: 0.7136026824149101\n",
      "AUPR+AUROC: 0.7246488655512329\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [129 142 186 262 316 398 429 448 498 550]\n",
      "first few testing idx:  [ 78 402 411 445 452 495 537 545 570 676]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.7148797192312394\n",
      "AUROC for each fold: [0.72278275 0.7193033  0.71970718 0.69772565]\n",
      "--- tuning end ---\n",
      "target size: 144\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.015514044465166335\n",
      "AUROCperdrug: 0.736299172550999\n",
      "AUPR+AUROCperdrug: 0.7518132170161653\n",
      "AUPR: 0.013557551179515901\n",
      "AUROC: 0.7186952688739037\n",
      "AUPR+AUROC: 0.7322528200534195\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [129 142 186 262 316 398 429 448 498 550]\n",
      "first few testing idx:  [106 111 227 301 323 474 521 551 667 679]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.7167981696835014\n",
      "AUROC for each fold: [0.71981784 0.71842625 0.72794658 0.70100201]\n",
      "--- tuning end ---\n",
      "target size: 144\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.011809917868101665\n",
      "AUROCperdrug: 0.73012506321837\n",
      "AUPR+AUROCperdrug: 0.7419349810864717\n",
      "AUPR: 0.010098389197649988\n",
      "AUROC: 0.7230228862227734\n",
      "AUPR+AUROC: 0.7331212754204234\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [129 142 186 262 316 398 429 448 498 550]\n",
      "first few testing idx:  [107 130 162 285 403 417 418 426 534 711]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.7123962324188362\n",
      "AUROC for each fold: [0.71003002 0.71781757 0.71294515 0.70879218]\n",
      "--- tuning end ---\n",
      "target size: 144\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.020779197751981105\n",
      "AUROCperdrug: 0.7557854044436506\n",
      "AUPR+AUROCperdrug: 0.7765646021956317\n",
      "AUPR: 0.01454610952775448\n",
      "AUROC: 0.7285500356644943\n",
      "AUPR+AUROC: 0.7430961451922488\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [129 142 186 262 316 398 429 448 498 550]\n",
      "first few testing idx:  [ 15 152 158 198 208 278 465 541 564 589]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.7120318190312809\n",
      "AUROC for each fold: [0.7250601  0.71116825 0.69980415 0.71209478]\n",
      "--- tuning end ---\n",
      "target size: 144\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.017454243762349282\n",
      "AUROCperdrug: 0.7410018255828847\n",
      "AUPR+AUROCperdrug: 0.758456069345234\n",
      "AUPR: 0.015080991097127497\n",
      "AUROC: 0.7251340134578944\n",
      "AUPR+AUROC: 0.7402150045550219\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.015904997099941653, std: 0.0030605258931270343\n",
      "Mean AUROCperdrug: 0.7426128306078128, std: 0.009212319742415816\n",
      "Mean AUPR+AUROCperdrug: 0.7585178277077544, std: 0.011608172747245422\n",
      "Mean AUPR: 0.01286584482767412, std: 0.0019584993985044623\n",
      "Mean AUROC: 0.7218009773267952, std: 0.0051963341713856725\n",
      "Mean AUPR+AUROC: 0.7346668221544693, std: 0.006487085480866767\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 78 305 355 378 498 546 623 648 681 687]\n",
      "first few testing idx:  [139 282 369 438 510 565 660 677 685 727]\n",
      "--- tuning end ---\n",
      "target size: 146\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.09890384841022298\n",
      "AUROCperdrug: 0.7392433818833114\n",
      "AUPR+AUROCperdrug: 0.8381472302935344\n",
      "AUPR: 0.06627299818499753\n",
      "AUROC: 0.7024055045503924\n",
      "AUPR+AUROC: 0.76867850273539\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [139 282 369 438 510 565 660 677 685 727]\n",
      "first few testing idx:  [ 78 305 355 378 498 546 623 648 681 687]\n",
      "--- tuning end ---\n",
      "target size: 146\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.09715286776244281\n",
      "AUROCperdrug: 0.7441434611160965\n",
      "AUPR+AUROCperdrug: 0.8412963288785393\n",
      "AUPR: 0.06604424839924311\n",
      "AUROC: 0.694179829272533\n",
      "AUPR+AUROC: 0.7602240776717761\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [139 282 369 438 510 565 660 677 685 727]\n",
      "first few testing idx:  [106 111 227 300 339 385 429 479 534 554]\n",
      "--- tuning end ---\n",
      "target size: 146\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.10632523233873611\n",
      "AUROCperdrug: 0.726512805291685\n",
      "AUPR+AUROCperdrug: 0.8328380376304212\n",
      "AUPR: 0.07057004280749074\n",
      "AUROC: 0.7174250386083403\n",
      "AUPR+AUROC: 0.787995081415831\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [139 282 369 438 510 565 660 677 685 727]\n",
      "first few testing idx:  [ 21 107 130 162 285 403 417 418 426 717]\n",
      "--- tuning end ---\n",
      "target size: 146\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.10091298619514705\n",
      "AUROCperdrug: 0.7493892618934558\n",
      "AUPR+AUROCperdrug: 0.8503022480886029\n",
      "AUPR: 0.0669136755939864\n",
      "AUROC: 0.7197733713261218\n",
      "AUPR+AUROC: 0.7866870469201083\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [139 282 369 438 510 565 660 677 685 727]\n",
      "first few testing idx:  [ 15  50 113 158 198 272 278 621 627 702]\n",
      "--- tuning end ---\n",
      "target size: 146\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.10520614737280784\n",
      "AUROCperdrug: 0.7378746294190188\n",
      "AUPR+AUROCperdrug: 0.8430807767918267\n",
      "AUPR: 0.07532204171977476\n",
      "AUROC: 0.7195845446255459\n",
      "AUPR+AUROC: 0.7949065863453206\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.10170021641587135, std: 0.003544012115691256\n",
      "Mean AUROCperdrug: 0.7394327079207135, std: 0.007625109829889657\n",
      "Mean AUPR+AUROCperdrug: 0.841132924336585, std: 0.005755290482466414\n",
      "Mean AUPR: 0.06902460134109852, std: 0.0035484074102486735\n",
      "Mean AUROC: 0.7106736576765866, std: 0.010470898440409776\n",
      "Mean AUPR+AUROC: 0.7796982590176853, std: 0.013035738613292836\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 78 305 355 378 498 546 623 648 681 687]\n",
      "first few testing idx:  [139 282 369 438 510 565 660 677 685 727]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.7666575045248194\n",
      "AUROC for each fold: [0.7650732  0.77973722 0.7546115  0.76720809]\n",
      "--- tuning end ---\n",
      "target size: 146\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.026343319233019094\n",
      "AUROCperdrug: 0.775692554956797\n",
      "AUPR+AUROCperdrug: 0.8020358741898161\n",
      "AUPR: 0.022897151177046667\n",
      "AUROC: 0.7735665955119695\n",
      "AUPR+AUROC: 0.7964637466890162\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [139 282 369 438 510 565 660 677 685 727]\n",
      "first few testing idx:  [ 78 305 355 378 498 546 623 648 681 687]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.7731315755023387\n",
      "AUROC for each fold: [0.77295348 0.78952681 0.75606435 0.77398167]\n",
      "--- tuning end ---\n",
      "target size: 146\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.031112218305188972\n",
      "AUROCperdrug: 0.7903762451623461\n",
      "AUPR+AUROCperdrug: 0.821488463467535\n",
      "AUPR: 0.026976484325007603\n",
      "AUROC: 0.7592075989478949\n",
      "AUPR+AUROC: 0.7861840832729026\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [139 282 369 438 510 565 660 677 685 727]\n",
      "first few testing idx:  [106 111 227 300 339 385 429 479 534 554]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.7661104044440368\n",
      "AUROC for each fold: [0.7639923  0.77559897 0.75926848 0.76558187]\n",
      "--- tuning end ---\n",
      "target size: 146\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.025453833840794197\n",
      "AUROCperdrug: 0.7823071567280704\n",
      "AUPR+AUROCperdrug: 0.8077609905688646\n",
      "AUPR: 0.02182895961712482\n",
      "AUROC: 0.7754392266655639\n",
      "AUPR+AUROC: 0.7972681862826887\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [139 282 369 438 510 565 660 677 685 727]\n",
      "first few testing idx:  [ 21 107 130 162 285 403 417 418 426 717]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.768383180304475\n",
      "AUROC for each fold: [0.77385004 0.77709651 0.75844229 0.76414387]\n",
      "--- tuning end ---\n",
      "target size: 146\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.023966449790951787\n",
      "AUROCperdrug: 0.8029307455684267\n",
      "AUPR+AUROCperdrug: 0.8268971953593784\n",
      "AUPR: 0.019989603177559007\n",
      "AUROC: 0.7771398843789706\n",
      "AUPR+AUROC: 0.7971294875565297\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [139 282 369 438 510 565 660 677 685 727]\n",
      "first few testing idx:  [ 15  50 113 158 198 272 278 621 627 702]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.7651552470923167\n",
      "AUROC for each fold: [0.77279981 0.76418009 0.76872269 0.7549184 ]\n",
      "--- tuning end ---\n",
      "target size: 146\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.030073729967415478\n",
      "AUROCperdrug: 0.7811216182954341\n",
      "AUPR+AUROCperdrug: 0.8111953482628497\n",
      "AUPR: 0.02585535104307369\n",
      "AUROC: 0.776210110507395\n",
      "AUPR+AUROC: 0.8020654615504687\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.027389910227473908, std: 0.002743074613169965\n",
      "Mean AUROCperdrug: 0.7864856641422149, std: 0.009468911676995616\n",
      "Mean AUPR+AUROCperdrug: 0.8138755743696887, std: 0.0090804068301546\n",
      "Mean AUPR: 0.02350950986796236, std: 0.00257339690392789\n",
      "Mean AUROC: 0.7723126832023588, std: 0.006657065633169392\n",
      "Mean AUPR+AUROC: 0.7958221930703212, std: 0.005216954438594309\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54 197 215 256 332 464 556 668 690]\n",
      "first few testing idx:  [139 144 187 280 446 474 550 560 631 642]\n",
      "--- tuning end ---\n",
      "target size: 147\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.1162260074309881\n",
      "AUROCperdrug: 0.766519318180025\n",
      "AUPR+AUROCperdrug: 0.8827453256110132\n",
      "AUPR: 0.08242163611900725\n",
      "AUROC: 0.7477142737105273\n",
      "AUPR+AUROC: 0.8301359098295346\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [139 144 187 280 446 474 550 560 631 642]\n",
      "first few testing idx:  [ 49  54 197 215 256 332 464 556 668 690]\n",
      "--- tuning end ---\n",
      "target size: 147\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.11447928668176412\n",
      "AUROCperdrug: 0.7422286949263608\n",
      "AUPR+AUROCperdrug: 0.8567079816081249\n",
      "AUPR: 0.08373050127230368\n",
      "AUROC: 0.7338764253702902\n",
      "AUPR+AUROC: 0.8176069266425938\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [139 144 187 280 446 474 550 560 631 642]\n",
      "first few testing idx:  [106 111 227 299 310 334 384 400 489 513]\n",
      "--- tuning end ---\n",
      "target size: 147\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.09359212543778807\n",
      "AUROCperdrug: 0.7614489516048885\n",
      "AUPR+AUROCperdrug: 0.8550410770426765\n",
      "AUPR: 0.07839646237360905\n",
      "AUROC: 0.7271044943411746\n",
      "AUPR+AUROC: 0.8055009567147837\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [139 144 187 280 446 474 550 560 631 642]\n",
      "first few testing idx:  [107 120 130 162 249 417 426 437 585 723]\n",
      "--- tuning end ---\n",
      "target size: 147\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.11497215415180931\n",
      "AUROCperdrug: 0.7661723968098623\n",
      "AUPR+AUROCperdrug: 0.8811445509616715\n",
      "AUPR: 0.084587069255065\n",
      "AUROC: 0.7703246291553009\n",
      "AUPR+AUROC: 0.8549116984103659\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [139 144 187 280 446 474 550 560 631 642]\n",
      "first few testing idx:  [ 15  50 113 158 198 272 278 596 625 708]\n",
      "--- tuning end ---\n",
      "target size: 147\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.12287318102789845\n",
      "AUROCperdrug: 0.7595680450111322\n",
      "AUPR+AUROCperdrug: 0.8824412260390306\n",
      "AUPR: 0.11102850299853587\n",
      "AUROC: 0.7221046679003317\n",
      "AUPR+AUROC: 0.8331331708988675\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.1124285509460496, std: 0.009889361289345604\n",
      "Mean AUROCperdrug: 0.7591874813064537, std: 0.008892742981331057\n",
      "Mean AUPR+AUROCperdrug: 0.8716160322525035, std: 0.012874919605106097\n",
      "Mean AUPR: 0.08803283440370417, std: 0.011692128583359291\n",
      "Mean AUROC: 0.7402248980955248, std: 0.017337101256671747\n",
      "Mean AUPR+AUROC: 0.8282577324992291, std: 0.016547155997113448\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54 197 215 256 332 464 556 668 690]\n",
      "first few testing idx:  [139 144 187 280 446 474 550 560 631 642]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.790331704239828\n",
      "AUROC for each fold: [0.78797873 0.79523032 0.79057454 0.78754323]\n",
      "--- tuning end ---\n",
      "target size: 147\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.040379690598467514\n",
      "AUROCperdrug: 0.8181850378935718\n",
      "AUPR+AUROCperdrug: 0.8585647284920392\n",
      "AUPR: 0.03474051761547728\n",
      "AUROC: 0.810573753984041\n",
      "AUPR+AUROC: 0.8453142715995182\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [139 144 187 280 446 474 550 560 631 642]\n",
      "first few testing idx:  [ 49  54 197 215 256 332 464 556 668 690]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.7979319546404622\n",
      "AUROC for each fold: [0.79216145 0.79773129 0.79990263 0.80193245]\n",
      "--- tuning end ---\n",
      "target size: 147\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.04287224506696695\n",
      "AUROCperdrug: 0.7969481386190883\n",
      "AUPR+AUROCperdrug: 0.8398203836860553\n",
      "AUPR: 0.03830278529538003\n",
      "AUROC: 0.7872403550324883\n",
      "AUPR+AUROC: 0.8255431403278684\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [139 144 187 280 446 474 550 560 631 642]\n",
      "first few testing idx:  [106 111 227 299 310 334 384 400 489 513]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.7937831834788172\n",
      "AUROC for each fold: [0.79002131 0.7953283  0.79515193 0.7946312 ]\n",
      "--- tuning end ---\n",
      "target size: 147\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.03778521853883286\n",
      "AUROCperdrug: 0.8041048176186246\n",
      "AUPR+AUROCperdrug: 0.8418900361574575\n",
      "AUPR: 0.033366591097359774\n",
      "AUROC: 0.8023382343389895\n",
      "AUPR+AUROC: 0.8357048254363493\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [139 144 187 280 446 474 550 560 631 642]\n",
      "first few testing idx:  [107 120 130 162 249 417 426 437 585 723]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.7976448842749609\n",
      "AUROC for each fold: [0.80154722 0.79462993 0.79470418 0.79969821]\n",
      "--- tuning end ---\n",
      "target size: 147\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.0334638245379313\n",
      "AUROCperdrug: 0.8094458498070057\n",
      "AUPR+AUROCperdrug: 0.842909674344937\n",
      "AUPR: 0.029838778631715884\n",
      "AUROC: 0.796531965398729\n",
      "AUPR+AUROC: 0.8263707440304449\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [139 144 187 280 446 474 550 560 631 642]\n",
      "first few testing idx:  [ 15  50 113 158 198 272 278 596 625 708]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.7927330303824931\n",
      "AUROC for each fold: [0.79531957 0.80034465 0.78570048 0.78956743]\n",
      "--- tuning end ---\n",
      "target size: 147\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.03974256567025234\n",
      "AUROCperdrug: 0.8180798463713043\n",
      "AUPR+AUROCperdrug: 0.8578224120415566\n",
      "AUPR: 0.035734463982427876\n",
      "AUROC: 0.8055852951249319\n",
      "AUPR+AUROC: 0.8413197591073598\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.03884870888249019, std: 0.003145146086108146\n",
      "Mean AUROCperdrug: 0.809352738061919, std: 0.008192623094873225\n",
      "Mean AUPR+AUROCperdrug: 0.8482014469444092, std: 0.00822240303734478\n",
      "Mean AUPR: 0.03439662732447217, std: 0.0027928872832439487\n",
      "Mean AUROC: 0.8004539207758359, std: 0.008028358712844384\n",
      "Mean AUPR+AUROC: 0.834850548100308, std: 0.00788168645398046\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54 234 348 414 462 575 645 668 680]\n",
      "first few testing idx:  [104 122 223 255 262 480 542 595 608 627]\n",
      "--- tuning end ---\n",
      "target size: 148\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.14196552421616787\n",
      "AUROCperdrug: 0.7948748646228836\n",
      "AUPR+AUROCperdrug: 0.9368403888390515\n",
      "AUPR: 0.12433009416075233\n",
      "AUROC: 0.7809117128165765\n",
      "AUPR+AUROC: 0.9052418069773288\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [104 122 223 255 262 480 542 595 608 627]\n",
      "first few testing idx:  [ 49  54 234 348 414 462 575 645 668 680]\n",
      "--- tuning end ---\n",
      "target size: 148\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.1303876905025373\n",
      "AUROCperdrug: 0.7787800306274664\n",
      "AUPR+AUROCperdrug: 0.9091677211300037\n",
      "AUPR: 0.09805623164806378\n",
      "AUROC: 0.7633872931816408\n",
      "AUPR+AUROC: 0.8614435248297045\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [104 122 223 255 262 480 542 595 608 627]\n",
      "first few testing idx:  [106 111 227 301 469 495 629 642 665 735]\n",
      "--- tuning end ---\n",
      "target size: 148\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.11514888701238342\n",
      "AUROCperdrug: 0.7820800139183198\n",
      "AUPR+AUROCperdrug: 0.8972289009307033\n",
      "AUPR: 0.11690099831940945\n",
      "AUROC: 0.7590554516183747\n",
      "AUPR+AUROC: 0.8759564499377842\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [104 122 223 255 262 480 542 595 608 627]\n",
      "first few testing idx:  [107 120 130 249 307 417 426 437 544 648]\n",
      "--- tuning end ---\n",
      "target size: 148\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.10789265658976599\n",
      "AUROCperdrug: 0.7679907662790908\n",
      "AUPR+AUROCperdrug: 0.8758834228688568\n",
      "AUPR: 0.08627760137563731\n",
      "AUROC: 0.7439037529979013\n",
      "AUPR+AUROC: 0.8301813543735387\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [104 122 223 255 262 480 542 595 608 627]\n",
      "first few testing idx:  [ 15  50 113 158 198 272 507 599 628 712]\n",
      "--- tuning end ---\n",
      "target size: 148\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.15434869721622557\n",
      "AUROCperdrug: 0.8001123200643234\n",
      "AUPR+AUROCperdrug: 0.954461017280549\n",
      "AUPR: 0.13708183256312953\n",
      "AUROC: 0.7639652040981201\n",
      "AUPR+AUROC: 0.9010470366612496\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.12994869110741603, std: 0.0170027065871147\n",
      "Mean AUROCperdrug: 0.7847675991024168, std: 0.011507853732523889\n",
      "Mean AUPR+AUROCperdrug: 0.9147162902098328, std: 0.027977512607937145\n",
      "Mean AUPR: 0.1125293516133985, std: 0.018219872296230694\n",
      "Mean AUROC: 0.7622446829425227, std: 0.0118261123214406\n",
      "Mean AUPR+AUROC: 0.8747740345559212, std: 0.02751786153571368\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54 234 348 414 462 575 645 668 680]\n",
      "first few testing idx:  [104 122 223 255 262 480 542 595 608 627]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8172350108032481\n",
      "AUROC for each fold: [0.81197722 0.8168528  0.8297762  0.81033382]\n",
      "--- tuning end ---\n",
      "target size: 148\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.049944513599165505\n",
      "AUROCperdrug: 0.8270882976438105\n",
      "AUPR+AUROCperdrug: 0.877032811242976\n",
      "AUPR: 0.045326440725944106\n",
      "AUROC: 0.8267860549212714\n",
      "AUPR+AUROC: 0.8721124956472155\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [104 122 223 255 262 480 542 595 608 627]\n",
      "first few testing idx:  [ 49  54 234 348 414 462 575 645 668 680]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8215814694472555\n",
      "AUROC for each fold: [0.82187617 0.8237766  0.83362896 0.80704415]\n",
      "--- tuning end ---\n",
      "target size: 148\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.045974654725346495\n",
      "AUROCperdrug: 0.8285183710108249\n",
      "AUPR+AUROCperdrug: 0.8744930257361714\n",
      "AUPR: 0.04011681680874227\n",
      "AUROC: 0.8092477675320607\n",
      "AUPR+AUROC: 0.849364584340803\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [104 122 223 255 262 480 542 595 608 627]\n",
      "first few testing idx:  [106 111 227 301 469 495 629 642 665 735]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8138932937018231\n",
      "AUROC for each fold: [0.80745156 0.82178628 0.82081713 0.8055182 ]\n",
      "--- tuning end ---\n",
      "target size: 148\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.06040274849439911\n",
      "AUROCperdrug: 0.8265810972682516\n",
      "AUPR+AUROCperdrug: 0.8869838457626507\n",
      "AUPR: 0.05287649727077295\n",
      "AUROC: 0.8292054789611968\n",
      "AUPR+AUROC: 0.8820819762319697\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [104 122 223 255 262 480 542 595 608 627]\n",
      "first few testing idx:  [107 120 130 249 307 417 426 437 544 648]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8158508974698162\n",
      "AUROC for each fold: [0.80475821 0.81551853 0.82509597 0.81803088]\n",
      "--- tuning end ---\n",
      "target size: 148\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.05078410002995678\n",
      "AUROCperdrug: 0.8298268016835351\n",
      "AUPR+AUROCperdrug: 0.8806109017134919\n",
      "AUPR: 0.04604473523764616\n",
      "AUROC: 0.8243463683185037\n",
      "AUPR+AUROC: 0.8703911035561499\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [104 122 223 255 262 480 542 595 608 627]\n",
      "first few testing idx:  [ 15  50 113 158 198 272 507 599 628 712]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.818061069563994\n",
      "AUROC for each fold: [0.80522839 0.81470539 0.82068829 0.83162221]\n",
      "--- tuning end ---\n",
      "target size: 148\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.05846350199793348\n",
      "AUROCperdrug: 0.8461153030558378\n",
      "AUPR+AUROCperdrug: 0.9045788050537713\n",
      "AUPR: 0.053156793116105154\n",
      "AUROC: 0.8201628341004005\n",
      "AUPR+AUROC: 0.8733196272165056\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.053113903769360274, std: 0.005444030768840262\n",
      "Mean AUROCperdrug: 0.8316259741324519, std: 0.007333159780109353\n",
      "Mean AUPR+AUROCperdrug: 0.8847398779018123, std: 0.010770921246143936\n",
      "Mean AUPR: 0.04750425663184213, std: 0.004944886048202209\n",
      "Mean AUROC: 0.8219497007666865, std: 0.007018727155979354\n",
      "Mean AUPR+AUROC: 0.8694539573985288, std: 0.01082533363173911\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 54 234 348 414 462 575 645 656 682 700]\n",
      "first few testing idx:  [104 122 223 255 262 480 542 595 608 627]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.1308384184428799\n",
      "AUROCperdrug: 0.8059775797349401\n",
      "AUPR+AUROCperdrug: 0.93681599817782\n",
      "AUPR: 0.11902497109049931\n",
      "AUROC: 0.7885044368801655\n",
      "AUPR+AUROC: 0.9075294079706648\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [104 122 223 255 262 480 542 595 608 627]\n",
      "first few testing idx:  [ 54 234 348 414 462 575 645 656 682 700]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.12238562202810715\n",
      "AUROCperdrug: 0.7922528307447193\n",
      "AUPR+AUROCperdrug: 0.9146384527728264\n",
      "AUPR: 0.10777420315789099\n",
      "AUROC: 0.7831371745256026\n",
      "AUPR+AUROC: 0.8909113776834936\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [104 122 223 255 262 480 542 595 608 627]\n",
      "first few testing idx:  [106 111 227 301 469 495 570 629 642 672]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.14616242731566628\n",
      "AUROCperdrug: 0.8116191041606183\n",
      "AUPR+AUROCperdrug: 0.9577815314762846\n",
      "AUPR: 0.11400172544860145\n",
      "AUROC: 0.7867244631953804\n",
      "AUPR+AUROC: 0.9007261886439818\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [104 122 223 255 262 480 542 595 608 627]\n",
      "first few testing idx:  [107 130 162 249 285 417 426 437 544 744]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.14345236502354802\n",
      "AUROCperdrug: 0.7946329015212783\n",
      "AUPR+AUROCperdrug: 0.9380852665448263\n",
      "AUPR: 0.11598898689956907\n",
      "AUROC: 0.7730288748717846\n",
      "AUPR+AUROC: 0.8890178617713537\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [104 122 223 255 262 480 542 595 608 627]\n",
      "first few testing idx:  [ 50 113 119 238 272 457 505 507 628 714]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.13905130804231136\n",
      "AUROCperdrug: 0.8035382603103044\n",
      "AUPR+AUROCperdrug: 0.9425895683526158\n",
      "AUPR: 0.1398053681876495\n",
      "AUROC: 0.7512745151478469\n",
      "AUPR+AUROC: 0.8910798833354965\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.13637802817050254, std: 0.008710933812208332\n",
      "Mean AUROCperdrug: 0.8016041352943721, std: 0.007200172974913204\n",
      "Mean AUPR+AUROCperdrug: 0.9379821634648746, std: 0.013853104735377555\n",
      "Mean AUPR: 0.11931905095684207, std: 0.010885058240874403\n",
      "Mean AUROC: 0.7765338929241561, std: 0.01371908371690519\n",
      "Mean AUPR+AUROC: 0.8958529438809981, std: 0.00712752213687407\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 54 234 348 414 462 575 645 656 682 700]\n",
      "first few testing idx:  [104 122 223 255 262 480 542 595 608 627]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8338551721674907\n",
      "AUROC for each fold: [0.83613799 0.82348678 0.84151007 0.83428585]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.06124055825523297\n",
      "AUROCperdrug: 0.8358031299395206\n",
      "AUPR+AUROCperdrug: 0.8970436881947536\n",
      "AUPR: 0.053968593505874005\n",
      "AUROC: 0.8250272777553198\n",
      "AUPR+AUROC: 0.8789958712611938\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [104 122 223 255 262 480 542 595 608 627]\n",
      "first few testing idx:  [ 54 234 348 414 462 575 645 656 682 700]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8311181320799117\n",
      "AUROC for each fold: [0.82671187 0.82343763 0.83835754 0.83596549]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.057932196299435926\n",
      "AUROCperdrug: 0.8408477500734108\n",
      "AUPR+AUROCperdrug: 0.8987799463728467\n",
      "AUPR: 0.05150759110515444\n",
      "AUROC: 0.8384718349300977\n",
      "AUPR+AUROC: 0.8899794260352522\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [104 122 223 255 262 480 542 595 608 627]\n",
      "first few testing idx:  [106 111 227 301 469 495 570 629 642 672]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8301607534663786\n",
      "AUROC for each fold: [0.82585598 0.82346357 0.84163613 0.82968733]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.06848322744235132\n",
      "AUROCperdrug: 0.8454095163394776\n",
      "AUPR+AUROCperdrug: 0.9138927437818289\n",
      "AUPR: 0.061116257324505596\n",
      "AUROC: 0.8400224461125656\n",
      "AUPR+AUROC: 0.9011387034370713\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [104 122 223 255 262 480 542 595 608 627]\n",
      "first few testing idx:  [107 130 162 249 285 417 426 437 544 744]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.830931406952466\n",
      "AUROC for each fold: [0.82587575 0.82460255 0.84511119 0.82813614]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.06483454889311749\n",
      "AUROCperdrug: 0.8423991035101238\n",
      "AUPR+AUROCperdrug: 0.9072336524032413\n",
      "AUPR: 0.058822402472224915\n",
      "AUROC: 0.8371289606817138\n",
      "AUPR+AUROC: 0.8959513631539388\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [104 122 223 255 262 480 542 595 608 627]\n",
      "first few testing idx:  [ 50 113 119 238 272 457 505 507 628 714]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8313206616710038\n",
      "AUROC for each fold: [0.82658287 0.83391094 0.83806908 0.82671976]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.07109607135664715\n",
      "AUROCperdrug: 0.8519823979370658\n",
      "AUPR+AUROCperdrug: 0.923078469293713\n",
      "AUPR: 0.06423080536910965\n",
      "AUROC: 0.8286697102317365\n",
      "AUPR+AUROC: 0.8929005156008462\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.06471732044935698, std: 0.0047541570485102255\n",
      "Mean AUROCperdrug: 0.8432883795599198, std: 0.0053453086504446\n",
      "Mean AUPR+AUROCperdrug: 0.9080057000092767, std: 0.009671834872139016\n",
      "Mean AUPR: 0.05792912995537373, std: 0.004638724821525985\n",
      "Mean AUROC: 0.8338640459422866, std: 0.005914167324878438\n",
      "Mean AUPR+AUROC: 0.8917931758976604, std: 0.007388048483711089\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54 234 248 255 370 476 593 604 641]\n",
      "first few testing idx:  [139 254 282 342 375 598 607 632 686 726]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.1329240952215936\n",
      "AUROCperdrug: 0.805466939679875\n",
      "AUPR+AUROCperdrug: 0.9383910349014686\n",
      "AUPR: 0.10117520108581315\n",
      "AUROC: 0.7831796373751384\n",
      "AUPR+AUROC: 0.8843548384609515\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [139 254 282 342 375 598 607 632 686 726]\n",
      "first few testing idx:  [ 49  54 234 248 255 370 476 593 604 641]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.15899980040530395\n",
      "AUROCperdrug: 0.8166476903618931\n",
      "AUPR+AUROCperdrug: 0.975647490767197\n",
      "AUPR: 0.1492279499114063\n",
      "AUROC: 0.80882661866558\n",
      "AUPR+AUROC: 0.9580545685769863\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [139 254 282 342 375 598 607 632 686 726]\n",
      "first few testing idx:  [106 111 220 227 303 392 466 467 499 562]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.12993190007783081\n",
      "AUROCperdrug: 0.811910955894748\n",
      "AUPR+AUROCperdrug: 0.9418428559725789\n",
      "AUPR: 0.10113145295947776\n",
      "AUROC: 0.7758913269390864\n",
      "AUPR+AUROC: 0.8770227798985641\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [139 254 282 342 375 598 607 632 686 726]\n",
      "first few testing idx:  [107 120 130 249 307 417 426 437 547 651]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.16652700964383746\n",
      "AUROCperdrug: 0.8310577610292561\n",
      "AUPR+AUROCperdrug: 0.9975847706730936\n",
      "AUPR: 0.15872275116851664\n",
      "AUROC: 0.7914998746653671\n",
      "AUPR+AUROC: 0.9502226258338837\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [139 254 282 342 375 598 607 632 686 726]\n",
      "first few testing idx:  [ 15  50 113 119 158 272 507 602 631 717]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.1434769390847635\n",
      "AUROCperdrug: 0.8250911821169462\n",
      "AUPR+AUROCperdrug: 0.9685681212017097\n",
      "AUPR: 0.15905850629279872\n",
      "AUROC: 0.7929855711543629\n",
      "AUPR+AUROC: 0.9520440774471616\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.14637194888666588, std: 0.014319149156910379\n",
      "Mean AUROCperdrug: 0.8180349058165437, std: 0.00912980498470395\n",
      "Mean AUPR+AUROCperdrug: 0.9644068547032095, std: 0.02204721780530052\n",
      "Mean AUPR: 0.1338631722836025, std: 0.026939743208363648\n",
      "Mean AUROC: 0.790476605759907, std: 0.011045732806212695\n",
      "Mean AUPR+AUROC: 0.9243397780435094, std: 0.035810140526874985\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54 234 248 255 370 476 593 604 641]\n",
      "first few testing idx:  [139 254 282 342 375 598 607 632 686 726]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8449781893369338\n",
      "AUROC for each fold: [0.8404085  0.84613179 0.85541007 0.8379624 ]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.07584775021502636\n",
      "AUROCperdrug: 0.8479795666953818\n",
      "AUPR+AUROCperdrug: 0.9238273169104081\n",
      "AUPR: 0.0685763675459302\n",
      "AUROC: 0.8448538595550066\n",
      "AUPR+AUROC: 0.9134302271009368\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [139 254 282 342 375 598 607 632 686 726]\n",
      "first few testing idx:  [ 49  54 234 248 255 370 476 593 604 641]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.843120040930059\n",
      "AUROC for each fold: [0.83226672 0.84935622 0.85300174 0.83785548]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.08457964413059853\n",
      "AUROCperdrug: 0.8624763480088381\n",
      "AUPR+AUROCperdrug: 0.9470559921394366\n",
      "AUPR: 0.07837480308798417\n",
      "AUROC: 0.8529908507330948\n",
      "AUPR+AUROC: 0.9313656538210789\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [139 254 282 342 375 598 607 632 686 726]\n",
      "first few testing idx:  [106 111 220 227 303 392 466 467 499 562]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8458154365983394\n",
      "AUROC for each fold: [0.8320975  0.85616641 0.84893156 0.84606629]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.0766805004717181\n",
      "AUROCperdrug: 0.84906803178674\n",
      "AUPR+AUROCperdrug: 0.925748532258458\n",
      "AUPR: 0.06743660246347216\n",
      "AUROC: 0.839964135763861\n",
      "AUPR+AUROC: 0.9074007382273331\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [139 254 282 342 375 598 607 632 686 726]\n",
      "first few testing idx:  [107 120 130 249 307 417 426 437 547 651]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8434238396828966\n",
      "AUROC for each fold: [0.83380146 0.85423452 0.84687981 0.83877957]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.07921468042683058\n",
      "AUROCperdrug: 0.8620626704836751\n",
      "AUPR+AUROCperdrug: 0.9412773509105057\n",
      "AUPR: 0.07013020809978207\n",
      "AUROC: 0.8483167365153121\n",
      "AUPR+AUROC: 0.9184469446150942\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [139 254 282 342 375 598 607 632 686 726]\n",
      "first few testing idx:  [ 15  50 113 119 158 272 507 602 631 717]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8442057221909675\n",
      "AUROC for each fold: [0.83747576 0.85453766 0.84362198 0.84118749]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.07424626048442709\n",
      "AUROCperdrug: 0.8558271246225951\n",
      "AUPR+AUROCperdrug: 0.9300733851070222\n",
      "AUPR: 0.06646833596450623\n",
      "AUROC: 0.843144128247655\n",
      "AUPR+AUROC: 0.9096124642121611\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.07811376714572013, std: 0.0036101598053340303\n",
      "Mean AUROCperdrug: 0.855482748319446, std: 0.006160693630097461\n",
      "Mean AUPR+AUROCperdrug: 0.933596515465166, std: 0.009050892484381304\n",
      "Mean AUPR: 0.07019726343233498, std: 0.004266851386144896\n",
      "Mean AUROC: 0.8458539421629858, std: 0.004472893829672697\n",
      "Mean AUPR+AUROC: 0.9160512055953209, std: 0.008525601380103897\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54 117 203 235 256 267 365 452 748]\n",
      "first few testing idx:  [138 147 151 261 339 376 468 538 710 726]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.12678978706922964\n",
      "AUROCperdrug: 0.8002754009668857\n",
      "AUPR+AUROCperdrug: 0.9270651880361153\n",
      "AUPR: 0.1147124862721639\n",
      "AUROC: 0.7771053858875183\n",
      "AUPR+AUROC: 0.8918178721596822\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [138 147 151 261 339 376 468 538 710 726]\n",
      "first few testing idx:  [ 49  54 117 203 235 256 267 365 452 748]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.15522180179654832\n",
      "AUROCperdrug: 0.8363997559610157\n",
      "AUPR+AUROCperdrug: 0.991621557757564\n",
      "AUPR: 0.14585049643542425\n",
      "AUROC: 0.8246149310114504\n",
      "AUPR+AUROC: 0.9704654274468747\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [138 147 151 261 339 376 468 538 710 726]\n",
      "first few testing idx:  [  5 106 111 220 227 305 446 463 501 667]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.14883148410445768\n",
      "AUROCperdrug: 0.8222415888564972\n",
      "AUPR+AUROCperdrug: 0.9710730729609549\n",
      "AUPR: 0.13387678166257835\n",
      "AUROC: 0.772554176379459\n",
      "AUPR+AUROC: 0.9064309580420373\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [138 147 151 261 339 376 468 538 710 726]\n",
      "first few testing idx:  [ 42 120 130 249 276 307 417 437 548 652]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.17731968223208452\n",
      "AUROCperdrug: 0.844834622915614\n",
      "AUPR+AUROCperdrug: 1.0221543051476984\n",
      "AUPR: 0.14326519892755257\n",
      "AUROC: 0.8238414438446906\n",
      "AUPR+AUROC: 0.9671066427722432\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [138 147 151 261 339 376 468 538 710 726]\n",
      "first few testing idx:  [ 15  50 113 158 198 272 507 614 632 718]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.15911358250613675\n",
      "AUROCperdrug: 0.8288379205914082\n",
      "AUPR+AUROCperdrug: 0.9879515030975449\n",
      "AUPR: 0.17325055866787104\n",
      "AUROC: 0.8006081280155251\n",
      "AUPR+AUROC: 0.973858686683396\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.15345526754169136, std: 0.016352826557676056\n",
      "Mean AUROCperdrug: 0.8265178578582841, std: 0.015135993549393248\n",
      "Mean AUPR+AUROCperdrug: 0.9799731253999756, std: 0.031167461178285196\n",
      "Mean AUPR: 0.14219110439311802, std: 0.01899177161477289\n",
      "Mean AUROC: 0.7997448130277286, std: 0.022144028904408853\n",
      "Mean AUPR+AUROC: 0.9419359174208466, std: 0.035324162143557394\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54 117 203 235 256 267 365 452 748]\n",
      "first few testing idx:  [138 147 151 261 339 376 468 538 710 726]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8534699875348315\n",
      "AUROC for each fold: [0.86150361 0.84110585 0.85544023 0.85583026]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.08502979346633956\n",
      "AUROCperdrug: 0.8460786646501454\n",
      "AUPR+AUROCperdrug: 0.9311084581164849\n",
      "AUPR: 0.07876828671675064\n",
      "AUROC: 0.8427407213211493\n",
      "AUPR+AUROC: 0.9215090080378999\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [138 147 151 261 339 376 468 538 710 726]\n",
      "first few testing idx:  [ 49  54 117 203 235 256 267 365 452 748]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8478169159993222\n",
      "AUROC for each fold: [0.85577943 0.83155269 0.85085015 0.85308539]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.08647941474629253\n",
      "AUROCperdrug: 0.8676460781077101\n",
      "AUPR+AUROCperdrug: 0.9541254928540026\n",
      "AUPR: 0.08013210940209847\n",
      "AUROC: 0.8683571431524717\n",
      "AUPR+AUROC: 0.9484892525545702\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [138 147 151 261 339 376 468 538 710 726]\n",
      "first few testing idx:  [  5 106 111 220 227 305 446 463 501 667]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8514801647849154\n",
      "AUROC for each fold: [0.85211894 0.84635625 0.85683999 0.85060547]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.09532175522200255\n",
      "AUROCperdrug: 0.8589633719693177\n",
      "AUPR+AUROCperdrug: 0.9542851271913203\n",
      "AUPR: 0.0858597395544702\n",
      "AUROC: 0.8486321848007714\n",
      "AUPR+AUROC: 0.9344919243552416\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [138 147 151 261 339 376 468 538 710 726]\n",
      "first few testing idx:  [ 42 120 130 249 276 307 417 437 548 652]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8487973442729899\n",
      "AUROC for each fold: [0.85536212 0.84062342 0.85554681 0.84365703]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.08687105491069425\n",
      "AUROCperdrug: 0.8707712375638244\n",
      "AUPR+AUROCperdrug: 0.9576422924745186\n",
      "AUPR: 0.07900842959418904\n",
      "AUROC: 0.8575918450619793\n",
      "AUPR+AUROC: 0.9366002746561684\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [138 147 151 261 339 376 468 538 710 726]\n",
      "first few testing idx:  [ 15  50 113 158 198 272 507 614 632 718]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8521403748306751\n",
      "AUROC for each fold: [0.85423021 0.84380251 0.85817003 0.85235875]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.08093828937196963\n",
      "AUROCperdrug: 0.8603246291306379\n",
      "AUPR+AUROCperdrug: 0.9412629185026076\n",
      "AUPR: 0.07298078733785761\n",
      "AUROC: 0.8481462374912745\n",
      "AUPR+AUROC: 0.9211270248291321\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.0869280615434597, std: 0.004693387255127539\n",
      "Mean AUROCperdrug: 0.860756796284327, std: 0.008562732340500378\n",
      "Mean AUPR+AUROCperdrug: 0.9476848578277869, std: 0.010002141491112638\n",
      "Mean AUPR: 0.07934987052107319, std: 0.004099032440020212\n",
      "Mean AUROC: 0.8530936263655292, std: 0.00899747382894958\n",
      "Mean AUPR+AUROC: 0.9324434968866024, std: 0.010262228975089749\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54 117 203 235 256 267 365 452 748]\n",
      "first few testing idx:  [138 147 151 261 339 376 468 538 710 726]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.13932462568653692\n",
      "AUROCperdrug: 0.8102667146895303\n",
      "AUPR+AUROCperdrug: 0.9495913403760672\n",
      "AUPR: 0.12507744496531664\n",
      "AUROC: 0.7860722516253964\n",
      "AUPR+AUROC: 0.9111496965907131\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [138 147 151 261 339 376 468 538 710 726]\n",
      "first few testing idx:  [ 49  54 117 203 235 256 267 365 452 748]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.16337098427416005\n",
      "AUROCperdrug: 0.8427046613772182\n",
      "AUPR+AUROCperdrug: 1.0060756456513782\n",
      "AUPR: 0.15431514280096348\n",
      "AUROC: 0.8317100494004\n",
      "AUPR+AUROC: 0.9860251922013635\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [138 147 151 261 339 376 468 538 710 726]\n",
      "first few testing idx:  [  5 106 111 220 227 305 446 463 501 667]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.16184569117992056\n",
      "AUROCperdrug: 0.8300801010500207\n",
      "AUPR+AUROCperdrug: 0.9919257922299413\n",
      "AUPR: 0.1473784249077965\n",
      "AUROC: 0.782891906918587\n",
      "AUPR+AUROC: 0.9302703318263835\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [138 147 151 261 339 376 468 538 710 726]\n",
      "first few testing idx:  [ 42 120 130 249 276 307 417 437 548 652]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.18716949831731136\n",
      "AUROCperdrug: 0.8526122606700964\n",
      "AUPR+AUROCperdrug: 1.0397817589874079\n",
      "AUPR: 0.15425550632363133\n",
      "AUROC: 0.8323552320866001\n",
      "AUPR+AUROC: 0.9866107384102314\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [138 147 151 261 339 376 468 538 710 726]\n",
      "first few testing idx:  [ 15  50 113 158 198 272 507 614 632 718]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.16535084266819014\n",
      "AUROCperdrug: 0.8350616609288215\n",
      "AUPR+AUROCperdrug: 1.0004125035970117\n",
      "AUPR: 0.1829041234296993\n",
      "AUROC: 0.8084097675955799\n",
      "AUPR+AUROC: 0.9913138910252792\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.1634123284252238, std: 0.015171252048372521\n",
      "Mean AUROCperdrug: 0.8341450797431375, std: 0.014155166545246315\n",
      "Mean AUPR+AUROCperdrug: 0.9975574081683612, std: 0.028969178446571504\n",
      "Mean AUPR: 0.15278612848548145, std: 0.018485697043243387\n",
      "Mean AUROC: 0.8082878415253127, std: 0.02129009114724647\n",
      "Mean AUPR+AUROC: 0.9610739700107942, std: 0.0335572348502407\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54 117 203 235 256 267 365 452 748]\n",
      "first few testing idx:  [138 147 151 261 339 376 468 538 710 726]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8596024284288605\n",
      "AUROC for each fold: [0.86739563 0.84748223 0.86131035 0.86222151]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.09763714579385584\n",
      "AUROCperdrug: 0.8528581374259704\n",
      "AUPR+AUROCperdrug: 0.9504952832198262\n",
      "AUPR: 0.08893922760565864\n",
      "AUROC: 0.8488176970601404\n",
      "AUPR+AUROC: 0.9377569246657991\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [138 147 151 261 339 376 468 538 710 726]\n",
      "first few testing idx:  [ 49  54 117 203 235 256 267 365 452 748]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8541673063227715\n",
      "AUROC for each fold: [0.86180106 0.83830696 0.85681138 0.85974982]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.09629700239899379\n",
      "AUROCperdrug: 0.8717701581811791\n",
      "AUPR+AUROCperdrug: 0.9680671605801728\n",
      "AUPR: 0.08821740719833751\n",
      "AUROC: 0.8733849960734331\n",
      "AUPR+AUROC: 0.9616024032717706\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [138 147 151 261 339 376 468 538 710 726]\n",
      "first few testing idx:  [  5 106 111 220 227 305 446 463 501 667]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.857525884438114\n",
      "AUROC for each fold: [0.85813307 0.8525952  0.86245233 0.85692294]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.10863939919732797\n",
      "AUROCperdrug: 0.8646574280312522\n",
      "AUPR+AUROCperdrug: 0.9732968272285802\n",
      "AUPR: 0.09800499908090594\n",
      "AUROC: 0.8551505481772066\n",
      "AUPR+AUROC: 0.9531555472581126\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [138 147 151 261 339 376 468 538 710 726]\n",
      "first few testing idx:  [ 42 120 130 249 276 307 417 437 548 652]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8549084164912735\n",
      "AUROC for each fold: [0.86101084 0.84696672 0.8613922  0.85026391]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.10120992789690968\n",
      "AUROCperdrug: 0.8759833541329912\n",
      "AUPR+AUROCperdrug: 0.9771932820299009\n",
      "AUPR: 0.09104655236224836\n",
      "AUROC: 0.8639863247646609\n",
      "AUPR+AUROC: 0.9550328771269092\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [138 147 151 261 339 376 468 538 710 726]\n",
      "first few testing idx:  [ 15  50 113 158 198 272 507 614 632 718]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8583208285418682\n",
      "AUROC for each fold: [0.85979073 0.85025627 0.86438584 0.85885047]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.09142713925171553\n",
      "AUROCperdrug: 0.866027912635411\n",
      "AUPR+AUROCperdrug: 0.9574550518871265\n",
      "AUPR: 0.08230823682314158\n",
      "AUROC: 0.8540947778926744\n",
      "AUPR+AUROC: 0.936403014715816\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.09904212290776057, std: 0.005732446493938754\n",
      "Mean AUROCperdrug: 0.8662593980813608, std: 0.007837569506915212\n",
      "Mean AUPR+AUROCperdrug: 0.9653015209891214, std: 0.009937599499987744\n",
      "Mean AUPR: 0.08970328461405841, std: 0.00506361882390393\n",
      "Mean AUROC: 0.8590868687936231, std: 0.008652312895083081\n",
      "Mean AUPR+AUROC: 0.9487901534076816, std: 0.00997351844562442\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54 117 203 235 256 267 365 452 748]\n",
      "first few testing idx:  [138 147 151 261 339 376 468 538 710 726]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.1489923728945445\n",
      "AUROCperdrug: 0.8174739544224268\n",
      "AUPR+AUROCperdrug: 0.9664663273169712\n",
      "AUPR: 0.1371702379340821\n",
      "AUROC: 0.7947842446595073\n",
      "AUPR+AUROC: 0.9319544825935894\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [138 147 151 261 339 376 468 538 710 726]\n",
      "first few testing idx:  [ 49  54 117 203 235 256 267 365 452 748]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.17331423166475876\n",
      "AUROCperdrug: 0.850065546696758\n",
      "AUPR+AUROCperdrug: 1.0233797783615168\n",
      "AUPR: 0.16554744136720628\n",
      "AUROC: 0.8390962149795794\n",
      "AUPR+AUROC: 1.0046436563467858\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [138 147 151 261 339 376 468 538 710 726]\n",
      "first few testing idx:  [  5 106 111 220 227 305 446 463 501 667]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.17495309921197097\n",
      "AUROCperdrug: 0.8378621890183033\n",
      "AUPR+AUROCperdrug: 1.0128152882302743\n",
      "AUPR: 0.16112916843826852\n",
      "AUROC: 0.7922448174067449\n",
      "AUPR+AUROC: 0.9533739858450134\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [138 147 151 261 339 376 468 538 710 726]\n",
      "first few testing idx:  [ 42 120 130 249 276 307 417 437 548 652]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.19966078511228358\n",
      "AUROCperdrug: 0.8592417689390301\n",
      "AUPR+AUROCperdrug: 1.0589025540513137\n",
      "AUPR: 0.1660235418385448\n",
      "AUROC: 0.8402256534132677\n",
      "AUPR+AUROC: 1.0062491952518124\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [138 147 151 261 339 376 468 538 710 726]\n",
      "first few testing idx:  [ 15  50 113 158 198 272 507 614 632 718]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.1724460685471709\n",
      "AUROCperdrug: 0.8405382022094433\n",
      "AUPR+AUROCperdrug: 1.0129842707566141\n",
      "AUPR: 0.19628325077344372\n",
      "AUROC: 0.8160353555070957\n",
      "AUPR+AUROC: 1.0123186062805394\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.17387331148614577, std: 0.01604724546708353\n",
      "Mean AUROCperdrug: 0.8410363322571923, std: 0.013989092938756071\n",
      "Mean AUPR+AUROCperdrug: 1.014909643743338, std: 0.02953630860603224\n",
      "Mean AUPR: 0.16523072807030909, std: 0.01881064552487609\n",
      "Mean AUROC: 0.816477257193239, std: 0.020657186557024868\n",
      "Mean AUPR+AUROC: 0.981707985263548, std: 0.03269113844989658\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54 117 203 235 256 267 365 452 748]\n",
      "first few testing idx:  [138 147 151 261 339 376 468 538 710 726]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8653903082881061\n",
      "AUROC for each fold: [0.87279543 0.85422932 0.86644719 0.8680893 ]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.10664979229103815\n",
      "AUROCperdrug: 0.8587834005926442\n",
      "AUPR+AUROCperdrug: 0.9654331928836823\n",
      "AUPR: 0.09867711933812566\n",
      "AUROC: 0.8548360632132637\n",
      "AUPR+AUROC: 0.9535131825513893\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [138 147 151 261 339 376 468 538 710 726]\n",
      "first few testing idx:  [ 49  54 117 203 235 256 267 365 452 748]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8601637104170956\n",
      "AUROC for each fold: [0.86758375 0.84508823 0.8617922  0.86619066]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.1060536383781095\n",
      "AUROCperdrug: 0.8777469626226009\n",
      "AUPR+AUROCperdrug: 0.9838006010007103\n",
      "AUPR: 0.09833072701080997\n",
      "AUROC: 0.8783895401242624\n",
      "AUPR+AUROC: 0.9767202671350723\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [138 147 151 261 339 376 468 538 710 726]\n",
      "first few testing idx:  [  5 106 111 220 227 305 446 463 501 667]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8633801508943693\n",
      "AUROC for each fold: [0.86402551 0.85891266 0.86759861 0.86298382]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.11849481884447814\n",
      "AUROCperdrug: 0.8710073672575961\n",
      "AUPR+AUROCperdrug: 0.9895021861020742\n",
      "AUPR: 0.10913723884929243\n",
      "AUROC: 0.8610375854070833\n",
      "AUPR+AUROC: 0.9701748242563757\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [138 147 151 261 339 376 468 538 710 726]\n",
      "first few testing idx:  [ 42 120 130 249 276 307 417 437 548 652]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8607306309396656\n",
      "AUROC for each fold: [0.86636293 0.85313251 0.86685422 0.85657287]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.11242057377159088\n",
      "AUROCperdrug: 0.8819274104479902\n",
      "AUPR+AUROCperdrug: 0.994347984219581\n",
      "AUPR: 0.1027583698247396\n",
      "AUROC: 0.8701109397223155\n",
      "AUPR+AUROC: 0.9728693095470551\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [138 147 151 261 339 376 468 538 710 726]\n",
      "first few testing idx:  [ 15  50 113 158 198 272 507 614 632 718]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8642574230466631\n",
      "AUROC for each fold: [0.86530646 0.85666495 0.86990589 0.86515238]\n",
      "--- tuning end ---\n",
      "target size: 149\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.10145056694105747\n",
      "AUROCperdrug: 0.8700922604449807\n",
      "AUPR+AUROCperdrug: 0.9715428273860381\n",
      "AUPR: 0.09266746924516352\n",
      "AUROC: 0.8595538444822968\n",
      "AUPR+AUROC: 0.9522213137274603\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.10901387804525484, std: 0.005883016393132345\n",
      "Mean AUROCperdrug: 0.8719114802731625, std: 0.007884734221821723\n",
      "Mean AUPR+AUROCperdrug: 0.9809253583184173, std: 0.0108631023004428\n",
      "Mean AUPR: 0.10031418485362624, std: 0.005457227686223755\n",
      "Mean AUROC: 0.8647855945898444, std: 0.008412355098529726\n",
      "Mean AUPR+AUROC: 0.9650997794434707, std: 0.01021040174343995\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.18138844582232075\n",
      "AUROCperdrug: 0.8464348266155869\n",
      "AUPR+AUROCperdrug: 1.0278232724379077\n",
      "AUPR: 0.14765954940524673\n",
      "AUROC: 0.8324103676459955\n",
      "AUPR+AUROC: 0.9800699170512422\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.18055833796889284\n",
      "AUROCperdrug: 0.8516649917757371\n",
      "AUPR+AUROCperdrug: 1.03222332974463\n",
      "AUPR: 0.15798798278915888\n",
      "AUROC: 0.8228544925200941\n",
      "AUPR+AUROC: 0.9808424753092531\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.1923809670491456\n",
      "AUROCperdrug: 0.8554646736315316\n",
      "AUPR+AUROCperdrug: 1.047845640680677\n",
      "AUPR: 0.20612997117047765\n",
      "AUROC: 0.840304440925002\n",
      "AUPR+AUROC: 1.0464344120954796\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.18624342870943902\n",
      "AUROCperdrug: 0.8390775511206762\n",
      "AUPR+AUROCperdrug: 1.0253209798301153\n",
      "AUPR: 0.17516022484739024\n",
      "AUROC: 0.8061541835461287\n",
      "AUPR+AUROC: 0.9813144083935189\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.19375548709310622\n",
      "AUROCperdrug: 0.8357104221111183\n",
      "AUPR+AUROCperdrug: 1.0294659092042246\n",
      "AUPR: 0.1932460974093373\n",
      "AUROC: 0.8032897518982848\n",
      "AUPR+AUROC: 0.9965358493076221\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.18686533332858088, std: 0.005441648404976161\n",
      "Mean AUROCperdrug: 0.84567049305093, std: 0.007417736722572284\n",
      "Mean AUPR+AUROCperdrug: 1.032535826379511, std: 0.00797715030483904\n",
      "Mean AUPR: 0.17603676512432215, std: 0.02160349696895649\n",
      "Mean AUROC: 0.821002647307101, std: 0.01442461916804689\n",
      "Mean AUPR+AUROC: 0.997039412431423, std: 0.025446806735704215\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8656205143780997\n",
      "AUROC for each fold: [0.87018784 0.8621038  0.8649698  0.86522062]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.11363835568346374\n",
      "AUROCperdrug: 0.8768131461690594\n",
      "AUPR+AUROCperdrug: 0.9904515018525231\n",
      "AUPR: 0.1017717954244347\n",
      "AUROC: 0.8727080591526484\n",
      "AUPR+AUROC: 0.9744798545770831\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8665020174894555\n",
      "AUROC for each fold: [0.87732838 0.86537469 0.86085228 0.86245272]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.10834814880719863\n",
      "AUROCperdrug: 0.8772156456159913\n",
      "AUPR+AUROCperdrug: 0.98556379442319\n",
      "AUPR: 0.09837788782021334\n",
      "AUROC: 0.8646575585578299\n",
      "AUPR+AUROC: 0.9630354463780433\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8649454793319984\n",
      "AUROC for each fold: [0.87414807 0.86775392 0.8556326  0.86224732]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.12187905911237573\n",
      "AUROCperdrug: 0.8811831237179151\n",
      "AUPR+AUROCperdrug: 1.0030621828302908\n",
      "AUPR: 0.11229262976945789\n",
      "AUROC: 0.8747405499380059\n",
      "AUPR+AUROC: 0.9870331797074637\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8649600932441455\n",
      "AUROC for each fold: [0.87423848 0.87252442 0.85127206 0.86180541]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.12190975753594249\n",
      "AUROCperdrug: 0.8741849682784186\n",
      "AUPR+AUROCperdrug: 0.9960947258143611\n",
      "AUPR: 0.11130839887449834\n",
      "AUROC: 0.872010258463302\n",
      "AUPR+AUROC: 0.9833186573378003\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8684597157424354\n",
      "AUROC for each fold: [0.87652497 0.87599138 0.85924912 0.86207339]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.1277785175043062\n",
      "AUROCperdrug: 0.8714359943923443\n",
      "AUPR+AUROCperdrug: 0.9992145118966504\n",
      "AUPR: 0.1179773539329267\n",
      "AUROC: 0.8580736451538834\n",
      "AUPR+AUROC: 0.9760509990868101\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.11871076772865737, std: 0.006864530966360883\n",
      "Mean AUROCperdrug: 0.8761665756347459, std: 0.0032554422912333437\n",
      "Mean AUPR+AUROCperdrug: 0.994877343363403, std: 0.006222779362271941\n",
      "Mean AUPR: 0.1083456131643062, std: 0.007206914703145703\n",
      "Mean AUROC: 0.8684380142531338, std: 0.006203678913188355\n",
      "Mean AUPR+AUROC: 0.9767836274174402, std: 0.008277880570155272\n",
      "-----------\n",
      "using feature DGI\n",
      "The KRR requires hyperparameter lambda, sigma_X\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.18851208608761702\n",
      "AUROCperdrug: 0.8503373764758886\n",
      "AUPR+AUROCperdrug: 1.0388494625635056\n",
      "AUPR: 0.15515700270093466\n",
      "AUROC: 0.8370560409586554\n",
      "AUPR+AUROC: 0.9922130436595901\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.18849342776426492\n",
      "AUROCperdrug: 0.8560755377353312\n",
      "AUPR+AUROCperdrug: 1.0445689654995962\n",
      "AUPR: 0.16443893555879685\n",
      "AUROC: 0.8271474547232341\n",
      "AUPR+AUROC: 0.991586390282031\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.19992097018799157\n",
      "AUROCperdrug: 0.8580977265116453\n",
      "AUPR+AUROCperdrug: 1.0580186966996368\n",
      "AUPR: 0.21154959253136552\n",
      "AUROC: 0.8436212008261514\n",
      "AUPR+AUROC: 1.055170793357517\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.1918967095694743\n",
      "AUROCperdrug: 0.8431987625226657\n",
      "AUPR+AUROCperdrug: 1.03509547209214\n",
      "AUPR: 0.17860211736694107\n",
      "AUROC: 0.8098464201711292\n",
      "AUPR+AUROC: 0.9884485375380703\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  25\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  (0.1, 10) ------\n",
      "KRR starts:\n",
      "KRR ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.20713512637077694\n",
      "AUROCperdrug: 0.8407558987198511\n",
      "AUPR+AUROCperdrug: 1.0478910250906281\n",
      "AUPR: 0.19952590153514482\n",
      "AUROC: 0.8073426899387048\n",
      "AUPR+AUROC: 1.0068685914738498\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.19519166399602497, std: 0.007284950032477779\n",
      "Mean AUROCperdrug: 0.8496930603930763, std: 0.0068386890031141775\n",
      "Mean AUPR+AUROCperdrug: 1.0448847243891013, std: 0.007923289999429161\n",
      "Mean AUPR: 0.1818547099386366, std: 0.02107469189370716\n",
      "Mean AUROC: 0.825002761323575, std: 0.01440916616393271\n",
      "Mean AUPR+AUROC: 1.0068574712622116, std: 0.02498291908690941\n",
      "-----------\n",
      "using feature DGI\n",
      "The Naive requires no hyperparameter\n",
      "---------- nested cv start ----------\n",
      "Fold: 0\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "first few testing idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8684518940356909\n",
      "AUROC for each fold: [0.87299823 0.86494915 0.86773827 0.86812193]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.12182987907616337\n",
      "AUROCperdrug: 0.8797829471052186\n",
      "AUPR+AUROCperdrug: 1.001612826181382\n",
      "AUPR: 0.1103710674377813\n",
      "AUROC: 0.8758888626379576\n",
      "AUPR+AUROC: 0.9862599300757389\n",
      "-----------\n",
      "Fold: 1\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 49  54  67 117 183 251 258 271 411 711]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8693920102506654\n",
      "AUROC for each fold: [0.88029807 0.86814317 0.86382173 0.86530507]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.11716786786222326\n",
      "AUROCperdrug: 0.880565150180401\n",
      "AUPR+AUROCperdrug: 0.9977330180426243\n",
      "AUPR: 0.10589255228500952\n",
      "AUROC: 0.8676780976718743\n",
      "AUPR+AUROC: 0.9735706499568838\n",
      "-----------\n",
      "Fold: 2\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [  5 106 111 220 227 306 395 463 520 538]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8678944292506079\n",
      "AUROC for each fold: [0.87718751 0.87059494 0.85863677 0.8651585 ]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.13070726876462796\n",
      "AUROCperdrug: 0.8838419550521739\n",
      "AUPR+AUROCperdrug: 1.014549223816802\n",
      "AUPR: 0.11939742289319555\n",
      "AUROC: 0.8774619184397657\n",
      "AUPR+AUROC: 0.9968593413329613\n",
      "-----------\n",
      "Fold: 3\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 42 120 130 249 307 417 426 437 653 668]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8680188640563491\n",
      "AUROC for each fold: [0.87714971 0.87545987 0.85441722 0.86504865]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.12950104214031508\n",
      "AUROCperdrug: 0.8771090072367622\n",
      "AUPR+AUROCperdrug: 1.0066100493770773\n",
      "AUPR: 0.11650186076730731\n",
      "AUROC: 0.8743775414407566\n",
      "AUPR+AUROC: 0.9908794022080639\n",
      "-----------\n",
      "Fold: 4\n",
      "number of hyperpars combination:  1\n",
      "first few training idx:  [ 94 124 142 193 241 339 379 438 655 688]\n",
      "first few testing idx:  [ 15  50 113 119 238 272 505 507 633 719]\n",
      "Inner Fold: 0\n",
      "Inner Fold: 1\n",
      "Inner Fold: 2\n",
      "Inner Fold: 3\n",
      "best hyperpar: ()\n",
      "AUROC: 0.8713508179813421\n",
      "AUROC for each fold: [0.87924426 0.87877428 0.86247312 0.86491161]\n",
      "--- tuning end ---\n",
      "target size: 150\n",
      "------ best hyper pars:  () ------\n",
      "Naive starts:\n",
      "Naive ends:\n",
      "-----------\n",
      "AUPRperdrug: 0.1362383296594254\n",
      "AUROCperdrug: 0.8748786565441967\n",
      "AUPR+AUROCperdrug: 1.0111169862036222\n",
      "AUPR: 0.12495762722887463\n",
      "AUROC: 0.8610894465073482\n",
      "AUPR+AUROC: 0.9860470737362228\n",
      "-----------\n",
      "Mean AUPRperdrug: 0.12708887750055103, std: 0.006763242788312592\n",
      "Mean AUROCperdrug: 0.8792355432237505, std: 0.0030591225030746393\n",
      "Mean AUPR+AUROCperdrug: 1.0063244207243014, std: 0.00611079334762464\n",
      "Mean AUPR: 0.11542410612243366, std: 0.006696574414230428\n",
      "Mean AUROC: 0.8712991733395405, std: 0.006097076941812221\n",
      "Mean AUPR+AUROC: 0.986723279461974, std: 0.007663898698031968\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "SEs = {}\n",
    "SIDER = Pairs2Mat(path=\"data/drug_se.tsv\",colname1=\"1_x\",colname2=\"5\")\n",
    "column_sums = np.sum(SIDER, axis=0)\n",
    "results[\"KRR\"] = {}\n",
    "results[\"Naive\"] = {}\n",
    "for i in range(5, 305, 25):\n",
    "    results[\"KRR\"][i] = {}\n",
    "    results[\"Naive\"][i] = {}\n",
    "    SEs[\"SIDER\"] = SIDER.loc[:, (column_sums < i)]\n",
    "    \n",
    "    validation = \"nested_cv\"\n",
    "    method = \"KRR\"\n",
    "    str = \"DGI\"\n",
    "    print(f\"using feature {str}\")\n",
    "    hyperparList = loadHyperpar(*all_hyperparlist[method],method_option=method)\n",
    "    results[method][i], _ = evaluation(Y=SEs[\"SIDER\"], X=features_dict[str], method_option=method,tuning_metrice=metrice,hyperparList=hyperparList,hyperparfixed=hyperpars[validation][method][str],Validation=validation, n_jobs=1)\n",
    "\n",
    "    method = \"Naive\"\n",
    "    print(f\"using feature {str}\")\n",
    "    hyperparList = loadHyperpar(*all_hyperparlist[method],method_option=method)\n",
    "    results[method][i], _ = evaluation(Y=SEs[\"SIDER\"], X=features_dict[str], method_option=method,tuning_metrice=metrice,hyperparList=hyperparList,Validation=validation,n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "vector1 = []\n",
    "metrice = \"AUPR\"\n",
    "for i in range(5, 305, 25):\n",
    "    vector1.append(np.array(results[\"KRR\"][i][metrice]).mean())\n",
    "    vector2 = []\n",
    "x = []\n",
    "for i in range(5, 305, 25):\n",
    "    vector2.append(np.array(results[\"Naive\"][i][metrice]).mean())\n",
    "    x.append(i)\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot the first series\n",
    "plt.plot(x, vector1, marker='o', linestyle='-', color='b', label='KRR')\n",
    "\n",
    "# Plot the second series\n",
    "plt.plot(x, vector2, marker='s', linestyle='--', color='r', label='Naive')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title(metrice)\n",
    "plt.xlabel('threshold (ADRs less than)')\n",
    "plt.ylabel('Value')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show grid\n",
    "plt.grid(True)\n",
    "\n",
    "# Display the chart\n",
    "plt.show()\n",
    "\n",
    "vector1 = []\n",
    "metrice = \"AUROC\"\n",
    "for i in range(5, 305, 25):\n",
    "    vector1.append(np.array(results[\"KRR\"][i][metrice]).mean())\n",
    "    vector2 = []\n",
    "x = []\n",
    "for i in range(5, 305, 25):\n",
    "    vector2.append(np.array(results[\"Naive\"][i][metrice]).mean())\n",
    "    x.append(i)\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot the first series\n",
    "plt.plot(x, vector1, marker='o', linestyle='-', color='b', label='KRR')\n",
    "\n",
    "# Plot the second series\n",
    "plt.plot(x, vector2, marker='s', linestyle='--', color='r', label='Naive')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title(metrice)\n",
    "plt.xlabel('threshold (ADRs greater than)')\n",
    "plt.ylabel('Value')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show grid\n",
    "plt.grid(True)\n",
    "\n",
    "# Display the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
